{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f44d3b7-0ac2-4d07-ab06-c2cdf178a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 14:16:00.699611: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-12 14:16:00.699648: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-12 14:16:00.700429: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-12 14:16:00.705062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os, sys, random\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab1743d-1201-4bb2-b74c-1c6b1e0979a0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class RecorderMeter(object):\n",
    "    \"\"\"Computes and stores the minimum loss value and its epoch index, along with MCC\"\"\"\n",
    "\n",
    "    def __init__(self, total_epoch):\n",
    "        self.reset(total_epoch)\n",
    "\n",
    "    def reset(self, total_epoch):\n",
    "        assert total_epoch > 0\n",
    "        self.total_epoch = total_epoch\n",
    "        self.current_epoch = 0\n",
    "        self.epoch_losses = np.zeros((self.total_epoch, 2), dtype=np.float32)  # [epoch, train/val]\n",
    "        self.epoch_losses = self.epoch_losses - 1\n",
    "\n",
    "        self.epoch_mcc = np.zeros((self.total_epoch, 2), dtype=np.float32)  # [epoch, train/val]\n",
    "        self.epoch_mcc = self.epoch_mcc\n",
    "\n",
    "    def update(self, idx, train_loss, train_mcc, val_loss, val_mcc):\n",
    "        assert idx >= 0 and idx < self.total_epoch, 'total_epoch : {} , but update with the {} index'.format(\n",
    "            self.total_epoch, idx)\n",
    "        self.epoch_losses[idx, 0] = train_loss\n",
    "        self.epoch_losses[idx, 1] = val_loss\n",
    "        self.epoch_mcc[idx, 0] = train_mcc\n",
    "        self.epoch_mcc[idx, 1] = val_mcc\n",
    "        self.current_epoch = idx + 1\n",
    "\n",
    "    def max_mcc(self, istrain):\n",
    "        if self.current_epoch <= 0:\n",
    "            return 0\n",
    "        if istrain:\n",
    "            return self.epoch_mcc[:self.current_epoch, 0].max()\n",
    "        else:\n",
    "            return self.epoch_mcc[:self.current_epoch, 1].max()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d94f3b-6448-4cc4-8909-784cdfc88190",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def time_string():\n",
    "    ISOTIMEFORMAT = '%Y-%m-%d %X'\n",
    "    string = '[{}]'.format(\n",
    "        time.strftime(ISOTIMEFORMAT, time.gmtime(time.time())))\n",
    "    return string\n",
    "\n",
    "\n",
    "def convert_secs2time(epoch_time):\n",
    "    need_hour = int(epoch_time / 3600)\n",
    "    need_mins = int((epoch_time - 3600 * need_hour) / 60)\n",
    "    need_secs = int(epoch_time - 3600 * need_hour - 60 * need_mins)\n",
    "    return need_hour, need_mins, need_secs\n",
    "\n",
    "\n",
    "def time_file_str():\n",
    "    ISOTIMEFORMAT = '%Y-%m-%d'\n",
    "    string = '{}'.format(time.strftime(ISOTIMEFORMAT,\n",
    "                                       time.gmtime(time.time())))\n",
    "    return string + '-{}'.format(random.randint(1, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebfc21f-f070-4c3a-9d14-0016ff758cdf",
   "metadata": {},
   "source": [
    "### Class quan_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d955bd-6a8c-4182-8406-0edb3d399df1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class quan_Linear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(quan_Linear, self).__init__(in_features, out_features, bias=bias)\n",
    "\n",
    "        self.N_bits = 8\n",
    "        self.full_lvls = 2**self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "        # Initialize the step size\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        self.__reset_stepsize__()\n",
    "        # flag to enable the inference with quantized weight or self.weight\n",
    "        self.inf_with_weight = False  # disabled by default\n",
    "\n",
    "        # create a vector to identify the weight to each bit\n",
    "        self.b_w = nn.Parameter(2**torch.arange(start=self.N_bits - 1,\n",
    "                                                end=-1,\n",
    "                                                step=-1).unsqueeze(-1).float(),\n",
    "                                requires_grad=False)\n",
    "\n",
    "        self.b_w[0] = -self.b_w[0]  #in-place reverse\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.inf_with_weight:\n",
    "            return F.linear(input, self.weight * self.step_size, self.bias)\n",
    "        else:\n",
    "            self.__reset_stepsize__()\n",
    "            weight_quan = quantize(self.weight, self.step_size,\n",
    "                                   self.half_lvls) * self.step_size\n",
    "            return F.linear(input, weight_quan, self.bias)\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        with torch.no_grad():\n",
    "            self.step_size.data = self.weight.abs().max() / self.half_lvls\n",
    "\n",
    "    def __reset_weight__(self):\n",
    "        '''\n",
    "        This function will reconstruct the weight stored in self.weight.\n",
    "        Replacing the orginal floating-point with the quantized fix-point\n",
    "        weight representation.\n",
    "        '''\n",
    "        # replace the weight with the quantized version\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = quantize(self.weight, self.step_size,\n",
    "                                        self.half_lvls)\n",
    "        # enable the flag, thus now computation does not invovle weight quantization\n",
    "        self.inf_with_weight = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ef91d-ed9d-4cc0-8e3e-871496baa077",
   "metadata": {},
   "source": [
    "### Class quan_Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7af0b0-250e-40d1-a1e5-8c4dc2c0edee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class quan_Conv1d(nn.Conv1d):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True):\n",
    "        super(quan_Conv1d, self).__init__(in_channels,\n",
    "                                          out_channels,\n",
    "                                          kernel_size,\n",
    "                                          stride=stride,\n",
    "                                          padding=padding,\n",
    "                                          dilation=dilation,\n",
    "                                          groups=groups,\n",
    "                                          bias=bias)\n",
    "\n",
    "        # Số lượng bit để lượng tử hóa trọng số\n",
    "        self.N_bits = 8\n",
    "        self.full_lvls = 2 ** self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "\n",
    "        # Bước lượng tử hóa (step size), là một tham số có thể học được\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        self.__reset_stepsize__()\n",
    "\n",
    "        # Cờ để bật hoặc tắt sử dụng trọng số lượng tử hóa\n",
    "        self.inf_with_weight = False  # Tắt theo mặc định\n",
    "\n",
    "        # Tạo một vector để biểu diễn trọng số cho từng bit\n",
    "        self.b_w = nn.Parameter(2 ** torch.arange(start=self.N_bits - 1,\n",
    "                                                  end=-1,\n",
    "                                                  step=-1).unsqueeze(-1).float(),\n",
    "                                requires_grad=False)\n",
    "        self.b_w[0] = -self.b_w[0]  # Biến đổi MSB thành giá trị âm để hỗ trợ bù hai\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        \"\"\"Hàm này dùng để đặt lại giá trị `step_size`.\"\"\"\n",
    "        # Giá trị này có thể được tùy chỉnh tùy thuộc vào yêu cầu của mô hình\n",
    "        self.step_size.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Kiểm tra cờ `inf_with_weight` để quyết định sử dụng trọng số đã lượng tử hóa hay không\n",
    "        if self.inf_with_weight:\n",
    "            quantized_weight = self.quantize_weight(self.weight)\n",
    "            return nn.functional.conv1d(x, quantized_weight, self.bias, self.stride,\n",
    "                                        self.padding, self.dilation, self.groups)\n",
    "        else:\n",
    "            return nn.functional.conv1d(x, self.weight, self.bias, self.stride,\n",
    "                                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def quantize_weight(self, weight):\n",
    "        \"\"\"Lượng tử hóa trọng số theo số bit đã định.\"\"\"\n",
    "        # Tạo trọng số lượng tử hóa bằng cách sử dụng step_size\n",
    "        quantized_weight = torch.round(weight / self.step_size) * self.step_size\n",
    "        quantized_weight = torch.clamp(quantized_weight, -self.half_lvls * self.step_size,\n",
    "                                       (self.half_lvls - 1) * self.step_size)\n",
    "        return quantized_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fa88fb5-bb55-4533-a756-13cbd6a6c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_quan_bitwidth(model, n_bit):\n",
    "    '''This script change the quantization bit-width of entire model to n_bit'''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear):\n",
    "            m.N_bits = n_bit\n",
    "            # print(\"Change weight bit-width as {}.\".format(m.N_bits))\n",
    "            m.b_w.data = m.b_w.data[-m.N_bits:]\n",
    "            m.b_w[0] = -m.b_w[0]\n",
    "            print(m.b_w)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa75564-0034-4b5e-9d74-bdd47ab945f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _quantize_func(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, step_size, half_lvls):\n",
    "        # ctx is a context object that can be used to stash information\n",
    "        # for backward computation\n",
    "        ctx.step_size = step_size\n",
    "        ctx.half_lvls = half_lvls\n",
    "        output = F.hardtanh(input,\n",
    "                            min_val=-ctx.half_lvls * ctx.step_size.item(),\n",
    "                            max_val=ctx.half_lvls * ctx.step_size.item())\n",
    "\n",
    "        output = torch.round(output / ctx.step_size)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone() / ctx.step_size\n",
    "\n",
    "        return grad_input, None, None\n",
    "\n",
    "quantize = _quantize_func.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d00dfb4e-6a31-4c77-80fd-5f3c446e2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _bin_func(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, mu):\n",
    "        ctx.mu = mu\n",
    "        output = input.clone().zero_()\n",
    "        output[input.ge(0)] = 1\n",
    "        output[input.lt(0)] = -1\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone() / ctx.mu\n",
    "        return grad_input, None\n",
    "\n",
    "w_bin = _bin_func.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f06e03c-27bb-4119-a6b7-785167405267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(tensor, step_size, half_lvls):\n",
    "    \"\"\"Quantization function.\"\"\"\n",
    "    return torch.clamp(torch.round(tensor / step_size), min=-half_lvls, max=half_lvls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ffdeb-6fac-47a8-b893-220f06d0200f",
   "metadata": {},
   "source": [
    "### Class CustomBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86a72a2a-9140-440b-9fec-b84050b902dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, apply_softmax=False):\n",
    "        super(CustomBlock, self).__init__()\n",
    "        self.N_bits = 16\n",
    "        self.full_lvls = 2 ** self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        # Initialize the step size\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_features)) if bias else None\n",
    "\n",
    "        # Reset parameters\n",
    "        self.__reset_stepsize__()\n",
    "        self.reset_parameters()\n",
    "\n",
    "        # Flag for inference with quantized weights\n",
    "        self.inf_with_weight = False\n",
    "\n",
    "        self.b_w = nn.Parameter(2**torch.arange(start=self.N_bits - 1,\n",
    "                                             end=-1,\n",
    "                                             step=-1).unsqueeze(-1).float(),\n",
    "                           requires_grad=False)\n",
    "        self.b_w[0] = -self.b_w[0]  #in-place reverse\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=5 ** 0.5)\n",
    "        if self.bias is not None:\n",
    "            nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.inf_with_weight:\n",
    "            weight_applied = self.weight * self.step_size\n",
    "        else:\n",
    "            self.__reset_stepsize__()\n",
    "            weight_quan = quantize(self.weight, self.step_size, self.half_lvls) * self.step_size\n",
    "            weight_applied = weight_quan\n",
    "\n",
    "        # Linear transformation\n",
    "        input = input.view(input.size(0), -1)  # Flatten input to 2D for matmul\n",
    "        output = input @ weight_applied.T\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "\n",
    "        if self.apply_softmax:\n",
    "            output = F.softmax(output, dim=-1)\n",
    "        return output\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        with torch.no_grad():\n",
    "            self.step_size.data = self.weight.abs().max() / self.half_lvls\n",
    "\n",
    "    def __reset_weight__(self):\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = quantize(self.weight, self.step_size, self.half_lvls)\n",
    "        self.inf_with_weight = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37fcad76-3af7-4814-9f3f-115a0d6e6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleA(nn.Module):\n",
    "    def __init__(self, nIn, nOut, stride):\n",
    "        super(DownsampleA, self).__init__()\n",
    "        assert stride == 2\n",
    "        self.avg = nn.AvgPool1d(kernel_size=1, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        return torch.cat((x, x.mul(0)), 1)\n",
    "        \n",
    "class SEBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.conv_a = quan_Conv1d(inplanes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_a = nn.BatchNorm1d(planes)\n",
    "        self.dropout_a = nn.Dropout(p=0.3)  # Dropout sau BatchNorm\n",
    "\n",
    "        self.conv_b = quan_Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_b = nn.BatchNorm1d(planes)\n",
    "        self.dropout_b = nn.Dropout(p=0.3)  # Dropout sau BatchNorm\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        basicblock = self.conv_a(x)\n",
    "        basicblock = self.bn_a(basicblock)\n",
    "        basicblock = F.relu(basicblock, inplace=True)\n",
    "        basicblock = self.dropout_a(basicblock)  # Áp dụng dropout\n",
    "\n",
    "        basicblock = self.conv_b(basicblock)\n",
    "        basicblock = self.bn_b(basicblock)\n",
    "        basicblock = self.dropout_b(basicblock)  # Áp dụng dropout\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        return F.relu(residual + basicblock, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b7bf3-7bc7-4e4f-b34c-7b60196f150d",
   "metadata": {},
   "source": [
    "### Class CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00cab76a-39cf-453d-b657-ca053aee8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size=39, hidden_sizes=[32, 64, 128, 256, 512], output_size=34):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = quan_Conv1d(input_size, hidden_sizes[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "\n",
    "        self.inplanes = 32\n",
    "        self.stage_1 = self._make_layer(SEBlock, 32, 16, 1)\n",
    "        self.stage_2 = self._make_layer(SEBlock, 64, 16, 2)\n",
    "        self.stage_3 = self._make_layer(SEBlock, 128, 16, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.classifier = CustomBlock(128 * SEBlock.expansion, output_size)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                #m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal(m.weight)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        downsample = None\n",
    "        if stride == 2 or self.inplanes != planes * SEBlock.expansion:\n",
    "            downsample = DownsampleA(self.inplanes, planes * SEBlock.expansion, stride) if stride == 2 else None\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride=1, downsample=downsample))\n",
    "        self.inplanes = planes * SEBlock.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn_1(x), inplace=True)\n",
    "        \n",
    "        x = self.stage_1(x)\n",
    "        x = self.stage_2(x)\n",
    "        x = self.stage_3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4518cc2-57d4-474d-b206-68dfd5baa981",
   "metadata": {},
   "source": [
    "### Class CustomModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aa14999-e6e2-4a3b-8eb1-7032515747b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel2(nn.Module):\n",
    "    def __init__(self, input_size=39, hidden_sizes=[32, 64, 128, 100], output_size=34):\n",
    "        super(CustomModel2, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Conv1d(input_size, hidden_sizes[0], kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.stage_1 = nn.Conv1d(hidden_sizes[0], hidden_sizes[1], kernel_size=3, stride=2, padding=1)\n",
    "        self.stage_2 = nn.Conv1d(hidden_sizes[1], hidden_sizes[2], kernel_size=3, stride=2, padding=1)\n",
    "        self.stage_3 = nn.Conv1d(hidden_sizes[2], hidden_sizes[3], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Global Pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = CustomBlock(hidden_sizes[-1], output_size, apply_softmax=True)\n",
    "        nn.Dropout(0.15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_1(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_2(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_3(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        # Global Pooling\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be8524-9419-4c78-a136-c665a10da763",
   "metadata": {},
   "source": [
    "### Init dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c6d2715-cc0b-4a89-86b6-7b7859d97691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.arch = 'CustomModel'\n",
    "        self.data_path = '../../dataset/'\n",
    "        self.dataset = 'inid'\n",
    "        self.save_path = './save/attack_random'\n",
    "        self.epochs = 20\n",
    "        self.optimizer = 'SGD'\n",
    "        self.test_batch_size = 32\n",
    "        self.learning_rate = 0.001\n",
    "        self.momentum = 0.9\n",
    "        self.decay = 1e-4\n",
    "        self.schedule = [80, 120]\n",
    "        self.gammas = [0.1, 0.1]\n",
    "        self.print_freq = 100\n",
    "        self.resume = 'save\\model_best.pth.tar'\n",
    "        self.start_epoch = 0\n",
    "        self.enable_bfa = False\n",
    "        self.evaluate = False\n",
    "        self.ngpu = 1\n",
    "        self.gpu_id = 0\n",
    "        self.workers = 4\n",
    "        self.manualSeed = None\n",
    "        self.quan_bitwidth = 16\n",
    "        self.reset_weight = False\n",
    "        self.bfa = True\n",
    "        self.attack_sample_size = 128\n",
    "        self.n_iter = 20\n",
    "        self.k_top = None\n",
    "        self.random_bfa = True\n",
    "        self.progressive_bit_search= True\n",
    "        self.random_flip = True\n",
    "        self.clustering = False\n",
    "        self.lambda_coeff = 1e-3\n",
    "        self.use_cuda = True  \n",
    "\n",
    "args = Args()\n",
    "args.use_cuda = torch.cuda.is_available() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896db0e2-2ae5-4eeb-a5be-9513eb168b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Save path: ./save/attack_random\n",
      "State: {'arch': 'CustomModel', 'attack_sample_size': 128, 'bfa': True, 'clustering': False, 'data_path': '../../dataset/', 'dataset': 'inid', 'decay': 0.0001, 'enable_bfa': False, 'epochs': 20, 'evaluate': False, 'gammas': [0.1, 0.1], 'gpu_id': 0, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': None, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 100, 'progressive_bit_search': True, 'quan_bitwidth': 16, 'random_bfa': True, 'random_flip': True, 'reset_weight': False, 'resume': 'save\\\\model_best.pth.tar', 'save_path': './save/attack_random', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 32, 'use_cuda': True, 'workers': 4}\n",
      "Random Seed: None\n",
      "Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n",
      "Torch version: 2.2.2+cu118\n",
      "CUDNN version: 8907\n"
     ]
    }
   ],
   "source": [
    "# Thiết lập cấu hình logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Init logger\n",
    "if not os.path.isdir(args.save_path):\n",
    "    os.makedirs(args.save_path)\n",
    "\n",
    "# Tạo tệp log\n",
    "log_file_path = os.path.join(args.save_path, 'log_seed_{}.txt'.format(args.manualSeed))\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Định dạng cho tệp log\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Thêm file handler vào logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Ghi log vào console và tệp\n",
    "logger.info('Save path: {}'.format(args.save_path))\n",
    "state = {k: getattr(args, k) for k in dir(args) if not k.startswith('__')}\n",
    "logger.info('State: {}'.format(state))\n",
    "logger.info(\"Random Seed: {}\".format(args.manualSeed))\n",
    "logger.info(\"Python version: {}\".format(sys.version.replace('\\n', ' ')))\n",
    "logger.info(\"Torch version: {}\".format(torch.__version__))\n",
    "logger.info(\"CUDNN version: {}\".format(torch.backends.cudnn.version()))\n",
    "\n",
    "# Init the tensorboard path and writer\n",
    "tb_path = os.path.join(args.save_path, 'tb_log', 'run_' + str(args.manualSeed))\n",
    "writer = SummaryWriter(tb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcada582-5dd5-4a18-82bd-bedbe8d01b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inid dataset import sucsess!\n"
     ]
    }
   ],
   "source": [
    "# Init dataset\n",
    "if not os.path.isdir(args.data_path):\n",
    "    os.makedirs(args.data_path)\n",
    "\n",
    "if args.dataset == 'inid':\n",
    "    print(\"Inid dataset import sucsess!\")\n",
    "else:\n",
    "    assert False, \"Unknow dataset : {}\".format(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b1c44c7-8223-4bb5-92cf-416ec52171c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "=> creating model 'CustomModel'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of y_train: torch.Size([435954])\n",
      "Data type of y_test: torch.Size([108989])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Time_To_Live</th>\n",
       "      <th>Rate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>ack_flag_number</th>\n",
       "      <th>ece_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>LLC</th>\n",
       "      <th>Tot sum</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>AVG</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.672433</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>-0.241073</td>\n",
       "      <td>0.033427</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.99</td>\n",
       "      <td>6421</td>\n",
       "      <td>60</td>\n",
       "      <td>481</td>\n",
       "      <td>64.21</td>\n",
       "      <td>42.100000</td>\n",
       "      <td>64.21</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>100</td>\n",
       "      <td>1772.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.615759</td>\n",
       "      <td>3.780463</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>-0.679955</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>57320</td>\n",
       "      <td>98</td>\n",
       "      <td>578</td>\n",
       "      <td>573.20</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>573.20</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>100</td>\n",
       "      <td>2304.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.705996</td>\n",
       "      <td>0.733195</td>\n",
       "      <td>-0.085147</td>\n",
       "      <td>-0.166566</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6010</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>60.10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.10</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.727570</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>2.641403</td>\n",
       "      <td>-0.790616</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2223</td>\n",
       "      <td>54</td>\n",
       "      <td>1500</td>\n",
       "      <td>222.30</td>\n",
       "      <td>451.596686</td>\n",
       "      <td>222.30</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>10</td>\n",
       "      <td>203939.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.579001</td>\n",
       "      <td>-0.892015</td>\n",
       "      <td>-0.204384</td>\n",
       "      <td>0.131488</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6006</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>60.06</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>60.06</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>100</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712305</th>\n",
       "      <td>-1.606570</td>\n",
       "      <td>3.780463</td>\n",
       "      <td>0.148435</td>\n",
       "      <td>-0.699755</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>56436</td>\n",
       "      <td>70</td>\n",
       "      <td>578</td>\n",
       "      <td>564.36</td>\n",
       "      <td>79.049086</td>\n",
       "      <td>564.36</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>100</td>\n",
       "      <td>6248.757980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712306</th>\n",
       "      <td>0.681623</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>0.267584</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6000</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712307</th>\n",
       "      <td>-0.696806</td>\n",
       "      <td>0.733195</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>0.777507</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6000</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712308</th>\n",
       "      <td>0.681623</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>0.031644</td>\n",
       "      <td>-0.461580</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6061</td>\n",
       "      <td>60</td>\n",
       "      <td>121</td>\n",
       "      <td>60.61</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>60.61</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>100</td>\n",
       "      <td>37.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712309</th>\n",
       "      <td>0.681623</td>\n",
       "      <td>-0.384137</td>\n",
       "      <td>-0.201938</td>\n",
       "      <td>-0.049287</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6000</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>544943 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Header_Length  Protocol Type  Time_To_Live      Rate  fin_flag_number  \\\n",
       "0            0.672433      -0.384137     -0.241073  0.033427             0.00   \n",
       "1           -1.615759       3.780463     -0.201938 -0.679955             0.00   \n",
       "2           -0.705996       0.733195     -0.085147 -0.166566             0.00   \n",
       "3            0.727570      -0.384137      2.641403 -0.790616             0.10   \n",
       "4           -1.579001      -0.892015     -0.204384  0.131488             0.00   \n",
       "...               ...            ...           ...       ...              ...   \n",
       "712305      -1.606570       3.780463      0.148435 -0.699755             0.00   \n",
       "712306       0.681623      -0.384137     -0.201938  0.267584             0.00   \n",
       "712307      -0.696806       0.733195     -0.201938  0.777507             0.00   \n",
       "712308       0.681623      -0.384137      0.031644 -0.461580             0.98   \n",
       "712309       0.681623      -0.384137     -0.201938 -0.049287             0.00   \n",
       "\n",
       "        syn_flag_number  rst_flag_number  psh_flag_number  ack_flag_number  \\\n",
       "0                   0.0             0.00             0.99             0.99   \n",
       "1                   0.0             0.00             0.00             0.00   \n",
       "2                   0.0             0.00             0.00             0.00   \n",
       "3                   0.0             0.30             0.20             0.40   \n",
       "4                   0.0             0.00             0.00             0.01   \n",
       "...                 ...              ...              ...              ...   \n",
       "712305              0.0             0.00             0.00             0.00   \n",
       "712306              1.0             0.00             0.00             0.00   \n",
       "712307              0.0             0.00             0.00             0.00   \n",
       "712308              0.0             0.98             0.01             0.02   \n",
       "712309              1.0             0.00             0.00             0.00   \n",
       "\n",
       "        ece_flag_number  ...   LLC  Tot sum  Min   Max     AVG         Std  \\\n",
       "0                   0.0  ...  0.99     6421   60   481   64.21   42.100000   \n",
       "1                   0.0  ...  1.00    57320   98   578  573.20   48.000000   \n",
       "2                   0.0  ...  1.00     6010   60    70   60.10    1.000000   \n",
       "3                   0.0  ...  0.90     2223   54  1500  222.30  451.596686   \n",
       "4                   0.0  ...  1.00     6006   60    66   60.06    0.600000   \n",
       "...                 ...  ...   ...      ...  ...   ...     ...         ...   \n",
       "712305              0.0  ...  1.00    56436   70   578  564.36   79.049086   \n",
       "712306              0.0  ...  1.00     6000   60    60   60.00    0.000000   \n",
       "712307              0.0  ...  1.00     6000   60    60   60.00    0.000000   \n",
       "712308              0.0  ...  1.00     6061   60   121   60.61    6.100000   \n",
       "712309              0.0  ...  1.00     6000   60    60   60.00    0.000000   \n",
       "\n",
       "        Tot size       IAT  Number       Variance  \n",
       "0          64.21  0.000039     100    1772.410000  \n",
       "1         573.20  0.000271     100    2304.000000  \n",
       "2          60.10  0.000057     100       1.000000  \n",
       "3         222.30  0.004766      10  203939.566667  \n",
       "4          60.06  0.000035     100       0.360000  \n",
       "...          ...       ...     ...            ...  \n",
       "712305    564.36  0.000325     100    6248.757980  \n",
       "712306     60.00  0.000034     100       0.000000  \n",
       "712307     60.00  0.000020     100       0.000000  \n",
       "712308     60.61  0.000102     100      37.210000  \n",
       "712309     60.00  0.000048     100       0.000000  \n",
       "\n",
       "[544943 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init dataset\n",
    "if args.dataset == 'inid':\n",
    "    data = pd.read_csv(\"../../dataset/CIC_IoT_Dataset2023.csv\", skipinitialspace=True)\n",
    "    \n",
    "    # Remove duplicates and handle NaN values\n",
    "    data = data.drop(columns=['Cat'])\n",
    "    data = data.drop_duplicates()\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.fillna(0, inplace=True)\n",
    "    \n",
    "    # Separate labels and data\n",
    "    datalabel = data[['Label']]\n",
    "    data = data.drop(columns=['Label'])\n",
    "    \n",
    "    # Normalize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    data[['Header_Length', 'Protocol Type', 'Time_To_Live', 'Rate']] = scaler.fit_transform(\n",
    "        data[['Header_Length', 'Protocol Type', 'Time_To_Live', 'Rate']]\n",
    "    )\n",
    "    \n",
    "    # Label Encoding\n",
    "    onc = LabelEncoder()\n",
    "    y = onc.fit_transform(datalabel['Label'].to_numpy().reshape(-1, 1))\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=100)\n",
    "    \n",
    "    # Normalize X_train and X_test\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert y_train and y_test to Tensor\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_test = torch.LongTensor(y_test)\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"Data type of y_train:\", y_train.shape)\n",
    "    print(\"Data type of y_test:\", y_test.shape)\n",
    "    \n",
    "    # Create DataLoader for training set\n",
    "    train_loader = DataLoader(\n",
    "        torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_train),\n",
    "            y_train\n",
    "        ),\n",
    "        batch_size=256,\n",
    "        num_workers=5,\n",
    "        shuffle=True,\n",
    "        pin_memory=True \n",
    "    )\n",
    "    \n",
    "    # Create DataLoader for testing set\n",
    "    test_loader = DataLoader(\n",
    "        torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_test),\n",
    "            y_test\n",
    "        ),\n",
    "        batch_size=256,\n",
    "        num_workers=5,\n",
    "        shuffle=False,\n",
    "        pin_memory=True \n",
    "    )\n",
    "else:\n",
    "    # Code for other datasets\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=args.attack_sample_size,\n",
    "        shuffle=True,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True \n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data,\n",
    "        batch_size=args.test_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True \n",
    "    )\n",
    "\n",
    "logger.info(\"=> creating model '{}'\".format(args.arch))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba26c0f8-c31c-4391-b077-66165d0b8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc_score(preds, targets):\n",
    "    preds = preds.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "    return matthews_corrcoef(targets, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99229d0e-0d79-4b51-beb2-c70f5f5c53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc2(outputs_label, outputs_cat, y_label_batch, y_cat_batch):\n",
    "    \"\"\"Compute MCC for each output of the model (label, category).\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Ensure target has at least one dimension\n",
    "        if y_label_batch.dim() == 0:\n",
    "            y_label_batch = y_label_batch.unsqueeze(0)\n",
    "        if y_cat_batch.dim() == 0:\n",
    "            y_cat_batch = y_cat_batch.unsqueeze(0)\n",
    "\n",
    "        # Get the predicted classes (top-1 prediction) for each output\n",
    "        _, pred_label = outputs_label.topk(1, 1, True, True)\n",
    "        _, pred_cat = outputs_cat.topk(1, 1, True, True)\n",
    "\n",
    "        # Compute MCC for each output type\n",
    "        mcc_label = mcc_score(pred_label.view(-1), y_label_batch)\n",
    "        mcc_cat = mcc_score(pred_cat.view(-1), y_cat_batch)\n",
    "\n",
    "        return mcc_label, mcc_cat\n",
    "\n",
    "\n",
    "def mcc(output, target):\n",
    "    \"\"\"Compute the Matthews Correlation Coefficient (MCC) for the given output and target.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Ensure target has at least one dimension\n",
    "        if target.dim() == 0:\n",
    "            target = target.unsqueeze(0)\n",
    "\n",
    "        # Get the predicted classes (top-1 prediction)\n",
    "        _, pred = output.topk(1, 1, True, True)\n",
    "        return mcc_score(pred.view(-1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41d98736-bb0a-4d10-9422-11caa334f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f291e-ad43-4770-9e9a-0a0a07850136",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e39667a-f0ba-49cc-bc17-9fe62aaa29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()  # Track MCC instead of accuracy\n",
    "\n",
    "    # Switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.use_cuda:\n",
    "            input = input.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "            \n",
    "        input = input.view(input.size(0), 39, -1)  # Reshape input\n",
    "        \n",
    "        # Compute output and loss\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if args.clustering:\n",
    "            loss += clustering_loss(model, args.lambda_coeff)\n",
    "\n",
    "        # Compute MCC and record loss\n",
    "        mcc_value = mcc(output.data, target)  # MCC calculation instead of topk accuracy\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        mcc_meter.update(mcc_value, input.size(0))\n",
    "\n",
    "        # Compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    return mcc_meter.avg, losses.avg\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, summary_output=True):\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "    tpr_meter = AverageMeter()\n",
    "    f1_meter = AverageMeter()\n",
    "\n",
    "    # Chuyển model sang chế độ đánh giá\n",
    "    model.eval()\n",
    "    output_summary = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            if input.size(1) == 39 and input.dim() == 2:  # Kiểm tra nếu thiếu chiều thứ 3\n",
    "                input = input.unsqueeze(-1)\n",
    "\n",
    "            if torch.cuda.is_available() and args.use_cuda:\n",
    "                target = target.cuda(non_blocking=True)\n",
    "                input = input.cuda(non_blocking=True)\n",
    "\n",
    "            # Tính toán output và loss\n",
    "            output = model(input)\n",
    "            pred = torch.argmax(output, dim=1)  # Chọn nhãn dự đoán có xác suất cao nhất\n",
    "            loss = criterion(output, target)\n",
    "            losses.update(loss.item(), input.size(0))  # Cập nhật losses\n",
    "\n",
    "            # Chuyển sang numpy để tính toán các chỉ số\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            target_np = target.cpu().numpy()\n",
    "\n",
    "            if summary_output:\n",
    "                tmp_list = output.max(1, keepdim=True)[1].flatten().cpu().numpy() # get the index of the max log-probability\n",
    "                output_summary.append(tmp_list)\n",
    "\n",
    "            # Tính các chỉ số đánh giá\n",
    "            mcc_value = matthews_corrcoef(target_np, pred_np)\n",
    "            acc_value = accuracy_score(target_np, pred_np)\n",
    "            tpr_value = recall_score(target_np, pred_np, average='macro')  # Macro recall ~ TPR\n",
    "            f1_value = f1_score(target_np, pred_np, average='macro')\n",
    "\n",
    "            # Cập nhật giá trị trung bình\n",
    "            mcc_meter.update(mcc_value, input.size(0))\n",
    "            acc_meter.update(acc_value, input.size(0))\n",
    "            tpr_meter.update(tpr_value, input.size(0))\n",
    "            f1_meter.update(f1_value, input.size(0))\n",
    "\n",
    "    return mcc_meter.avg, acc_meter.avg, tpr_meter.avg, f1_meter.avg, losses.avg, output_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1687046-4b16-4dce-9495-484ece92b6b1",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8d35b5b-6c57-4d4e-8747-560eaa878af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, recall_score, f1_score\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "# Tắt cảnh báo UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "def validate_score(model, test_loader):\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "    tpr_meter = AverageMeter()\n",
    "    f1_meter = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            if input.size(1) == 39 and input.dim() == 2:  # Kiểm tra nếu thiếu chiều thứ 3\n",
    "                input = input.unsqueeze(-1)\n",
    "\n",
    "            if torch.cuda.is_available() and args.use_cuda:\n",
    "                target = target.cuda(non_blocking=True)\n",
    "                input = input.cuda(non_blocking=True)\n",
    "\n",
    "            # Tính toán output và loss\n",
    "            output = model(input)\n",
    "            pred = torch.argmax(output, dim=1)  # Chọn nhãn dự đoán có xác suất cao nhất\n",
    "\n",
    "            # Chuyển sang numpy để tính toán các chỉ số\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            target_np = target.cpu().numpy()\n",
    "\n",
    "            # Tính các chỉ số đánh giá\n",
    "            mcc_value = matthews_corrcoef(target_np, pred_np)\n",
    "            acc_value = accuracy_score(target_np, pred_np)\n",
    "            tpr_value = recall_score(target_np, pred_np, average='macro')  # Macro recall ~ TPR\n",
    "            f1_value = f1_score(target_np, pred_np, average='macro')\n",
    "\n",
    "            # Cập nhật giá trị trung bình\n",
    "            mcc_meter.update(mcc_value, input.size(0))\n",
    "            acc_meter.update(acc_value, input.size(0))\n",
    "            tpr_meter.update(tpr_value, input.size(0))\n",
    "            f1_meter.update(f1_value, input.size(0))\n",
    "\n",
    "    return {\n",
    "        \"MCC\": mcc_meter.avg,\n",
    "        \"Accuracy\": acc_meter.avg,\n",
    "        \"TPR\": tpr_meter.avg,\n",
    "        \"F1 Score\": f1_meter.avg\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db928785-c739-49a0-af06-9b3adb6fc504",
   "metadata": {},
   "source": [
    "### class BFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74582bcb-fbb1-4843-b49d-8b886e216d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFA(object):\n",
    "    def __init__(self, criterion, model, k_top=10):\n",
    "        self.criterion = criterion\n",
    "        self.loss_dict = {}\n",
    "        self.bit_counter = 0\n",
    "        self.k_top = k_top\n",
    "        self.n_bits2flip = 0\n",
    "        self.loss = 0\n",
    "        self.num_bit_flipped = 0\n",
    "        \n",
    "        # Attributes for random attack\n",
    "        self.module_list = []\n",
    "\n",
    "        for name, m in model.named_modules():\n",
    "            if isinstance(m, (quan_Conv1d, quan_Linear, CustomBlock)):\n",
    "                self.module_list.append(name)\n",
    "\n",
    "    def flip_bit(self, m):\n",
    "        '''\n",
    "        the data type of input param is 32-bit floating, then return the data should\n",
    "        be in the same data_type.\n",
    "        '''\n",
    "        if self.k_top is None:\n",
    "            k_top = m.weight.detach().flatten().__len__()\n",
    "        else: \n",
    "            k_top = self.k_top\n",
    "        # 1. flatten the gradient tensor to perform topk\n",
    "        w_grad_topk, w_idx_topk = m.weight.grad.detach().abs().view(-1).topk(k_top)\n",
    "        # update the b_grad to its signed representation\n",
    "        w_grad_topk = m.weight.grad.detach().view(-1)[w_idx_topk]\n",
    "\n",
    "        # 2. create the b_grad matrix in shape of [N_bits, k_top]\n",
    "        b_grad_topk = w_grad_topk * m.b_w.data\n",
    "\n",
    "        # 3. generate the gradient mask to zero-out the bit-gradient\n",
    "        # which can not be flipped\n",
    "        b_grad_topk_sign = (b_grad_topk.sign() +\n",
    "                            1) * 0.5  # zero -> negative, one -> positive\n",
    "        # convert to twos complement into unsigned integer\n",
    "        w_bin = int2bin(m.weight.detach().view(-1), m.N_bits).short()\n",
    "        w_bin_topk = w_bin[w_idx_topk]  # get the weights whose grads are topk\n",
    "        \n",
    "        # generate two's complement bit-map\n",
    "        b_bin_topk = (w_bin_topk.repeat(m.N_bits, 1) & m.b_w.abs().repeat(1, k_top).short()) \\\n",
    "           // m.b_w.abs().repeat(1, k_top).short()\n",
    "\n",
    "        grad_mask = b_bin_topk ^ b_grad_topk_sign.short()\n",
    "\n",
    "        # 4. apply the gradient mask upon ```b_grad_topk``` and in-place update it\n",
    "        b_grad_topk *= grad_mask.float()\n",
    "\n",
    "        # 5. identify the several maximum of absolute bit gradient and return the index, the number of bits to flip is self.n_bits2flip\n",
    "\n",
    "        grad_max = b_grad_topk.abs().max()\n",
    "        num_elements = b_grad_topk.nelement()  # Get the total number of elements\n",
    "        k = min(self.n_bits2flip, num_elements)  # Clamp the value of k\n",
    "    \n",
    "        _, b_grad_max_idx = b_grad_topk.abs().view(-1).topk(k)  # Use clamped k\n",
    "        bit2flip = b_grad_topk.clone().view(-1).zero_()\n",
    "\n",
    "        if grad_max.item() != 0:  # ensure the max grad is not zero\n",
    "            bit2flip[b_grad_max_idx] = 1\n",
    "            bit2flip = bit2flip.view(b_grad_topk.size())\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # 6. Based on the identified bit indexed by ```bit2flip```, generate another\n",
    "        # mask, then perform the bitwise xor operation to realize the bit-flip.\n",
    "        bit2flip = bit2flip.reshape(m.b_w.abs().shape[0], -1)  # Định hình lại\n",
    "\n",
    "        w_bin_topk_flipped = (bit2flip.short() * m.b_w.abs().short()).sum(0, dtype=torch.int16) \\\n",
    "            ^ w_bin_topk\n",
    "\n",
    "        # 7. update the weight in the original weight tensor\n",
    "        w_bin[w_idx_topk] = w_bin_topk_flipped  # in-place change\n",
    "        param_flipped = bin2int(w_bin,\n",
    "                                m.N_bits).view(m.weight.data.size()).float()\n",
    "\n",
    "        return param_flipped\n",
    "\n",
    "    def progressive_bit_search(self, model, data, target, test_loader):\n",
    "        ''' \n",
    "        Given the model, based on the current data and target, go through\n",
    "        all the layers and identify the bits to be flipped. \n",
    "        '''\n",
    "        model.eval()\n",
    "        output = model(data)\n",
    "        self.loss = self.criterion(output, target)\n",
    "\n",
    "        # Zero out the grads first, then get the grads\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, (quan_Conv1d, quan_Linear, CustomBlock)):\n",
    "                if m.weight.grad is not None:\n",
    "                    m.weight.grad.data.zero_()\n",
    "\n",
    "        self.loss.backward()\n",
    "        self.loss_max = self.loss.item()\n",
    "\n",
    "        attack_log = []\n",
    "\n",
    "        # 3. Flip bits until no further loss degradation is observed\n",
    "        while self.loss_max <= self.loss.item():\n",
    "            self.n_bits2flip += 1\n",
    "            self.loss_dict = {}\n",
    "\n",
    "            for name, module in model.named_modules():\n",
    "                if isinstance(module, CustomBlock) or isinstance(module, quan_Conv1d):\n",
    "                    clean_weight = module.weight.data.detach()\n",
    "                    attack_weight = self.flip_bit(module)\n",
    "                    self.num_bit_flipped += 1\n",
    "\n",
    "                    module.weight.data = attack_weight\n",
    "                    output = model(data)\n",
    "\n",
    "                    self.loss_dict[name] = self.criterion(output, target).item()\n",
    "                    module.weight.data = clean_weight\n",
    "\n",
    "            max_loss_module = max(self.loss_dict.items(), key=lambda item: item[1])[0]\n",
    "            self.loss_max = self.loss_dict[max_loss_module]\n",
    "\n",
    "            if self.n_bits2flip == 100:\n",
    "                break;\n",
    "\n",
    "        weight_prior = None\n",
    "        weight_post = None\n",
    "                \n",
    "        # If loss_max does lead to degradation, change that layer's weight\n",
    "        for module_idx, (name, module) in enumerate(model.named_modules()):\n",
    "            if name == max_loss_module:\n",
    "                attack_weight = self.flip_bit(module)\n",
    "                self.num_bit_flipped += 1\n",
    "\n",
    "                ###########################################################\n",
    "                ## Attack profiling\n",
    "                ##########################################################\n",
    "                \n",
    "                weight_mismatch = attack_weight - module.weight.detach()\n",
    "                attack_weight_idx = torch.nonzero(weight_mismatch)\n",
    "                print('attacked module:', max_loss_module)\n",
    "                \n",
    "                attack_log = []\n",
    "                for i in range(attack_weight_idx.size(0)):\n",
    "                    weight_idx = attack_weight_idx[i, :].cpu().numpy()\n",
    "                    weight_prior = module.weight.detach()[tuple(weight_idx)].item()\n",
    "                    weight_post = attack_weight[tuple(weight_idx)].item()\n",
    "                \n",
    "                    tmp_list = [module_idx, self.bit_counter + (i + 1), max_loss_module,\n",
    "                                weight_idx, weight_prior, weight_post]\n",
    "                    attack_log.append(tmp_list)\n",
    "\n",
    "                module.weight.data = attack_weight\n",
    "\n",
    "        self.bit_counter += self.n_bits2flip\n",
    "        self.n_bits2flip = 0\n",
    "\n",
    "        if weight_prior is None or weight_post is None:\n",
    "            attack_last_status = [self.bit_counter, max_loss_module, \"No attack\", \"No attack\"]\n",
    "        else:\n",
    "            attack_last_status = [self.bit_counter, max_loss_module, round(weight_prior, 5), round(weight_post, 5)]\n",
    "        \n",
    "        return attack_log, validate_score(model, test_loader), self.bit_counter, attack_last_status\n",
    "\n",
    "    def random_flip_one_bit(self, model, test_loader):\n",
    "        \"\"\"\n",
    "        Randomly flip one bit in the weight of a chosen module.\n",
    "        \"\"\"\n",
    "        weight_prior = None\n",
    "        weight_post = None\n",
    "        \n",
    "        chosen_module = random.choice(self.module_list)\n",
    "        for name, m in model.named_modules():\n",
    "            if name == chosen_module:\n",
    "                flatten_weight = m.weight.detach().view(-1)\n",
    "                chosen_idx = random.choice(range(flatten_weight.numel()))\n",
    "                bin_w = int2bin(flatten_weight[chosen_idx], m.N_bits).short()\n",
    "                bit_idx = random.choice(range(m.N_bits))\n",
    "                mask = (bin_w.clone().zero_() + 1) * (2 ** bit_idx)\n",
    "                bin_w = bin_w ^ mask\n",
    "                int_w = bin2int(bin_w, m.N_bits).float()\n",
    "\n",
    "                ##############################################\n",
    "                ###   attack profiling\n",
    "                ###############################################\n",
    "                \n",
    "                weight_mismatch = flatten_weight[chosen_idx] - int_w\n",
    "                attack_weight_idx = chosen_idx\n",
    "\n",
    "                print('attacked module:', chosen_module)\n",
    "                \n",
    "                attack_log = []\n",
    "                weight_idx = chosen_idx\n",
    "                weight_prior = flatten_weight[chosen_idx]\n",
    "                weight_post = int_w\n",
    "\n",
    "                print('attacked weight index:', weight_idx)\n",
    "                print('weight before attack:', weight_prior)\n",
    "                print('weight after attack:', weight_post)\n",
    "\n",
    "                tmp_list = [\"module_idx\", self.bit_counter + 1, \"loss\",\n",
    "                            weight_idx, weight_prior, weight_post]\n",
    "                attack_log.append(tmp_list)                            \n",
    "\n",
    "                self.bit_counter += 1\n",
    "                flatten_weight[chosen_idx] = int_w\n",
    "                m.weight.data = flatten_weight.view(m.weight.data.size())\n",
    "                \n",
    "        if weight_prior is None or weight_post is None:\n",
    "            attack_last_status = [self.bit_counter, chosen_module, \"No attack\", \"No attack\"]\n",
    "        else:\n",
    "            attack_last_status = [self.bit_counter, chosen_module, weight_prior, weight_post]\n",
    "\n",
    "        return attack_log, validate_score(model, test_loader), self.bit_counter, attack_last_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f84e2d5-5b3e-44c2-ad91-bb2db1f4123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using SGD as optimizer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = CustomModel().to(device)\n",
    "\n",
    "if args.use_cuda:\n",
    "    if args.ngpu > 1:\n",
    "        net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, weight_decay=0.01)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# separate the parameters thus param groups can be updated by different optimizer\n",
    "all_param = [\n",
    "    param for name, param in net.named_parameters()\n",
    "    if not 'step_size' in name\n",
    "]\n",
    "\n",
    "step_param = [\n",
    "    param for name, param in net.named_parameters() if 'step_size' in name \n",
    "]\n",
    "\n",
    "if args.optimizer == \"SGD\":\n",
    "    print(\"using SGD as optimizer\")\n",
    "    optimizer = torch.optim.SGD(all_param,\n",
    "                                lr=0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=0.0001,\n",
    "                                nesterov=True)\n",
    "\n",
    "elif args.optimizer == \"Adam\":\n",
    "    print(\"using Adam as optimizer\")\n",
    "    optimizer = torch.optim.Adam(filter(lambda param: param.requires_grad,\n",
    "                                        all_param),\n",
    "                                 lr=0.001,\n",
    "                                 #momentum=0.9,\n",
    "                                 weight_decay=0.001)\n",
    "\n",
    "\n",
    "elif args.optimizer == \"RMSprop\":\n",
    "    print(\"using RMSprop as optimizer\")\n",
    "    optimizer = torch.optim.RMSprop(\n",
    "        filter(lambda param: param.requires_grad, net.parameters()),\n",
    "        lr=0.01,\n",
    "        alpha=0.99,\n",
    "        eps=1e-08,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90b235-b1f9-4fca-8436-8b556b04e691",
   "metadata": {},
   "source": [
    "## BFA Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24700838-e7ee-4af6-8d1c-368edf0b351e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found at 'save\\model_best.pth.tar'\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if args.use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        if not args.fine_tune:\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            recorder = checkpoint['recorder']\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        state_tmp = net.state_dict()\n",
    "        if 'state_dict' in checkpoint.keys():\n",
    "            state_tmp.update(checkpoint['state_dict'])\n",
    "        else:\n",
    "            state_tmp.update(checkpoint)\n",
    "\n",
    "        net.load_state_dict(state_tmp, strict=False)\n",
    "    else:\n",
    "        print(\"No checkpoint found at '{}'\".format(args.resume))\n",
    "else:\n",
    "    print(\"Do not use any checkpoint for {} model\".format(args.arch))\n",
    "\n",
    "\n",
    "# Configure the quantization bit-width\n",
    "if args.quan_bitwidth is not None:\n",
    "    change_quan_bitwidth(net, args.quan_bitwidth)\n",
    "\n",
    "# Update the step_size once the model is loaded. This is used for quantization.\n",
    "for m in net.modules():\n",
    "    if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear) or isinstance(m, CustomBlock) or m.__class__.__name__ == \"CustomBlock\" or m.__class__.__name__ == \"quan_Conv1d\":\n",
    "        m.__reset_stepsize__()\n",
    "\n",
    "# Block for weight reset\n",
    "if args.reset_weight:\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear) or isinstance(m, CustomBlock):\n",
    "            m.__reset_weight__()\n",
    "\n",
    "attacker = BFA(criterion, net, args.k_top)  # Khởi tạo đối tượng tấn công\n",
    "net_clean = copy.deepcopy(net)\n",
    "    # weight_conversion(net)\n",
    "\n",
    "if args.enable_bfa:\n",
    "    perform_attack(attacker, net, net_clean, train_loader, test_loader,\n",
    "                   args.n_iter, writer, csv_save_path=args.save_path,\n",
    "                   random_attack=args.random_bfa)\n",
    "\n",
    "if args.evaluate:\n",
    "    print(\"Evaluate mode\")\n",
    "    _, _, _, _, _, _, output_summary = validate(test_loader, net, criterion, summary_output=True)\n",
    "    pd.DataFrame(output_summary).to_csv(os.path.join(args.save_path, 'output_summary_{}.csv'.format(args.arch)),\n",
    "                                        header=['top-1 output'], index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bede100-21b0-4bf2-9614-b17a15142bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, gammas, schedule):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.learning_rate\n",
    "    mu = args.momentum\n",
    "\n",
    "    if args.optimizer != \"YF\":\n",
    "        assert len(gammas) == len(\n",
    "            schedule), \"length of gammas and schedule should be equal\"\n",
    "        for (gamma, step) in zip(gammas, schedule):\n",
    "            if (epoch >= step):\n",
    "                lr = lr * gamma\n",
    "            else:\n",
    "                break\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    elif args.optimizer == \"YF\":\n",
    "        lr = optimizer._lr\n",
    "        mu = optimizer._mu\n",
    "\n",
    "    return lr, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbd7e109-0734-4e16-8a5b-e19358496855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 0 with seed: 7817\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "if args.ngpu == 1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
    "        args.gpu_id)  # make only device #gpu_id visible, then\n",
    "\n",
    "args.use_cuda = args.ngpu > 0 and torch.cuda.is_available()  # check GPU\n",
    "\n",
    "# Give a random seed if no manual configuration\n",
    "if args.manualSeed is None:\n",
    "    args.manualSeed = random.randint(1, 10000)\n",
    "random.seed(args.manualSeed)\n",
    "torch.manual_seed(args.manualSeed)\n",
    "\n",
    "if args.use_cuda:\n",
    "    torch.cuda.manual_seed_all(args.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if args.use_cuda:\n",
    "    print(f\"Using GPU: {args.gpu_id} with seed: {args.manualSeed}\")\n",
    "else:\n",
    "    print(f\"Using CPU with seed: {args.manualSeed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a48cb46-c3f3-4b1c-a3e0-63b33685a7b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = CustomModel().to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# # criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "# #optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# num_epochs = 50\n",
    "\n",
    "# best_val_loss = float('inf')\n",
    "# patience = 10  # Số epoch để chờ trước khi dừng\n",
    "# counter = 0\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# # Vòng lặp huấn luyện\n",
    "# best_val_loss = float('inf')\n",
    "# best_mcc = -1  # Khởi tạo MCC tốt nhất\n",
    "\n",
    "# # Vòng lặp huấn luyện\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_mcc, train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#     val_mcc, val_loss, output_summary = validate(test_loader, model, criterion, summary_output=True)\n",
    "#     scheduler.step(val_loss)\n",
    "\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         best_mcc = val_mcc  # Lưu MCC tốt nhất\n",
    "#         counter = 0\n",
    "\n",
    "#         save_dir = \"CustomModel\"\n",
    "#         save_path = os.path.join(save_dir, \"best_model.pth\")\n",
    "\n",
    "#         if not os.path.exists(save_dir):\n",
    "#             os.makedirs(save_dir)\n",
    "\n",
    "#         torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "#     else:\n",
    "#         counter += 1\n",
    "#         if counter >= patience:\n",
    "#             print(\"Early stopping triggered\")\n",
    "#             break\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f}, Train MCC: {train_mcc:.4f}\")\n",
    "#     print(f\"Validation Loss: {val_loss:.4f}, Validation MCC: {val_mcc:.4f}\")\n",
    "# print(f\"Best MCC during training: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d48ac-3ec1-42da-a557-591fbb18f1e1",
   "metadata": {},
   "source": [
    "## Random Attack\n",
    "\n",
    "### import data_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfca572d-36ef-4fd7-86cb-aa4958463a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2bin(input, num_bits):\n",
    "    '''\n",
    "    convert the signed integer value into unsigned integer (2's complement equivalently).\n",
    "    Note that, the conversion is different depends on number of bit used.\n",
    "    '''\n",
    "    output = input.clone()\n",
    "    if num_bits == 1: # when it is binary, the conversion is different\n",
    "        output = output/2 + .5\n",
    "    elif num_bits > 1:\n",
    "        output[input.lt(0)] = 2**num_bits + output[input.lt(0)]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def bin2int(input, num_bits):\n",
    "    '''\n",
    "    convert the unsigned integer (2's complement equivantly) back to the signed integer format\n",
    "    with the bitwise operations. Note that, in order to perform the bitwise operation, the input\n",
    "    tensor has to be in the integer format.\n",
    "    '''\n",
    "    if num_bits == 1:\n",
    "        output = input*2-1\n",
    "    elif num_bits > 1:\n",
    "        mask = 2**(num_bits - 1) - 1\n",
    "        output = -(input & ~mask) + (input & mask)\n",
    "    return output\n",
    "\n",
    "\n",
    "def weight_conversion(model):\n",
    "    '''\n",
    "    Perform the weight data type conversion between:\n",
    "        signed integer <==> two's complement (unsigned integer)\n",
    "    Such conversion is used as additional step to ensure the conversion correctness\n",
    "\n",
    "    Note that, the data type conversion chosen is depend on the bits:\n",
    "        N_bits <= 8   .char()   --> torch.CharTensor(), 8-bit signed integer\n",
    "        N_bits <= 16  .short()  --> torch.shortTensor(), 16 bit signed integer\n",
    "        N_bits <= 32  .int()    --> torch.IntTensor(), 32 bit signed integer\n",
    "    '''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear):\n",
    "            w_bin = int2bin(m.weight.data, m.N_bits).short()\n",
    "            m.weight.data = bin2int(w_bin, m.N_bits).float()\n",
    "    return\n",
    "\n",
    "def count_ones(t, n_bits):\n",
    "    counter = 0\n",
    "    for i in range(n_bits):\n",
    "        counter += ((t & 2**i) // 2**i).sum()\n",
    "    return counter.item()\n",
    "\n",
    "\n",
    "def hamming_distance(model1, model2):\n",
    "    '''\n",
    "    Given two model whose structure, name and so on are identical.\n",
    "    The only difference between the model1 and model2 are the weight.\n",
    "    The function compute the hamming distance bewtween the bianry weights\n",
    "    (two's complement) of model1 and model2.\n",
    "    '''\n",
    "    # TODO: add the function check model1 and model2 are same structure\n",
    "    # check the keys of state_dict match or not.\n",
    "\n",
    "    H_dist = 0  # hamming distance counter\n",
    "\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, quan_Conv1d) or isinstance(module, quan_Linear):\n",
    "            # remember to convert the tensor into integer for bitwise operations\n",
    "            binW_model1 = int2bin(model1.state_dict()[name + '.weight'],\n",
    "                                  module.N_bits).short()\n",
    "            binW_model2 = int2bin(model2.state_dict()[name + '.weight'],\n",
    "                                  module.N_bits).short()\n",
    "            H_dist += count_ones(binW_model1 ^ binW_model2, module.N_bits)\n",
    "\n",
    "    return H_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f209d-6392-4a4c-afce-986fa0128d9b",
   "metadata": {},
   "source": [
    "## Vẽ đồ thị MCC sau mỗi epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60ce8a7d-bea3-4e5b-a69e-dc8224dd1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mcc_vs_bit_flipped(images_filename, x_data, y_data):\n",
    "    titles = [\"MCC\", \"ACC\", \"TPR\", \"F1-Score\"]\n",
    "    \n",
    "    for image_filename, title in zip(images_filename, titles):\n",
    "        if len(x_data) != len(y_data):\n",
    "            raise ValueError(\"x_data and y_data must have the same length.\")\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x_data, y_data, marker='o', linestyle='-', color='b', label='MCC')\n",
    "        plt.title(f'{title} after Epochs', fontsize=14) \n",
    "        plt.xlabel('Epoch', fontsize=12)\n",
    "        plt.ylabel(title, fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot as an image file\n",
    "        plt.savefig(image_filename)\n",
    "        plt.close()\n",
    "        print(f\"Plot saved as {image_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf7df3e7-c55b-4690-be7c-cfd6f344f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def perform_attack(attacker, model, model_clean, train_loader, test_loader,\n",
    "                   N_iter, writer, file, csv_file, csv_save_path=None, attack_type=1,):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    iter_time = AverageMeter()\n",
    "    attack_time = AverageMeter()\n",
    "\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        if args.use_cuda:\n",
    "            target = target.cuda()\n",
    "            data = data.cuda()\n",
    "\n",
    "        data = data.unsqueeze(-1)  # Kích thước [512, 39, 1]\n",
    "        _, target = model(data).data.max(1)\n",
    "        break\n",
    "\n",
    "    val_mcc_top1, val_acc_top1, val_tpr_top1, val_f1score_top1, val_loss, output_summary = validate(test_loader, model, attacker.criterion, summary_output=True)\n",
    "    print(f'**Test** MCC: {val_mcc_top1:.3f}. Val_Loss: {val_loss:.3f}')\n",
    "    print(f'ACC: {val_acc_top1:.3f}.')\n",
    "    print(f'TPR: {val_tpr_top1:.3f}.')\n",
    "    print(f'F1-score: {val_f1score_top1:.3f}.')\n",
    "\n",
    "    tmp_df = pd.DataFrame(output_summary)\n",
    "    tmp_df['BFA iteration'] = 0\n",
    "    tmp_df.to_csv(os.path.join(args.save_path, 'output_summary_{}_BFA_0.csv'.format(args.arch)), index=False)\n",
    "\n",
    "    writer.add_scalar('attack/val_top1_acc', val_mcc_top1, 0)\n",
    "    writer.add_scalar('attack/val_loss', val_loss, 0)\n",
    "\n",
    "    print('Attack sample size is {}'.format(data.size()[0]))\n",
    "    end = time.time()\n",
    "    df = pd.DataFrame()\n",
    "    last_val_mcc_top1 = val_mcc_top1\n",
    "    last_val_acc_top1 = val_acc_top1\n",
    "    last_val_tpr_top1 = val_tpr_top1\n",
    "    last_val_f1score_top1 = val_f1score_top1\n",
    "\n",
    "    MCC_data = [val_mcc_top1]\n",
    "    Bit_flipped = [0]\n",
    "    all_attack_status = []\n",
    "\n",
    "    for i_iter in range(N_iter):\n",
    "        print('**********************************')        \n",
    "        if attack_type == 1:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            MCC_data.append(new_mcc['MCC'])\n",
    "            Bit_flipped.append(bit_count)\n",
    "        elif attack_type == 2:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            MCC_data.append(new_mcc['MCC'])\n",
    "            Bit_flipped.append(bit_count)\n",
    "        elif attack_type == 3:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            MCC_data.append(new_mcc['MCC'])\n",
    "            Bit_flipped.append(bit_count)\n",
    "        elif attack_type == 4:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            MCC_data.append(new_mcc['MCC'])\n",
    "            Bit_flipped.append(bit_count)\n",
    "        \n",
    "        attack_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        h_dist = hamming_distance(model, model_clean)\n",
    "\n",
    "        if hasattr(attacker, \"loss_max\"):\n",
    "            losses.update(attacker.loss_max, data.size(0))\n",
    "\n",
    "        print('Iteration: [{:03d}/{:03d}]   Attack Time {attack_time.val:.3f} ({attack_time.avg:.3f})'.format(i_iter + 1, N_iter, attack_time=attack_time))\n",
    "\n",
    "        try:\n",
    "            print('Loss before attack: {:.4f}'.format(attacker.loss.item()))\n",
    "            print('Loss after attack: {:.4f}'.format(attacker.loss_max))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print('Bit flips: {:.0f}'.format(attacker.bit_counter))\n",
    "        print('Hamming distance: {:.0f}'.format(h_dist))\n",
    "\n",
    "        writer.add_scalar('attack/bit_flip', attacker.bit_counter, i_iter + 1)\n",
    "        writer.add_scalar('attack/h_dist', h_dist, i_iter + 1)\n",
    "        writer.add_scalar('attack/sample_loss', losses.avg, i_iter + 1)\n",
    "\n",
    "        val_mcc_top1, val_acc_top1, val_tpr_top1, val_f1score_top1, val_loss, output_summary = validate(test_loader, model, attacker.criterion, summary_output=True)\n",
    "        print(f'**Test** MCC: {val_mcc_top1:.3f}. Val_Loss: {val_loss:.3f}')\n",
    "        print(f'ACC: {val_acc_top1:.3f}.')\n",
    "        print(f'TPR: {val_tpr_top1:.3f}.')\n",
    "        print(f'F1-score: {val_f1score_top1:.3f}.')\n",
    "        \n",
    "        tmp_df = pd.DataFrame(output_summary)\n",
    "        tmp_df['BFA iteration'] = i_iter + 1\n",
    "        tmp_df.to_csv(os.path.join(args.save_path, 'output_summary_{}_BFA_{}.csv'.format(args.arch, i_iter + 1)), index=False)\n",
    "\n",
    "        # last_val_mcc_top1 = val_mcc_top1\n",
    "        # last_val_acc_top1 = val_acc_top1\n",
    "        # last_val_tpr_top1 = val_tpr_top1\n",
    "        # last_val_f1score_top1 = val_f1score_top1\n",
    "        \n",
    "        mcc_drop = last_val_mcc_top1 - val_mcc_top1\n",
    "        last_val_mcc_top1 = val_mcc_top1\n",
    "\n",
    "        acc_drop = last_val_acc_top1 - val_acc_top1\n",
    "        last_val_acc_top1 = val_acc_top1\n",
    "\n",
    "        tpr_drop = last_val_tpr_top1 - val_tpr_top1\n",
    "        last_val_tpr_top1 = val_tpr_top1\n",
    "\n",
    "        f1score_drop = last_val_f1score_top1 - val_f1score_top1\n",
    "        last_val_f1score_top1 = val_f1score_top1\n",
    "\n",
    "        attack_last_status.append(round(val_mcc_top1, 5))\n",
    "        attack_last_status.append(round(mcc_drop, 5))\n",
    "        \n",
    "        attack_last_status.append(round(val_acc_top1, 5))\n",
    "        attack_last_status.append(round(acc_drop, 5))\n",
    "        \n",
    "        attack_last_status.append(round(val_tpr_top1, 5))\n",
    "        attack_last_status.append(round(tpr_drop, 5))\n",
    "        \n",
    "        attack_last_status.append(round(val_f1score_top1, 5))\n",
    "        attack_last_status.append(round(f1score_drop, 5))\n",
    "\n",
    "        for entry in attack_log:\n",
    "            entry.append(val_mcc_top1)\n",
    "            entry.append(mcc_drop)\n",
    "\n",
    "            entry.append(val_acc_top1)\n",
    "            entry.append(acc_drop)\n",
    "\n",
    "            entry.append(val_tpr_top1)\n",
    "            entry.append(tpr_drop)\n",
    "\n",
    "            entry.append(val_f1score_top1)\n",
    "            entry.append(f1score_drop)\n",
    "            \n",
    "        df = pd.concat([df, pd.DataFrame(attack_log)], ignore_index=True)\n",
    "\n",
    "        writer.add_scalar('attack/val_top1_acc', val_mcc_top1, i_iter + 1)\n",
    "        writer.add_scalar('attack/val_loss', val_loss, i_iter + 1)\n",
    "\n",
    "        iter_time.update(time.time() - end)\n",
    "        print('Iteration Time {iter_time.val:.3f} ({iter_time.avg:.3f})'.format(iter_time=iter_time))\n",
    "        end = time.time()\n",
    "\n",
    "        all_attack_status.append(attack_last_status)\n",
    "\n",
    "    column_list = ['module idx', 'bit-flip idx', 'module name', 'weight idx', 'weight before attack', 'weight after attack'\n",
    "                    , 'validation mcc', 'mcc drop'\n",
    "                    , \"ACC\", \"ACC Drop\"\n",
    "                    , \"TPR\", \"TPR Drop\"\n",
    "                    , \"F1-score\", \"F1-score Drop\",]\n",
    "    df.columns = column_list\n",
    "    df['trial seed'] = args.manualSeed\n",
    "\n",
    "    if csv_save_path is not None:\n",
    "        csv_file_name = 'attack_profile_{}.csv'.format(args.manualSeed)\n",
    "        df.to_csv(os.path.join(csv_save_path, csv_file_name), index=None)\n",
    "\n",
    "    # Vẽ đồ thị với MCC\n",
    "    plot_mcc_vs_bit_flipped(file, Bit_flipped, MCC_data)\n",
    "    \n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Ghi tiêu đề (nếu cần)\n",
    "        writer.writerow([\"Bit Counter\", \"Module\", \"Weight Before Attack\", \"Weight After Attack\"\n",
    "                         , \"MCC\", \"MCC Drop\"\n",
    "                         , \"ACC\", \"ACC Drop\"\n",
    "                         , \"TPR\", \"TPR Drop\"\n",
    "                         , \"F1-score\", \"F1-score Drop\",])\n",
    "        \n",
    "        # Ghi dữ liệu\n",
    "        writer.writerows(all_attack_status)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adfc613-8bbf-4eef-9108-2025db3e8a35",
   "metadata": {},
   "source": [
    "## Train CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f57a1b3-406b-4238-a9d7-40de139a9083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC before attack: 0.7452722620092466\n",
      "Accuracy before attack: 0.7634990687133564\n",
      "TPR before attack: 0.7069808655363797\n",
      "F1-score before attack: 0.6967175582937473\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "# Kiểm tra xem tệp có tồn tại không\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC before attack: {results['MCC']}\")\n",
    "print(f\"Accuracy before attack: {results['Accuracy']}\")\n",
    "print(f\"TPR before attack: {results['TPR']}\")\n",
    "print(f\"F1-score before attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d41b45-6173-4820-9156-0b02557344d2",
   "metadata": {},
   "source": [
    "## Attack CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d8058e6-93dd-406f-af0e-141023047ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.710.\n",
      "F1-score: 0.699.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: fc1\n",
      "Iteration: [001/020]   Attack Time 7.296 (7.296)\n",
      "Loss before attack: 0.3256\n",
      "Loss after attack: 105.6416\n",
      "Bit flips: 1\n",
      "Hamming distance: 1\n",
      "**Test** MCC: 0.003. Val_Loss: 101.059\n",
      "ACC: 0.040.\n",
      "TPR: 0.053.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 6.857 (6.857)\n",
      "**********************************\n",
      "attacked module: stage_1.6.conv_a\n",
      "Iteration: [002/020]   Attack Time 7.429 (7.363)\n",
      "Loss before attack: 105.6416\n",
      "Loss after attack: 2793.2605\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: -0.002. Val_Loss: 2671.741\n",
      "ACC: 0.032.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.598 (6.728)\n",
      "**********************************\n",
      "attacked module: stage_1.6.conv_b\n",
      "Iteration: [003/020]   Attack Time 7.159 (7.295)\n",
      "Loss before attack: 2793.2605\n",
      "Loss after attack: 191833.0938\n",
      "Bit flips: 3\n",
      "Hamming distance: 3\n",
      "**Test** MCC: 0.007. Val_Loss: 183476.194\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.475 (6.643)\n",
      "**********************************\n",
      "attacked module: stage_1.5.conv_a\n",
      "Iteration: [004/020]   Attack Time 7.255 (7.285)\n",
      "Loss before attack: 191833.0938\n",
      "Loss after attack: 6646140.0000\n",
      "Bit flips: 4\n",
      "Hamming distance: 4\n",
      "**Test** MCC: 0.008. Val_Loss: 6357334.307\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.428 (6.590)\n",
      "**********************************\n",
      "attacked module: stage_1.5.conv_b\n",
      "Iteration: [005/020]   Attack Time 7.240 (7.276)\n",
      "Loss before attack: 6646140.0000\n",
      "Loss after attack: 387380320.0000\n",
      "Bit flips: 5\n",
      "Hamming distance: 5\n",
      "**Test** MCC: 0.008. Val_Loss: 370551820.732\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.732 (6.618)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_a\n",
      "Iteration: [006/020]   Attack Time 7.046 (7.237)\n",
      "Loss before attack: 387380320.0000\n",
      "Loss after attack: 12164632576.0000\n",
      "Bit flips: 6\n",
      "Hamming distance: 6\n",
      "**Test** MCC: 0.009. Val_Loss: 11631184313.482\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.368 (6.576)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_b\n",
      "Iteration: [007/020]   Attack Time 7.198 (7.232)\n",
      "Loss before attack: 12164632576.0000\n",
      "Loss after attack: 701511827456.0000\n",
      "Bit flips: 7\n",
      "Hamming distance: 7\n",
      "**Test** MCC: 0.009. Val_Loss: 670772293870.607\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.717 (6.596)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_b\n",
      "Iteration: [008/020]   Attack Time 7.370 (7.249)\n",
      "Loss before attack: 701511827456.0000\n",
      "Loss after attack: 24851150536704.0000\n",
      "Bit flips: 8\n",
      "Hamming distance: 8\n",
      "**Test** MCC: 0.005. Val_Loss: 23747718249196.273\n",
      "ACC: 0.041.\n",
      "TPR: 0.054.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 6.512 (6.586)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_a\n",
      "Iteration: [009/020]   Attack Time 7.109 (7.234)\n",
      "Loss before attack: 24851150536704.0000\n",
      "Loss after attack: 2256197591760896.0000\n",
      "Bit flips: 9\n",
      "Hamming distance: 9\n",
      "**Test** MCC: 0.010. Val_Loss: 2156349820572085.250\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.005.\n",
      "Iteration Time 6.434 (6.569)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_b\n",
      "Iteration: [010/020]   Attack Time 7.276 (7.238)\n",
      "Loss before attack: 2256197591760896.0000\n",
      "Loss after attack: 58445893489131520.0000\n",
      "Bit flips: 10\n",
      "Hamming distance: 10\n",
      "**Test** MCC: 0.015. Val_Loss: 55857003296436400.000\n",
      "ACC: 0.036.\n",
      "TPR: 0.051.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.295 (6.542)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_a\n",
      "Iteration: [011/020]   Attack Time 7.049 (7.221)\n",
      "Loss before attack: 58445893489131520.0000\n",
      "Loss after attack: 6923228346163658752.0000\n",
      "Bit flips: 11\n",
      "Hamming distance: 11\n",
      "**Test** MCC: -0.001. Val_Loss: 6620004308799259648.000\n",
      "ACC: 0.028.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.003.\n",
      "Iteration Time 6.595 (6.546)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [012/020]   Attack Time 7.178 (7.217)\n",
      "Loss before attack: 6923228346163658752.0000\n",
      "Loss after attack: 144638010252909871104.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 11\n",
      "**Test** MCC: -0.003. Val_Loss: 143516405886607097856.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.557 (6.547)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_a\n",
      "Iteration: [013/020]   Attack Time 10.799 (7.493)\n",
      "Loss before attack: 144638010252909871104.0000\n",
      "Loss after attack: 2049602404902636617728.0000\n",
      "Bit flips: 13\n",
      "Hamming distance: 12\n",
      "**Test** MCC: -0.000. Val_Loss: 2033001088015347482624.000\n",
      "ACC: 0.028.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.003.\n",
      "Iteration Time 6.451 (6.540)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_b\n",
      "Iteration: [014/020]   Attack Time 10.876 (7.734)\n",
      "Loss before attack: 2049602404902636617728.0000\n",
      "Loss after attack: 126642266356771897475072.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 13\n",
      "**Test** MCC: 0.000. Val_Loss: 123278751107664599580672.000\n",
      "ACC: 0.028.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.003.\n",
      "Iteration Time 6.269 (6.520)\n",
      "**********************************\n",
      "attacked module: stage_3.7.conv_a\n",
      "Iteration: [015/020]   Attack Time 10.654 (7.929)\n",
      "Loss before attack: 126642266356771897475072.0000\n",
      "Loss after attack: 2212790138116123029143552.0000\n",
      "Bit flips: 15\n",
      "Hamming distance: 14\n",
      "**Test** MCC: -0.000. Val_Loss: 2125221550128239235563520.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.000.\n",
      "Iteration Time 6.599 (6.526)\n",
      "**********************************\n",
      "attacked module: stage_1.2.conv_b\n",
      "Iteration: [016/020]   Attack Time 7.219 (7.885)\n",
      "Loss before attack: 2212790138116123029143552.0000\n",
      "Loss after attack: 12198862984824750868529152.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 15\n",
      "**Test** MCC: 0.001. Val_Loss: 11717052922187209498427392.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.000.\n",
      "Iteration Time 6.718 (6.538)\n",
      "**********************************\n",
      "attacked module: stage_1.2.conv_a\n",
      "Iteration: [017/020]   Attack Time 7.618 (7.869)\n",
      "Loss before attack: 12198862984824750868529152.0000\n",
      "Loss after attack: 2534951865757071762423545856.0000\n",
      "Bit flips: 17\n",
      "Hamming distance: 16\n",
      "**Test** MCC: 0.000. Val_Loss: 2434534501360656402241028096.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.000.\n",
      "Iteration Time 6.628 (6.543)\n",
      "**********************************\n",
      "attacked module: stage_1.10.conv_b\n",
      "Iteration: [018/020]   Attack Time 7.200 (7.832)\n",
      "Loss before attack: 2534951865757071762423545856.0000\n",
      "Loss after attack: 13596877237577288133768118272.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 17\n",
      "**Test** MCC: 0.002. Val_Loss: 13058814236344147455393136640.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.399 (6.535)\n",
      "**********************************\n",
      "attacked module: stage_1.10.conv_a\n",
      "Iteration: [019/020]   Attack Time 7.078 (7.792)\n",
      "Loss before attack: 13596877237577288133768118272.0000\n",
      "Loss after attack: 2617521756605724251451641823232.0000\n",
      "Bit flips: 19\n",
      "Hamming distance: 18\n",
      "**Test** MCC: 0.000. Val_Loss: 2513839120819777317144455282688.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.000.\n",
      "Iteration Time 6.515 (6.534)\n",
      "**********************************\n",
      "attacked module: stage_1.7.conv_b\n",
      "Iteration: [020/020]   Attack Time 7.021 (7.753)\n",
      "Loss before attack: 2617521756605724251451641823232.0000\n",
      "Loss after attack: 12865347468861016779831184982016.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 19\n",
      "**Test** MCC: 0.001. Val_Loss: 12355825738263792057144135647232.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.000.\n",
      "Iteration Time 6.336 (6.524)\n",
      "Plot saved as CustomModel/PBS_attack/MCC_PBS_attack.png\n",
      "Plot saved as CustomModel/PBS_attack/ACC_PBS_attack.png\n",
      "Plot saved as CustomModel/PBS_attack/TPR_PBS_attack.png\n",
      "Plot saved as CustomModel/PBS_attack/F1_PBS_attack.png\n",
      "MCC after 100 times PBS attack: 0.0012726120918714482\n",
      "Accuracy after 100 times PBS attack: 0.003908651331785777\n",
      "TPR after 100 times PBS attack: 0.027266055661181086\n",
      "F1-score after 100 times PBS attack: 0.0004841137124260272\n"
     ]
    }
   ],
   "source": [
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_PBS_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 1,                  # Chế độ tấn công PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score(trained_model, test_loader)\n",
    "# print(f\"\\nMCC after 100 times PBS attack: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times PBS attack: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times PBS attack: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times PBS attack: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times PBS attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31bd74aa-83fe-4388-9e48-e018219c5c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: stage_1.12.conv_a\n",
      "attacked weight index: 96\n",
      "weight before attack: tensor(0.1083, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "Iteration: [001/020]   Attack Time 5.942 (5.942)\n",
      "Bit flips: 1\n",
      "Hamming distance: 1\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.554 (6.554)\n",
      "**********************************\n",
      "attacked module: stage_2.11.conv_b\n",
      "attacked weight index: 5914\n",
      "weight before attack: tensor(0.0662, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [002/020]   Attack Time 6.036 (5.989)\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.681 (6.617)\n",
      "**********************************\n",
      "attacked module: stage_2.8.conv_b\n",
      "attacked weight index: 583\n",
      "weight before attack: tensor(-0.0300, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [003/020]   Attack Time 5.804 (5.927)\n",
      "Bit flips: 3\n",
      "Hamming distance: 3\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.659 (6.631)\n",
      "**********************************\n",
      "attacked module: stage_2.11.conv_a\n",
      "attacked weight index: 2410\n",
      "weight before attack: tensor(-0.0735, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [004/020]   Attack Time 5.845 (5.907)\n",
      "Bit flips: 4\n",
      "Hamming distance: 4\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.473 (6.592)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_b\n",
      "attacked weight index: 358\n",
      "weight before attack: tensor(-0.0574, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [005/020]   Attack Time 5.934 (5.912)\n",
      "Bit flips: 5\n",
      "Hamming distance: 5\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.930 (6.659)\n",
      "**********************************\n",
      "attacked module: stage_2.10.conv_a\n",
      "attacked weight index: 7175\n",
      "weight before attack: tensor(0.0052, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [006/020]   Attack Time 5.687 (5.875)\n",
      "Bit flips: 6\n",
      "Hamming distance: 6\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.556 (6.642)\n",
      "**********************************\n",
      "attacked module: stage_2.8.conv_b\n",
      "attacked weight index: 10288\n",
      "weight before attack: tensor(-0.2450, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [007/020]   Attack Time 5.938 (5.884)\n",
      "Bit flips: 7\n",
      "Hamming distance: 7\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.603 (6.636)\n",
      "**********************************\n",
      "attacked module: stage_1.5.conv_b\n",
      "attacked weight index: 1973\n",
      "weight before attack: tensor(-0.0455, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [008/020]   Attack Time 6.002 (5.898)\n",
      "Bit flips: 8\n",
      "Hamming distance: 8\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.632 (6.636)\n",
      "**********************************\n",
      "attacked module: stage_2.15.conv_b\n",
      "attacked weight index: 11312\n",
      "weight before attack: tensor(-0.0042, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [009/020]   Attack Time 5.977 (5.907)\n",
      "Bit flips: 9\n",
      "Hamming distance: 9\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.787 (6.653)\n",
      "**********************************\n",
      "attacked module: stage_1.12.conv_b\n",
      "attacked weight index: 244\n",
      "weight before attack: tensor(0.0262, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [010/020]   Attack Time 5.983 (5.915)\n",
      "Bit flips: 10\n",
      "Hamming distance: 10\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.600 (6.647)\n",
      "**********************************\n",
      "attacked module: stage_2.5.conv_a\n",
      "attacked weight index: 7813\n",
      "weight before attack: tensor(-0.4800, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [011/020]   Attack Time 5.740 (5.899)\n",
      "Bit flips: 11\n",
      "Hamming distance: 11\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Iteration Time 6.511 (6.635)\n",
      "**********************************\n",
      "attacked module: stage_2.12.conv_b\n",
      "attacked weight index: 2974\n",
      "weight before attack: tensor(-0.0560, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [012/020]   Attack Time 5.870 (5.896)\n",
      "Bit flips: 12\n",
      "Hamming distance: 12\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.622 (6.634)\n",
      "**********************************\n",
      "attacked module: stage_1.14.conv_a\n",
      "attacked weight index: 2361\n",
      "weight before attack: tensor(-0.0004, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [013/020]   Attack Time 5.687 (5.880)\n",
      "Bit flips: 13\n",
      "Hamming distance: 13\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.567 (6.629)\n",
      "**********************************\n",
      "attacked module: stage_2.11.conv_a\n",
      "attacked weight index: 4000\n",
      "weight before attack: tensor(0.3643, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "Iteration: [014/020]   Attack Time 6.094 (5.896)\n",
      "Bit flips: 14\n",
      "Hamming distance: 14\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.576 (6.625)\n",
      "**********************************\n",
      "attacked module: stage_2.7.conv_a\n",
      "attacked weight index: 6896\n",
      "weight before attack: tensor(0.0442, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [015/020]   Attack Time 5.866 (5.894)\n",
      "Bit flips: 15\n",
      "Hamming distance: 15\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.471 (6.615)\n",
      "**********************************\n",
      "attacked module: stage_2.5.conv_a\n",
      "attacked weight index: 2622\n",
      "weight before attack: tensor(0.0403, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [016/020]   Attack Time 6.021 (5.902)\n",
      "Bit flips: 16\n",
      "Hamming distance: 16\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.491 (6.607)\n",
      "**********************************\n",
      "attacked module: stage_2.12.conv_b\n",
      "attacked weight index: 804\n",
      "weight before attack: tensor(-0.0393, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [017/020]   Attack Time 5.794 (5.895)\n",
      "Bit flips: 17\n",
      "Hamming distance: 17\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.565 (6.605)\n",
      "**********************************\n",
      "attacked module: stage_3.6.conv_b\n",
      "attacked weight index: 6511\n",
      "weight before attack: tensor(-0.0991, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "Iteration: [018/020]   Attack Time 5.781 (5.889)\n",
      "Bit flips: 18\n",
      "Hamming distance: 18\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.647 (6.607)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_b\n",
      "attacked weight index: 2468\n",
      "weight before attack: tensor(0.0790, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "Iteration: [019/020]   Attack Time 5.591 (5.873)\n",
      "Bit flips: 19\n",
      "Hamming distance: 19\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.494 (6.601)\n",
      "**********************************\n",
      "attacked module: stage_1.9.conv_b\n",
      "attacked weight index: 1337\n",
      "weight before attack: tensor(0.0603, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [020/020]   Attack Time 5.857 (5.872)\n",
      "Bit flips: 20\n",
      "Hamming distance: 20\n",
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.712.\n",
      "F1-score: 0.702.\n",
      "Iteration Time 6.583 (6.600)\n",
      "Plot saved as CustomModel/RandomFlip_attack/MCC_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_attack/ACC_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_attack/TPR_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_attack/F1_RandomFlip_attack.png\n",
      "MCC after 100 times random attack: 0.7490690411214455\n",
      "Accuracy after 100 times random attack: 0.7670131848168164\n",
      "TPR after 100 times random attack: 0.7121503579785792\n",
      "F1-score after 100 times random attack: 0.7021251824955163\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_RandomFlip_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 2,                  # Chế độ tấn công random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "\n",
    "# best_mcc = validate_score(trained_model ,test_loader)\n",
    "# print(f\"\\nMCC after 100 times random attack: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times random attack: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times random attack: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times random attack: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times random attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0b8375d-ecc2-40d2-b41a-97f243b4c903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: fc1\n",
      "attacked module: stage_1.6.conv_a\n",
      "attacked weight index: 2285\n",
      "weight before attack: tensor(-0.0737, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "Iteration: [001/020]   Attack Time 12.825 (12.825)\n",
      "Loss before attack: 0.3409\n",
      "Loss after attack: 17.5793\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.012. Val_Loss: 18.018\n",
      "ACC: 0.016.\n",
      "TPR: 0.030.\n",
      "F1-score: 0.014.\n",
      "Iteration Time 6.429 (6.429)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: stage_1.8.conv_b\n",
      "attacked weight index: 641\n",
      "weight before attack: tensor(0.1749, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [002/020]   Attack Time 12.973 (12.899)\n",
      "Loss before attack: 17.5793\n",
      "Loss after attack: 361.7913\n",
      "Bit flips: 4\n",
      "Hamming distance: 3\n",
      "**Test** MCC: 0.017. Val_Loss: 370.540\n",
      "ACC: 0.018.\n",
      "TPR: 0.036.\n",
      "F1-score: 0.020.\n",
      "Iteration Time 6.430 (6.430)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_a\n",
      "attacked module: stage_2.11.conv_b\n",
      "attacked weight index: 401\n",
      "weight before attack: tensor(0.0627, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [003/020]   Attack Time 16.622 (14.140)\n",
      "Loss before attack: 361.7913\n",
      "Loss after attack: 3705.7786\n",
      "Bit flips: 6\n",
      "Hamming distance: 5\n",
      "**Test** MCC: 0.024. Val_Loss: 3612.294\n",
      "ACC: 0.018.\n",
      "TPR: 0.034.\n",
      "F1-score: 0.013.\n",
      "Iteration Time 6.337 (6.399)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_a\n",
      "attacked module: stage_3.7.conv_a\n",
      "attacked weight index: 2835\n",
      "weight before attack: tensor(-0.0184, device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "Iteration: [004/020]   Attack Time 12.775 (13.799)\n",
      "Loss before attack: 3705.7786\n",
      "Loss after attack: 89105.1797\n",
      "Bit flips: 8\n",
      "Hamming distance: 7\n",
      "**Test** MCC: 0.012. Val_Loss: 85984.385\n",
      "ACC: 0.031.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.505 (6.425)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_b\n",
      "attacked module: stage_3.12.conv_b\n",
      "attacked weight index: 41654\n",
      "weight before attack: tensor(-0.0148, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [005/020]   Attack Time 12.935 (13.626)\n",
      "Loss before attack: 89105.1797\n",
      "Loss after attack: 7412805.0000\n",
      "Bit flips: 10\n",
      "Hamming distance: 9\n",
      "**Test** MCC: 0.003. Val_Loss: 7150759.233\n",
      "ACC: 0.028.\n",
      "TPR: 0.045.\n",
      "F1-score: 0.003.\n",
      "Iteration Time 6.479 (6.436)\n",
      "**********************************\n",
      "attacked module: stage_1.6.conv_b\n",
      "attacked module: stage_3.10.conv_a\n",
      "attacked weight index: 35570\n",
      "weight before attack: tensor(-0.0540, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [006/020]   Attack Time 13.100 (13.538)\n",
      "Loss before attack: 7412805.0000\n",
      "Loss after attack: 78726456.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 11\n",
      "**Test** MCC: 0.018. Val_Loss: 75946972.511\n",
      "ACC: 0.033.\n",
      "TPR: 0.049.\n",
      "F1-score: 0.010.\n",
      "Iteration Time 6.568 (6.458)\n",
      "**********************************\n",
      "attacked module: stage_1.6.conv_a\n",
      "attacked module: stage_3.15.conv_b\n",
      "attacked weight index: 349\n",
      "weight before attack: tensor(-0.3528, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [007/020]   Attack Time 12.939 (13.453)\n",
      "Loss before attack: 78726456.0000\n",
      "Loss after attack: 39352061952.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 13\n",
      "**Test** MCC: 0.003. Val_Loss: 37947977241.466\n",
      "ACC: 0.028.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.003.\n",
      "Iteration Time 6.627 (6.482)\n",
      "**********************************\n",
      "attacked module: stage_3.7.conv_a\n",
      "attacked module: stage_2.15.conv_a\n",
      "attacked weight index: 7413\n",
      "weight before attack: tensor(0.0295, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [008/020]   Attack Time 16.945 (13.889)\n",
      "Loss before attack: 39339266048.0000\n",
      "Loss after attack: 332792692736.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 15\n",
      "**Test** MCC: 0.001. Val_Loss: 335668654528.012\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.535 (6.489)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_b\n",
      "attacked module: stage_3.15.conv_b\n",
      "attacked weight index: 49034\n",
      "weight before attack: tensor(-0.0044, device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "Iteration: [009/020]   Attack Time 17.080 (14.244)\n",
      "Loss before attack: 332792692736.0000\n",
      "Loss after attack: 27680749649920.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 17\n",
      "**Test** MCC: 0.000. Val_Loss: 28081343887380.988\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.390 (6.478)\n",
      "**********************************\n",
      "attacked module: stage_1.5.conv_a\n",
      "attacked module: stage_3.2.conv_a\n",
      "attacked weight index: 32967\n",
      "weight before attack: tensor(-0.0026, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [010/020]   Attack Time 12.866 (14.106)\n",
      "Loss before attack: 27680749649920.0000\n",
      "Loss after attack: 177371143471104.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 19\n",
      "**Test** MCC: 0.001. Val_Loss: 179949893930502.875\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.503 (6.480)\n",
      "**********************************\n",
      "attacked module: stage_1.5.conv_b\n",
      "attacked module: stage_3.14.conv_a\n",
      "attacked weight index: 16527\n",
      "weight before attack: tensor(-0.0161, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [011/020]   Attack Time 12.966 (14.002)\n",
      "Loss before attack: 177371143471104.0000\n",
      "Loss after attack: 46818321802199040.0000\n",
      "Bit flips: 22\n",
      "Hamming distance: 21\n",
      "**Test** MCC: 0.001. Val_Loss: 47498257843153008.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.462 (6.479)\n",
      "**********************************\n",
      "attacked module: stage_1.10.conv_b\n",
      "attacked module: stage_2.7.conv_b\n",
      "attacked weight index: 10818\n",
      "weight before attack: tensor(0.0640, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [012/020]   Attack Time 12.954 (13.915)\n",
      "Loss before attack: 46818321802199040.0000\n",
      "Loss after attack: 269394659636150272.0000\n",
      "Bit flips: 24\n",
      "Hamming distance: 23\n",
      "**Test** MCC: -0.000. Val_Loss: 273299873740293504.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.221 (6.457)\n",
      "**********************************\n",
      "attacked module: stage_1.10.conv_a\n",
      "attacked module: stage_1.2.conv_b\n",
      "attacked weight index: 2948\n",
      "weight before attack: tensor(0.0343, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [013/020]   Attack Time 12.725 (13.823)\n",
      "Loss before attack: 269394659636150272.0000\n",
      "Loss after attack: 52683359129631195136.0000\n",
      "Bit flips: 26\n",
      "Hamming distance: 25\n",
      "**Test** MCC: 0.001. Val_Loss: 53447067605845483520.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.527 (6.463)\n",
      "**********************************\n",
      "attacked module: stage_1.7.conv_b\n",
      "attacked module: stage_2.10.conv_a\n",
      "attacked weight index: 10280\n",
      "weight before attack: tensor(-0.0344, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [014/020]   Attack Time 12.855 (13.754)\n",
      "Loss before attack: 52683359129631195136.0000\n",
      "Loss after attack: 269580864541654253568.0000\n",
      "Bit flips: 28\n",
      "Hamming distance: 27\n",
      "**Test** MCC: 0.000. Val_Loss: 273481619302419824640.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.000.\n",
      "Iteration Time 6.397 (6.458)\n",
      "**********************************\n",
      "attacked module: stage_1.7.conv_a\n",
      "attacked module: stage_3.11.conv_b\n",
      "attacked weight index: 6985\n",
      "weight before attack: tensor(-0.0128, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [015/020]   Attack Time 13.010 (13.705)\n",
      "Loss before attack: 269580864541654253568.0000\n",
      "Loss after attack: 97068334568529985536000.0000\n",
      "Bit flips: 30\n",
      "Hamming distance: 29\n",
      "**Test** MCC: 0.001. Val_Loss: 87492006247136508248064.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.612 (6.468)\n",
      "**********************************\n",
      "attacked module: stage_1.9.conv_b\n",
      "attacked module: stage_2.6.conv_b\n",
      "attacked weight index: 2086\n",
      "weight before attack: tensor(0.2154, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [016/020]   Attack Time 12.902 (13.655)\n",
      "Loss before attack: 86434930524341781135360.0000\n",
      "Loss after attack: 424164036914110221254656.0000\n",
      "Bit flips: 32\n",
      "Hamming distance: 31\n",
      "**Test** MCC: 0.001. Val_Loss: 429352812593940470431744.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.584 (6.475)\n",
      "**********************************\n",
      "attacked module: stage_1.9.conv_a\n",
      "attacked module: stage_2.2.conv_a\n",
      "attacked weight index: 6366\n",
      "weight before attack: tensor(0.0425, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [017/020]   Attack Time 13.008 (13.617)\n",
      "Loss before attack: 424164036914110221254656.0000\n",
      "Loss after attack: 86603109994464949382938624.0000\n",
      "Bit flips: 34\n",
      "Hamming distance: 33\n",
      "**Test** MCC: 0.001. Val_Loss: 87666775194294585340723200.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.316 (6.466)\n",
      "**********************************\n",
      "attacked module: stage_1.0.conv_b\n",
      "attacked module: stage_1.1.conv_b\n",
      "attacked weight index: 1038\n",
      "weight before attack: tensor(0.0336, device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "Iteration: [018/020]   Attack Time 13.043 (13.585)\n",
      "Loss before attack: 86603109994464949382938624.0000\n",
      "Loss after attack: 412951321591256046974795776.0000\n",
      "Bit flips: 36\n",
      "Hamming distance: 35\n",
      "**Test** MCC: 0.001. Val_Loss: 423786134042203842550956032.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.434 (6.464)\n",
      "**********************************\n",
      "attacked module: stage_1.0.conv_a\n",
      "attacked module: stage_1.10.conv_b\n",
      "attacked weight index: 641\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "Iteration: [019/020]   Attack Time 13.604 (13.586)\n",
      "Loss before attack: 412951321591256046974795776.0000\n",
      "Loss after attack: 43326956901691735692426608640.0000\n",
      "Bit flips: 38\n",
      "Hamming distance: 37\n",
      "**Test** MCC: 0.001. Val_Loss: 43838245674550336954061291520.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.673 (6.475)\n",
      "**********************************\n",
      "attacked module: stage_3.3.conv_b\n",
      "attacked module: stage_1.1.conv_a\n",
      "attacked weight index: 2717\n",
      "weight before attack: tensor(0.1175, device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "Iteration: [020/020]   Attack Time 16.291 (13.721)\n",
      "Loss before attack: 43326956901691735692426608640.0000\n",
      "Loss after attack: 198445834421048980778348707840.0000\n",
      "Bit flips: 40\n",
      "Hamming distance: 39\n",
      "**Test** MCC: 0.000. Val_Loss: 200767131471341996131760472064.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.487 (6.476)\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/MCC_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/ACC_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/TPR_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/F1_PBS_to_RandomFlip_attack.png\n",
      "MCC after 100 times PBS to Random: 0.0003965330324417396\n",
      "Accuracy after 100 times PBS to Random: 0.0038168989531053594\n",
      "TPR after 100 times PBS to Random: 0.02713533626606152\n",
      "F1-score after 100 times PBS to Random: 0.0005426244215392134\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"PBS_to_RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_PBS_to_RandomFlip_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,\n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 3,                  # Chế độ tấn công PBS -> random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score( trained_model,test_loader)\n",
    "# print(f\"\\nMCC after 100 times PBS to Random: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times PBS to Random: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times PBS to Random: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times PBS to Random: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times PBS to Random: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "799e64b0-3b50-4bfa-9193-95cda8da9a48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.749. Val_Loss: 0.461\n",
      "ACC: 0.767.\n",
      "TPR: 0.711.\n",
      "F1-score: 0.701.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: stage_2.11.conv_b\n",
      "attacked weight index: 3091\n",
      "weight before attack: tensor(-0.2004, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: fc1\n",
      "Iteration: [001/020]   Attack Time 13.850 (13.850)\n",
      "Loss before attack: 0.3394\n",
      "Loss after attack: 93.1466\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: -0.001. Val_Loss: 98.204\n",
      "ACC: 0.038.\n",
      "TPR: 0.052.\n",
      "F1-score: 0.013.\n",
      "Iteration Time 6.629 (6.629)\n",
      "**********************************\n",
      "attacked module: stage_1.11.conv_a\n",
      "attacked weight index: 419\n",
      "weight before attack: tensor(-0.0358, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "attacked module: stage_1.6.conv_a\n",
      "Iteration: [002/020]   Attack Time 13.347 (13.598)\n",
      "Loss before attack: 93.1466\n",
      "Loss after attack: 2464.9836\n",
      "Bit flips: 4\n",
      "Hamming distance: 4\n",
      "**Test** MCC: -0.003. Val_Loss: 2602.482\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.006.\n",
      "Iteration Time 6.400 (6.515)\n",
      "**********************************\n",
      "attacked module: stage_2.1.conv_b\n",
      "attacked weight index: 5333\n",
      "weight before attack: tensor(-0.0288, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "attacked module: stage_1.6.conv_b\n",
      "Iteration: [003/020]   Attack Time 13.010 (13.402)\n",
      "Loss before attack: 2464.9836\n",
      "Loss after attack: 169271.3281\n",
      "Bit flips: 6\n",
      "Hamming distance: 6\n",
      "**Test** MCC: 0.007. Val_Loss: 178710.041\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.005.\n",
      "Iteration Time 6.383 (6.471)\n",
      "**********************************\n",
      "attacked module: stage_1.14.conv_b\n",
      "attacked weight index: 1982\n",
      "weight before attack: tensor(-0.0043, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "attacked module: stage_1.5.conv_a\n",
      "Iteration: [004/020]   Attack Time 13.016 (13.306)\n",
      "Loss before attack: 169271.3281\n",
      "Loss after attack: 5784052.5000\n",
      "Bit flips: 8\n",
      "Hamming distance: 8\n",
      "**Test** MCC: 0.007. Val_Loss: 6105925.298\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.005.\n",
      "Iteration Time 6.485 (6.474)\n",
      "**********************************\n",
      "attacked module: stage_3.4.conv_b\n",
      "attacked weight index: 48236\n",
      "weight before attack: tensor(-0.0207, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "attacked module: stage_1.5.conv_b\n",
      "Iteration: [005/020]   Attack Time 12.629 (13.170)\n",
      "Loss before attack: 5784052.5000\n",
      "Loss after attack: 337046944.0000\n",
      "Bit flips: 10\n",
      "Hamming distance: 10\n",
      "**Test** MCC: 0.007. Val_Loss: 355812196.548\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.005.\n",
      "Iteration Time 6.572 (6.494)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_b\n",
      "attacked weight index: 463\n",
      "weight before attack: tensor(-0.0222, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "attacked module: stage_1.4.conv_a\n",
      "Iteration: [006/020]   Attack Time 12.666 (13.086)\n",
      "Loss before attack: 337047168.0000\n",
      "Loss after attack: 10341047296.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 12\n",
      "**Test** MCC: 0.008. Val_Loss: 10913601324.208\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.005.\n",
      "Iteration Time 6.470 (6.490)\n",
      "**********************************\n",
      "attacked module: stage_2.15.conv_a\n",
      "attacked weight index: 3991\n",
      "weight before attack: tensor(0.0083, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "attacked module: stage_1.4.conv_b\n",
      "Iteration: [007/020]   Attack Time 12.993 (13.073)\n",
      "Loss before attack: 10341047296.0000\n",
      "Loss after attack: 596245807104.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 14\n",
      "**Test** MCC: 0.008. Val_Loss: 629244369837.217\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.005.\n",
      "Iteration Time 6.388 (6.475)\n",
      "**********************************\n",
      "attacked module: stage_3.7.conv_b\n",
      "attacked weight index: 5339\n",
      "weight before attack: tensor(-0.0195, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "attacked module: stage_1.3.conv_b\n",
      "Iteration: [008/020]   Attack Time 12.850 (13.045)\n",
      "Loss before attack: 596245807104.0000\n",
      "Loss after attack: 21344154550272.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 16\n",
      "**Test** MCC: 0.003. Val_Loss: 22528724163610.805\n",
      "ACC: 0.039.\n",
      "TPR: 0.053.\n",
      "F1-score: 0.013.\n",
      "Iteration Time 6.415 (6.468)\n",
      "**********************************\n",
      "attacked module: stage_1.15.conv_b\n",
      "attacked weight index: 3013\n",
      "weight before attack: tensor(-0.1914, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "attacked module: stage_1.3.conv_a\n",
      "Iteration: [009/020]   Attack Time 12.983 (13.038)\n",
      "Loss before attack: 21344154550272.0000\n",
      "Loss after attack: 1900286671060992.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 18\n",
      "**Test** MCC: 0.010. Val_Loss: 2003987477021371.500\n",
      "ACC: 0.031.\n",
      "TPR: 0.048.\n",
      "F1-score: 0.005.\n",
      "Iteration Time 6.702 (6.494)\n",
      "**********************************\n",
      "attacked module: stage_1.2.conv_a\n",
      "attacked weight index: 2208\n",
      "weight before attack: tensor(0.0658, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "attacked module: stage_1.1.conv_b\n",
      "Iteration: [010/020]   Attack Time 13.146 (13.049)\n",
      "Loss before attack: 1900286671060992.0000\n",
      "Loss after attack: 48320228915937280.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 20\n",
      "**Test** MCC: 0.012. Val_Loss: 50964084628301024.000\n",
      "ACC: 0.034.\n",
      "TPR: 0.050.\n",
      "F1-score: 0.008.\n",
      "Iteration Time 6.767 (6.521)\n",
      "**********************************\n",
      "attacked module: stage_1.11.conv_b\n",
      "attacked weight index: 1705\n",
      "weight before attack: tensor(0.1027, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "attacked module: stage_1.1.conv_a\n",
      "Iteration: [011/020]   Attack Time 13.198 (13.062)\n",
      "Loss before attack: 48310835822460928.0000\n",
      "Loss after attack: 5747966964303659008.0000\n",
      "Bit flips: 22\n",
      "Hamming distance: 22\n",
      "**Test** MCC: -0.001. Val_Loss: 6069201573001614336.000\n",
      "ACC: 0.028.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.003.\n",
      "Iteration Time 6.495 (6.519)\n",
      "**********************************\n",
      "attacked module: stage_3.9.conv_b\n",
      "attacked weight index: 25885\n",
      "weight before attack: tensor(0.1171, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [012/020]   Attack Time 13.163 (13.071)\n",
      "Loss before attack: 5747966964303659008.0000\n",
      "Loss after attack: 123342317202423414784.0000\n",
      "Bit flips: 24\n",
      "Hamming distance: 23\n",
      "**Test** MCC: -0.003. Val_Loss: 130960586053363924992.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.541 (6.520)\n",
      "**********************************\n",
      "attacked module: stage_3.14.conv_a\n",
      "attacked weight index: 33810\n",
      "weight before attack: tensor(0.0277, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "attacked module: stage_3.1.conv_a\n",
      "Iteration: [013/020]   Attack Time 16.711 (13.351)\n",
      "Loss before attack: 123342317202423414784.0000\n",
      "Loss after attack: 1676862403955782582272.0000\n",
      "Bit flips: 26\n",
      "Hamming distance: 25\n",
      "**Test** MCC: -0.001. Val_Loss: 1811510947243330109440.000\n",
      "ACC: 0.028.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.003.\n",
      "Iteration Time 6.684 (6.533)\n",
      "**********************************\n",
      "attacked module: stage_3.10.conv_a\n",
      "attacked weight index: 27826\n",
      "weight before attack: tensor(0.2204, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "attacked module: stage_3.1.conv_b\n",
      "Iteration: [014/020]   Attack Time 16.799 (13.597)\n",
      "Loss before attack: 1676862403955782582272.0000\n",
      "Loss after attack: 108372198496444090417152.0000\n",
      "Bit flips: 28\n",
      "Hamming distance: 27\n",
      "**Test** MCC: -0.001. Val_Loss: 118759844496593922293760.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.000.\n",
      "Iteration Time 6.679 (6.543)\n",
      "**********************************\n",
      "attacked module: stage_1.12.conv_a\n",
      "attacked weight index: 294\n",
      "weight before attack: tensor(-0.1310, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "attacked module: stage_3.12.conv_a\n",
      "Iteration: [015/020]   Attack Time 16.863 (13.815)\n",
      "Loss before attack: 108372198496444090417152.0000\n",
      "Loss after attack: 902963510722064124215296.0000\n",
      "Bit flips: 30\n",
      "Hamming distance: 29\n",
      "**Test** MCC: -0.000. Val_Loss: 937187735256772949049344.000\n",
      "ACC: 0.008.\n",
      "TPR: 0.040.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.491 (6.540)\n",
      "**********************************\n",
      "attacked module: stage_1.0.conv_a\n",
      "attacked weight index: 2953\n",
      "weight before attack: tensor(-0.1021, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: stage_3.3.conv_a\n",
      "Iteration: [016/020]   Attack Time 16.563 (13.987)\n",
      "Loss before attack: 900598796658521443139584.0000\n",
      "Loss after attack: 5901313461060734849908736.0000\n",
      "Bit flips: 32\n",
      "Hamming distance: 31\n",
      "**Test** MCC: -0.000. Val_Loss: 6190417015075128335138816.000\n",
      "ACC: 0.004.\n",
      "TPR: 0.027.\n",
      "F1-score: 0.000.\n",
      "Iteration Time 6.545 (6.540)\n",
      "**********************************\n",
      "attacked module: stage_2.2.conv_a\n",
      "attacked weight index: 4950\n",
      "weight before attack: tensor(-0.0170, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "attacked module: stage_3.3.conv_b\n",
      "Iteration: [017/020]   Attack Time 16.696 (14.146)\n",
      "Loss before attack: 5901313461060734849908736.0000\n",
      "Loss after attack: 556536350242433506461351936.0000\n",
      "Bit flips: 34\n",
      "Hamming distance: 33\n",
      "**Test** MCC: -0.000. Val_Loss: 577457449941222382389690368.000\n",
      "ACC: 0.008.\n",
      "TPR: 0.040.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.713 (6.550)\n",
      "**********************************\n",
      "attacked module: stage_1.15.conv_b\n",
      "attacked weight index: 918\n",
      "weight before attack: tensor(0.0548, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "attacked module: stage_1.10.conv_b\n",
      "Iteration: [018/020]   Attack Time 13.026 (14.084)\n",
      "Loss before attack: 556536350242433506461351936.0000\n",
      "Loss after attack: 3202561669877508886868525056.0000\n",
      "Bit flips: 36\n",
      "Hamming distance: 35\n",
      "**Test** MCC: -0.000. Val_Loss: 3322854156321451940054564864.000\n",
      "ACC: 0.008.\n",
      "TPR: 0.040.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.705 (6.559)\n",
      "**********************************\n",
      "attacked module: stage_2.8.conv_a\n",
      "attacked weight index: 6149\n",
      "weight before attack: tensor(-0.0393, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: stage_1.10.conv_a\n",
      "Iteration: [019/020]   Attack Time 12.927 (14.023)\n",
      "Loss before attack: 3202561669877508886868525056.0000\n",
      "Loss after attack: 626472764394945977936435478528.0000\n",
      "Bit flips: 38\n",
      "Hamming distance: 37\n",
      "**Test** MCC: -0.000. Val_Loss: 649945594660687414800311910400.000\n",
      "ACC: 0.008.\n",
      "TPR: 0.040.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.656 (6.564)\n",
      "**********************************\n",
      "attacked module: stage_3.13.conv_a\n",
      "attacked weight index: 11333\n",
      "weight before attack: tensor(-0.0349, device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "attacked module: stage_1.2.conv_b\n",
      "Iteration: [020/020]   Attack Time 13.292 (13.986)\n",
      "Loss before attack: 626472764394945977936435478528.0000\n",
      "Loss after attack: 3513607797249577761473227128832.0000\n",
      "Bit flips: 40\n",
      "Hamming distance: 39\n",
      "**Test** MCC: 0.002. Val_Loss: 3645455344576847042144840450048.000\n",
      "ACC: 0.008.\n",
      "TPR: 0.040.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 6.422 (6.557)\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/MCC_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/ACC_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/TPR_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/F1_RandomFlip_to_PBS_attack.png\n",
      "MCC after 100 times random to PBS: 0.0015080800100471983\n",
      "Accuracy after 100 times random to PBS: 0.008349466459917973\n",
      "TPR after 100 times random to PBS: 0.040041789363860866\n",
      "F1-score after 100 times random to PBS: 0.0009268109123750712\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"RandomFlip_to_PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_RandomFlip_to_PBS_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 4,                  # Chế độ tấn công Random -> PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score( trained_model,test_loader)\n",
    "# print(f\"\\nMCC after 100 times random to PBS: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times random to PBS: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times random to PBS: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times random to PBS: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times random to PBS: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697a5c3-03a5-41bf-ab93-fb316b41e52f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Train CustomModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fb16fd3-7699-4cb4-8d3a-6e981aeffaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = CustomModel2().to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# best_val_loss = float('inf')\n",
    "# patience = 10  # Số epoch để chờ trước khi dừng\n",
    "# counter = 0\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# # Vòng lặp huấn luyện\n",
    "# best_val_loss = float('inf')\n",
    "# best_mcc = -1  # Khởi tạo MCC tốt nhất\n",
    "\n",
    "# # Vòng lặp huấn luyện\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_mcc, train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "#     val_mcc, val_loss, output_summary = validate(test_loader, model, criterion, summary_output=True)\n",
    "#     scheduler.step(val_loss)\n",
    "\n",
    "#     if val_loss < best_val_loss:\n",
    "#         best_val_loss = val_loss\n",
    "#         best_mcc = val_mcc  # Lưu MCC tốt nhất\n",
    "#         counter = 0\n",
    "\n",
    "#         save_dir = \"CustomModel2\"\n",
    "#         save_path = os.path.join(save_dir, \"model.pth\")\n",
    "\n",
    "#         if not os.path.exists(save_dir):\n",
    "#             os.makedirs(save_dir)\n",
    "\n",
    "#         torch.save(model.state_dict(), save_path)\n",
    "#     else:\n",
    "#         counter += 1\n",
    "#         if counter >= patience:\n",
    "#             print(\"Early stopping triggered\")\n",
    "#             break\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f}, Train MCC: {train_mcc:.4f}\")\n",
    "#     print(f\"Validation Loss: {val_loss:.4f}, Validation MCC: {val_mcc:.4f}\")\n",
    "# print(f\"Best MCC during training: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1da615-4cac-4211-aa06-e9fa9f329505",
   "metadata": {},
   "source": [
    "## Attack second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dcfa057-0619-4fa5-aed2-8b01848a50f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC before attack: 0.713019661995725\n",
      "Accuracy before attack: 0.725146574424942\n",
      "TPR before attack: 0.5750286438492276\n",
      "F1-score before attack: 0.5156814372130539\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# best_mcc = validate_score(trained_model, test_loader)\n",
    "# print(f\"MCC before attack: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC before attack: {results['MCC']}\")\n",
    "print(f\"Accuracy before attack: {results['Accuracy']}\")\n",
    "print(f\"TPR before attack: {results['TPR']}\")\n",
    "print(f\"F1-score before attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35349df9-2ad5-4463-ab65-d64b1f095f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.713. Val_Loss: 2.851\n",
      "ACC: 0.725.\n",
      "TPR: 0.575.\n",
      "F1-score: 0.516.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [001/020]   Attack Time 2.585 (2.585)\n",
      "Loss before attack: 2.5922\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.433 (2.433)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [002/020]   Attack Time 2.278 (2.432)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 101\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.491 (2.462)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [003/020]   Attack Time 2.360 (2.408)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 201\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.511 (2.478)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [004/020]   Attack Time 2.241 (2.366)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 301\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.506 (2.485)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [005/020]   Attack Time 2.324 (2.358)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 401\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.463 (2.481)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [006/020]   Attack Time 2.251 (2.340)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 501\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.415 (2.470)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [007/020]   Attack Time 2.351 (2.341)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 601\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.467 (2.469)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [008/020]   Attack Time 2.416 (2.351)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 701\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.407 (2.462)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [009/020]   Attack Time 2.384 (2.355)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 801\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.397 (2.454)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [010/020]   Attack Time 2.318 (2.351)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 901\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.417 (2.451)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [011/020]   Attack Time 2.359 (2.352)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1001\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.519 (2.457)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [012/020]   Attack Time 2.346 (2.351)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1101\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.509 (2.461)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [013/020]   Attack Time 2.325 (2.349)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1201\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.520 (2.466)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [014/020]   Attack Time 2.315 (2.347)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1301\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.564 (2.473)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [015/020]   Attack Time 2.248 (2.340)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1401\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.592 (2.481)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [016/020]   Attack Time 2.366 (2.342)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1501\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.427 (2.477)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [017/020]   Attack Time 2.285 (2.338)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1601\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.714 (2.491)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [018/020]   Attack Time 2.461 (2.345)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1701\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.551 (2.495)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [019/020]   Attack Time 2.336 (2.345)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1801\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.530 (2.496)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [020/020]   Attack Time 2.300 (2.342)\n",
      "Loss before attack: 2.6756\n",
      "Loss after attack: 2.6756\n",
      "Bit flips: 1901\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.408 (2.492)\n",
      "Plot saved as CustomModel2/PBS_attack/MCC_PBS_attack.png\n",
      "Plot saved as CustomModel2/PBS_attack/ACC_PBS_attack.png\n",
      "Plot saved as CustomModel2/PBS_attack/TPR_PBS_attack.png\n",
      "Plot saved as CustomModel2/PBS_attack/F1_PBS_attack.png\n",
      "MCC after 100 times PBS attack: 0.6612743462999665\n",
      "Accuracy after 100 times PBS attack: 0.677004101331327\n",
      "TPR after 100 times PBS attack: 0.4829373339200396\n",
      "F1-score after 100 times PBS attack: 0.4354109642091606\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_PBS_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_attack.csv\")\n",
    "\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 1,                  # Chế độ tấn công PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score(trained_model, test_loader)\n",
    "# print(f\"\\nMCC after 100 times PBS: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times PBS attack: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times PBS attack: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times PBS attack: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times PBS attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a700d594-b183-473f-9a0f-03aec9ccfdb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.713. Val_Loss: 2.851\n",
      "ACC: 0.725.\n",
      "TPR: 0.575.\n",
      "F1-score: 0.516.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1482\n",
      "weight before attack: tensor(0.0296, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [001/020]   Attack Time 2.259 (2.259)\n",
      "Bit flips: 1\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.713. Val_Loss: 2.851\n",
      "ACC: 0.725.\n",
      "TPR: 0.575.\n",
      "F1-score: 0.516.\n",
      "Iteration Time 2.483 (2.483)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1893\n",
      "weight before attack: tensor(0.0341, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [002/020]   Attack Time 2.294 (2.277)\n",
      "Bit flips: 2\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.551. Val_Loss: 3.021\n",
      "ACC: 0.555.\n",
      "TPR: 0.397.\n",
      "F1-score: 0.340.\n",
      "Iteration Time 2.455 (2.469)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 3207\n",
      "weight before attack: tensor(0.0167, device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "Iteration: [003/020]   Attack Time 2.245 (2.266)\n",
      "Bit flips: 3\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.551. Val_Loss: 3.021\n",
      "ACC: 0.555.\n",
      "TPR: 0.397.\n",
      "F1-score: 0.340.\n",
      "Iteration Time 2.358 (2.432)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 3045\n",
      "weight before attack: tensor(0.0247, device='cuda:0')\n",
      "weight after attack: tensor(1024., device='cuda:0')\n",
      "Iteration: [004/020]   Attack Time 2.276 (2.269)\n",
      "Bit flips: 4\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.091. Val_Loss: 3.516\n",
      "ACC: 0.058.\n",
      "TPR: 0.120.\n",
      "F1-score: 0.089.\n",
      "Iteration Time 2.422 (2.430)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 3294\n",
      "weight before attack: tensor(-0.0325, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [005/020]   Attack Time 2.167 (2.248)\n",
      "Bit flips: 5\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.091. Val_Loss: 3.516\n",
      "ACC: 0.058.\n",
      "TPR: 0.120.\n",
      "F1-score: 0.089.\n",
      "Iteration Time 2.602 (2.464)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 3325\n",
      "weight before attack: tensor(0.0220, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [006/020]   Attack Time 2.185 (2.238)\n",
      "Bit flips: 6\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.022. Val_Loss: 3.560\n",
      "ACC: 0.014.\n",
      "TPR: 0.028.\n",
      "F1-score: 0.025.\n",
      "Iteration Time 2.498 (2.470)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 753\n",
      "weight before attack: tensor(0.0169, device='cuda:0')\n",
      "weight after attack: tensor(4096., device='cuda:0')\n",
      "Iteration: [007/020]   Attack Time 2.187 (2.230)\n",
      "Bit flips: 7\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.000. Val_Loss: 3.575\n",
      "ACC: 0.001.\n",
      "TPR: 0.004.\n",
      "F1-score: 0.001.\n",
      "Iteration Time 2.468 (2.469)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2234\n",
      "weight before attack: tensor(0.0391, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [008/020]   Attack Time 2.258 (2.234)\n",
      "Bit flips: 8\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.041. Val_Loss: 3.547\n",
      "ACC: 0.028.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 2.559 (2.480)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 468\n",
      "weight before attack: tensor(0.0118, device='cuda:0')\n",
      "weight after attack: tensor(2048., device='cuda:0')\n",
      "Iteration: [009/020]   Attack Time 2.144 (2.224)\n",
      "Bit flips: 9\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.041. Val_Loss: 3.547\n",
      "ACC: 0.028.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 2.420 (2.474)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 3094\n",
      "weight before attack: tensor(-0.0075, device='cuda:0')\n",
      "weight after attack: tensor(-4097., device='cuda:0')\n",
      "Iteration: [010/020]   Attack Time 2.232 (2.225)\n",
      "Bit flips: 10\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.041. Val_Loss: 3.547\n",
      "ACC: 0.028.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 2.393 (2.466)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 960\n",
      "weight before attack: tensor(-0.0070, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [011/020]   Attack Time 2.304 (2.232)\n",
      "Bit flips: 11\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.041. Val_Loss: 3.547\n",
      "ACC: 0.028.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 2.416 (2.461)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2280\n",
      "weight before attack: tensor(-0.0042, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "Iteration: [012/020]   Attack Time 2.256 (2.234)\n",
      "Bit flips: 12\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.041. Val_Loss: 3.547\n",
      "ACC: 0.028.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 2.466 (2.462)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1505\n",
      "weight before attack: tensor(0.0091, device='cuda:0')\n",
      "weight after attack: tensor(1024., device='cuda:0')\n",
      "Iteration: [013/020]   Attack Time 2.294 (2.239)\n",
      "Bit flips: 13\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.034. Val_Loss: 3.547\n",
      "ACC: 0.028.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 2.421 (2.458)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2806\n",
      "weight before attack: tensor(-0.0177, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [014/020]   Attack Time 2.246 (2.239)\n",
      "Bit flips: 14\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.034. Val_Loss: 3.547\n",
      "ACC: 0.028.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 2.500 (2.461)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1140\n",
      "weight before attack: tensor(-0.0280, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [015/020]   Attack Time 2.201 (2.237)\n",
      "Bit flips: 15\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.034. Val_Loss: 3.547\n",
      "ACC: 0.028.\n",
      "TPR: 0.043.\n",
      "F1-score: 0.015.\n",
      "Iteration Time 2.549 (2.467)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 443\n",
      "weight before attack: tensor(-0.0069, device='cuda:0')\n",
      "weight after attack: tensor(32767., device='cuda:0')\n",
      "Iteration: [016/020]   Attack Time 2.234 (2.236)\n",
      "Bit flips: 16\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.034. Val_Loss: 3.547\n",
      "ACC: 0.029.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.017.\n",
      "Iteration Time 2.547 (2.472)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2916\n",
      "weight before attack: tensor(-0.0347, device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "Iteration: [017/020]   Attack Time 2.186 (2.233)\n",
      "Bit flips: 17\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.034. Val_Loss: 3.547\n",
      "ACC: 0.029.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.017.\n",
      "Iteration Time 2.503 (2.474)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 276\n",
      "weight before attack: tensor(0.0237, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [018/020]   Attack Time 2.184 (2.231)\n",
      "Bit flips: 18\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.034. Val_Loss: 3.547\n",
      "ACC: 0.029.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.017.\n",
      "Iteration Time 2.468 (2.474)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1010\n",
      "weight before attack: tensor(0.0415, device='cuda:0')\n",
      "weight after attack: tensor(128., device='cuda:0')\n",
      "Iteration: [019/020]   Attack Time 2.162 (2.227)\n",
      "Bit flips: 19\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.034. Val_Loss: 3.547\n",
      "ACC: 0.029.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.017.\n",
      "Iteration Time 2.376 (2.469)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1880\n",
      "weight before attack: tensor(0.0174, device='cuda:0')\n",
      "weight after attack: tensor(256., device='cuda:0')\n",
      "Iteration: [020/020]   Attack Time 2.283 (2.230)\n",
      "Bit flips: 20\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.034. Val_Loss: 3.547\n",
      "ACC: 0.029.\n",
      "TPR: 0.046.\n",
      "F1-score: 0.017.\n",
      "Iteration Time 2.403 (2.465)\n",
      "Plot saved as CustomModel2/RandomFlip_attack/MCC_RandomFlip_attack.png\n",
      "Plot saved as CustomModel2/RandomFlip_attack/ACC_RandomFlip_attack.png\n",
      "Plot saved as CustomModel2/RandomFlip_attack/TPR_RandomFlip_attack.png\n",
      "Plot saved as CustomModel2/RandomFlip_attack/F1_RandomFlip_attack.png\n",
      "MCC after 100 times random attack: 0.03445222240785396\n",
      "Accuracy after 100 times random attack: 0.028635917386158238\n",
      "TPR after 100 times random attack: 0.0457498337637604\n",
      "F1-score after 100 times random attack: 0.017024099420200375\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_RandomFlip_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 2,                  # Chế độ tấn công random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "\n",
    "# best_mcc = validate_score(trained_model ,test_loader)\n",
    "# print(f\"\\nMCC after 100 times Random attack: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times random attack: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times random attack: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times random attack: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times random attack: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59c7df1b-f79c-407c-a2a7-0b26256de0e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.713. Val_Loss: 2.851\n",
      "ACC: 0.725.\n",
      "TPR: 0.575.\n",
      "F1-score: 0.516.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 33\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [001/020]   Attack Time 4.750 (4.750)\n",
      "Loss before attack: 2.5853\n",
      "Loss after attack: 2.6838\n",
      "Bit flips: 2\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.661. Val_Loss: 2.899\n",
      "ACC: 0.677.\n",
      "TPR: 0.483.\n",
      "F1-score: 0.435.\n",
      "Iteration Time 2.525 (2.525)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 913\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [002/020]   Attack Time 4.617 (4.684)\n",
      "Loss before attack: 2.6838\n",
      "Loss after attack: 2.6838\n",
      "Bit flips: 103\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.233. Val_Loss: 3.366\n",
      "ACC: 0.210.\n",
      "TPR: 0.272.\n",
      "F1-score: 0.223.\n",
      "Iteration Time 2.423 (2.474)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 2052\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "Iteration: [003/020]   Attack Time 4.621 (4.663)\n",
      "Loss before attack: 3.3022\n",
      "Loss after attack: 3.3022\n",
      "Bit flips: 204\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.233. Val_Loss: 3.366\n",
      "ACC: 0.210.\n",
      "TPR: 0.272.\n",
      "F1-score: 0.223.\n",
      "Iteration Time 2.332 (2.427)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 1417\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "Iteration: [004/020]   Attack Time 4.461 (4.612)\n",
      "Loss before attack: 3.3022\n",
      "Loss after attack: 3.3022\n",
      "Bit flips: 305\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.233. Val_Loss: 3.366\n",
      "ACC: 0.210.\n",
      "TPR: 0.272.\n",
      "F1-score: 0.223.\n",
      "Iteration Time 2.653 (2.483)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 2921\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [005/020]   Attack Time 4.577 (4.605)\n",
      "Loss before attack: 3.3022\n",
      "Loss after attack: 3.3022\n",
      "Bit flips: 406\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.233. Val_Loss: 3.366\n",
      "ACC: 0.210.\n",
      "TPR: 0.272.\n",
      "F1-score: 0.223.\n",
      "Iteration Time 2.472 (2.481)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 2455\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [006/020]   Attack Time 4.500 (4.588)\n",
      "Loss before attack: 3.3022\n",
      "Loss after attack: 3.3022\n",
      "Bit flips: 507\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.034. Val_Loss: 3.543\n",
      "ACC: 0.033.\n",
      "TPR: 0.080.\n",
      "F1-score: 0.043.\n",
      "Iteration Time 2.436 (2.473)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 3291\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-2049., device='cuda:0')\n",
      "Iteration: [007/020]   Attack Time 4.591 (4.588)\n",
      "Loss before attack: 3.5483\n",
      "Loss after attack: 3.5483\n",
      "Bit flips: 608\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.034. Val_Loss: 3.543\n",
      "ACC: 0.033.\n",
      "TPR: 0.080.\n",
      "F1-score: 0.043.\n",
      "Iteration Time 2.499 (2.477)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 2371\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(-32768., device='cuda:0')\n",
      "Iteration: [008/020]   Attack Time 4.389 (4.563)\n",
      "Loss before attack: 3.5483\n",
      "Loss after attack: 3.5483\n",
      "Bit flips: 709\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.034. Val_Loss: 3.543\n",
      "ACC: 0.033.\n",
      "TPR: 0.080.\n",
      "F1-score: 0.043.\n",
      "Iteration Time 2.490 (2.479)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 2442\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-129., device='cuda:0')\n",
      "Iteration: [009/020]   Attack Time 4.727 (4.581)\n",
      "Loss before attack: 3.5483\n",
      "Loss after attack: 3.5483\n",
      "Bit flips: 810\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.044. Val_Loss: 3.483\n",
      "ACC: 0.092.\n",
      "TPR: 0.144.\n",
      "F1-score: 0.112.\n",
      "Iteration Time 2.394 (2.469)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 374\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [010/020]   Attack Time 4.614 (4.585)\n",
      "Loss before attack: 3.4702\n",
      "Loss after attack: 3.4702\n",
      "Bit flips: 911\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.044. Val_Loss: 3.483\n",
      "ACC: 0.092.\n",
      "TPR: 0.144.\n",
      "F1-score: 0.112.\n",
      "Iteration Time 2.580 (2.480)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 169\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-1025., device='cuda:0')\n",
      "Iteration: [011/020]   Attack Time 4.517 (4.578)\n",
      "Loss before attack: 3.4702\n",
      "Loss after attack: 3.4702\n",
      "Bit flips: 1012\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.037. Val_Loss: 3.488\n",
      "ACC: 0.088.\n",
      "TPR: 0.136.\n",
      "F1-score: 0.102.\n",
      "Iteration Time 2.423 (2.475)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 1977\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(-32768., device='cuda:0')\n",
      "Iteration: [012/020]   Attack Time 4.616 (4.581)\n",
      "Loss before attack: 3.4741\n",
      "Loss after attack: 3.4741\n",
      "Bit flips: 1113\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.037. Val_Loss: 3.488\n",
      "ACC: 0.088.\n",
      "TPR: 0.136.\n",
      "F1-score: 0.102.\n",
      "Iteration Time 2.460 (2.474)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 2098\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "Iteration: [013/020]   Attack Time 4.668 (4.588)\n",
      "Loss before attack: 3.4741\n",
      "Loss after attack: 3.4741\n",
      "Bit flips: 1214\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.012. Val_Loss: 3.511\n",
      "ACC: 0.065.\n",
      "TPR: 0.075.\n",
      "F1-score: 0.042.\n",
      "Iteration Time 2.488 (2.475)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 3333\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-1025., device='cuda:0')\n",
      "Iteration: [014/020]   Attack Time 4.597 (4.589)\n",
      "Loss before attack: 3.4858\n",
      "Loss after attack: 3.4858\n",
      "Bit flips: 1315\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.012. Val_Loss: 3.511\n",
      "ACC: 0.065.\n",
      "TPR: 0.075.\n",
      "F1-score: 0.042.\n",
      "Iteration Time 2.467 (2.474)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 1853\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-513., device='cuda:0')\n",
      "Iteration: [015/020]   Attack Time 4.632 (4.592)\n",
      "Loss before attack: 3.4858\n",
      "Loss after attack: 3.4858\n",
      "Bit flips: 1416\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.012. Val_Loss: 3.511\n",
      "ACC: 0.065.\n",
      "TPR: 0.075.\n",
      "F1-score: 0.042.\n",
      "Iteration Time 2.398 (2.469)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 408\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(16384., device='cuda:0')\n",
      "Iteration: [016/020]   Attack Time 4.537 (4.588)\n",
      "Loss before attack: 3.4858\n",
      "Loss after attack: 3.4858\n",
      "Bit flips: 1517\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.012. Val_Loss: 3.511\n",
      "ACC: 0.065.\n",
      "TPR: 0.075.\n",
      "F1-score: 0.042.\n",
      "Iteration Time 2.556 (2.475)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 2352\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8192., device='cuda:0')\n",
      "Iteration: [017/020]   Attack Time 4.556 (4.586)\n",
      "Loss before attack: 3.4858\n",
      "Loss after attack: 3.4858\n",
      "Bit flips: 1618\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.010. Val_Loss: 3.514\n",
      "ACC: 0.062.\n",
      "TPR: 0.070.\n",
      "F1-score: 0.049.\n",
      "Iteration Time 2.344 (2.467)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 1673\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(4096., device='cuda:0')\n",
      "Iteration: [018/020]   Attack Time 4.586 (4.586)\n",
      "Loss before attack: 3.4975\n",
      "Loss after attack: 3.4975\n",
      "Bit flips: 1719\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.013. Val_Loss: 3.514\n",
      "ACC: 0.061.\n",
      "TPR: 0.070.\n",
      "F1-score: 0.055.\n",
      "Iteration Time 2.458 (2.466)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 1790\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-257., device='cuda:0')\n",
      "Iteration: [019/020]   Attack Time 4.609 (4.588)\n",
      "Loss before attack: 3.4975\n",
      "Loss after attack: 3.4975\n",
      "Bit flips: 1820\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.013. Val_Loss: 3.514\n",
      "ACC: 0.061.\n",
      "TPR: 0.070.\n",
      "F1-score: 0.055.\n",
      "Iteration Time 2.468 (2.467)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 2314\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8192., device='cuda:0')\n",
      "Iteration: [020/020]   Attack Time 4.430 (4.580)\n",
      "Loss before attack: 3.4975\n",
      "Loss after attack: 3.4975\n",
      "Bit flips: 1921\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.015. Val_Loss: 3.515\n",
      "ACC: 0.061.\n",
      "TPR: 0.066.\n",
      "F1-score: 0.035.\n",
      "Iteration Time 2.415 (2.464)\n",
      "Plot saved as CustomModel2/PBS_to_RandomFlip_attack/MCC_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel2/PBS_to_RandomFlip_attack/ACC_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel2/PBS_to_RandomFlip_attack/TPR_PBS_to_RandomFlip_attack.png\n",
      "Plot saved as CustomModel2/PBS_to_RandomFlip_attack/F1_PBS_to_RandomFlip_attack.png\n",
      "MCC after 100 times PBS to Random: 0.01451473671999346\n",
      "Accuracy after 100 times PBS to Random: 0.061125434676894\n",
      "TPR after 100 times PBS to Random: 0.06642260276227498\n",
      "F1-score after 100 times PBS to Random: 0.03486209824181525\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"PBS_to_RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_PBS_to_RandomFlip_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 3,                  # Chế độ tấn công PBS -> random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score( trained_model,test_loader)\n",
    "# print(f\"\\nMCC after 100 times PBS to Random: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times PBS to Random: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times PBS to Random: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times PBS to Random: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times PBS to Random: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d875038-92fb-44a5-80f3-36ddbb14431b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.713. Val_Loss: 2.851\n",
      "ACC: 0.725.\n",
      "TPR: 0.575.\n",
      "F1-score: 0.516.\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 697\n",
      "weight before attack: tensor(0.0153, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [001/020]   Attack Time 4.737 (4.737)\n",
      "Loss before attack: 3.3728\n",
      "Loss after attack: 3.1616\n",
      "Bit flips: 101\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.307. Val_Loss: 3.262\n",
      "ACC: 0.313.\n",
      "TPR: 0.246.\n",
      "F1-score: 0.203.\n",
      "Iteration Time 2.434 (2.434)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 428\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [002/020]   Attack Time 4.542 (4.639)\n",
      "Loss before attack: 3.1616\n",
      "Loss after attack: 3.1616\n",
      "Bit flips: 202\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.307. Val_Loss: 3.262\n",
      "ACC: 0.313.\n",
      "TPR: 0.246.\n",
      "F1-score: 0.203.\n",
      "Iteration Time 2.606 (2.520)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1788\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-4097., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [003/020]   Attack Time 4.617 (4.632)\n",
      "Loss before attack: 3.1616\n",
      "Loss after attack: 3.1616\n",
      "Bit flips: 303\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.307. Val_Loss: 3.262\n",
      "ACC: 0.313.\n",
      "TPR: 0.246.\n",
      "F1-score: 0.203.\n",
      "Iteration Time 2.461 (2.501)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2935\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [004/020]   Attack Time 4.550 (4.612)\n",
      "Loss before attack: 3.1616\n",
      "Loss after attack: 3.1616\n",
      "Bit flips: 404\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.307. Val_Loss: 3.262\n",
      "ACC: 0.313.\n",
      "TPR: 0.246.\n",
      "F1-score: 0.203.\n",
      "Iteration Time 2.482 (2.496)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2459\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-4097., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [005/020]   Attack Time 4.582 (4.606)\n",
      "Loss before attack: 3.1616\n",
      "Loss after attack: 3.1616\n",
      "Bit flips: 505\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.307. Val_Loss: 3.262\n",
      "ACC: 0.313.\n",
      "TPR: 0.246.\n",
      "F1-score: 0.203.\n",
      "Iteration Time 2.524 (2.502)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2691\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(128., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [006/020]   Attack Time 4.600 (4.605)\n",
      "Loss before attack: 3.1616\n",
      "Loss after attack: 3.1616\n",
      "Bit flips: 606\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.307. Val_Loss: 3.262\n",
      "ACC: 0.313.\n",
      "TPR: 0.246.\n",
      "F1-score: 0.203.\n",
      "Iteration Time 2.445 (2.492)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 704\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [007/020]   Attack Time 4.596 (4.603)\n",
      "Loss before attack: 3.4077\n",
      "Loss after attack: 3.4077\n",
      "Bit flips: 707\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.160. Val_Loss: 3.380\n",
      "ACC: 0.195.\n",
      "TPR: 0.181.\n",
      "F1-score: 0.149.\n",
      "Iteration Time 2.475 (2.490)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1251\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(4096., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [008/020]   Attack Time 4.613 (4.605)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 808\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.153. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.092.\n",
      "F1-score: 0.032.\n",
      "Iteration Time 2.508 (2.492)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 39\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [009/020]   Attack Time 4.484 (4.591)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 909\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.430 (2.485)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 3110\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(1024., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [010/020]   Attack Time 4.581 (4.590)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1010\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.454 (2.482)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 3171\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [011/020]   Attack Time 4.498 (4.582)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1111\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.541 (2.487)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 220\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8192., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [012/020]   Attack Time 4.604 (4.584)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1212\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.497 (2.488)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2784\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-2049., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [013/020]   Attack Time 4.568 (4.582)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1313\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.532 (2.492)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 290\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(512., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [014/020]   Attack Time 4.521 (4.578)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1414\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.528 (2.494)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 28\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [015/020]   Attack Time 4.576 (4.578)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1515\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.456 (2.492)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 701\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [016/020]   Attack Time 4.480 (4.572)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1616\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.522 (2.494)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2868\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-513., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [017/020]   Attack Time 4.723 (4.581)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1717\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.551 (2.497)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2385\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-1025., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [018/020]   Attack Time 4.596 (4.582)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1818\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.438 (2.494)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 1383\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [019/020]   Attack Time 4.546 (4.580)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 1919\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.535 (2.496)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 2520\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(128., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [020/020]   Attack Time 4.540 (4.578)\n",
      "Loss before attack: 3.2397\n",
      "Loss after attack: 3.2397\n",
      "Bit flips: 2020\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.156. Val_Loss: 3.365\n",
      "ACC: 0.211.\n",
      "TPR: 0.088.\n",
      "F1-score: 0.034.\n",
      "Iteration Time 2.535 (2.498)\n",
      "Plot saved as CustomModel2/RandomFlip_to_PBS_attack/MCC_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel2/RandomFlip_to_PBS_attack/ACC_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel2/RandomFlip_to_PBS_attack/TPR_RandomFlip_to_PBS_attack.png\n",
      "Plot saved as CustomModel2/RandomFlip_to_PBS_attack/F1_RandomFlip_to_PBS_attack.png\n",
      "MCC after 100 times random to PBS: 0.15644085351690468\n",
      "Accuracy after 100 times random to PBS: 0.21070016240171027\n",
      "TPR after 100 times random to PBS: 0.08843508511615948\n",
      "F1-score after 100 times random to PBS: 0.03395864786757065\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"RandomFlip_to_PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_paths = [os.path.join(attack_dir, f\"{metric}_RandomFlip_to_PBS_attack.png\") \n",
    "                      for metric in [\"MCC\", \"ACC\", \"TPR\", \"F1\"]]\n",
    "# attack_image_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_paths,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 4,                  # Chế độ tấn công Random -> PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "# best_mcc = validate_score( trained_model,test_loader)\n",
    "# print(f\"\\nMCC after 100 times Random to PBS: {best_mcc}\")\n",
    "\n",
    "results = validate_score(trained_model, test_loader)\n",
    "print(f\"MCC after 100 times random to PBS: {results['MCC']}\")\n",
    "print(f\"Accuracy after 100 times random to PBS: {results['Accuracy']}\")\n",
    "print(f\"TPR after 100 times random to PBS: {results['TPR']}\")\n",
    "print(f\"F1-score after 100 times random to PBS: {results['F1 Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "199afe5b-0442-41e8-8bd7-f0e17a00340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đồ thị đã được lưu tại CustomModel/Aggregate_Results/CustomModel_comparison_plot.png\n",
      "Đồ thị đã được lưu tại CustomModel2/Aggregate_Results/CustomModel2_comparison_plot.png\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"CustomModel\", \"CustomModel2\"]\n",
    "attack_types = [\"PBS\", \"RandomFlip\", \"PBS_to_RandomFlip\", \"RandomFlip_to_PBS\"]\n",
    "\n",
    "def aggregate_results(model_name, attack_types):\n",
    "    \n",
    "    aggregate_dir = os.path.join(model_name, \"Aggregate_Results\")\n",
    "    os.makedirs(aggregate_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Đọc kết quả từ từng kịch bản tấn công\n",
    "    for attack_type in attack_types:\n",
    "        csv_file_path = os.path.join(model_name, f\"{attack_type}_attack\", f\"{attack_type}_attack.csv\")\n",
    "        if os.path.exists(csv_file_path):\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            \n",
    "            mcc_values = df['MCC Drop'].tolist()\n",
    "            results.append(mcc_values)\n",
    "        else:\n",
    "            print(f\"File {csv_file_path} không tồn tại.\")\n",
    "\n",
    "    # Ghi kết quả tổng hợp vào file CSV\n",
    "    aggregate_df = pd.DataFrame(results, index=attack_types).T\n",
    "    aggregate_csv_path = os.path.join(aggregate_dir, \"aggregated_results.csv\")\n",
    "    aggregate_df.to_csv(aggregate_csv_path)\n",
    "\n",
    "    # Vẽ đồ thị so sánh\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, attack_type in enumerate(attack_types):\n",
    "        plt.plot(aggregate_df.index, aggregate_df[attack_type], marker='o', label=attack_type)\n",
    "\n",
    "    plt.title(f'So sánh MCC giữa các kịch bản tấn công cho {model_name}', fontsize=14)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('MCC', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    epochs = aggregate_df.index.astype(int).tolist()\n",
    "    plt.xticks(epochs, epochs)\n",
    "    \n",
    "    plot_path = os.path.join(aggregate_dir, f\"{model_name}_comparison_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Đồ thị đã được lưu tại {plot_path}\")\n",
    "\n",
    "for model_name in model_names:\n",
    "    aggregate_results(model_name, attack_types)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
