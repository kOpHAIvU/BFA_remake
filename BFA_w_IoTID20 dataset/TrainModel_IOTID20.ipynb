{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f44d3b7-0ac2-4d07-ab06-c2cdf178a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 10:56:28.978259: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-10 10:56:28.978290: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-10 10:56:28.979065: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 10:56:28.983787: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os, sys, random\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab1743d-1201-4bb2-b74c-1c6b1e0979a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecorderMeter(object):\n",
    "    \"\"\"Computes and stores the minimum loss value and its epoch index, along with MCC\"\"\"\n",
    "\n",
    "    def __init__(self, total_epoch):\n",
    "        self.reset(total_epoch)\n",
    "\n",
    "    def reset(self, total_epoch):\n",
    "        assert total_epoch > 0\n",
    "        self.total_epoch = total_epoch\n",
    "        self.current_epoch = 0\n",
    "        self.epoch_losses = np.zeros((self.total_epoch, 2), dtype=np.float32)  # [epoch, train/val]\n",
    "        self.epoch_losses = self.epoch_losses - 1\n",
    "\n",
    "        self.epoch_mcc = np.zeros((self.total_epoch, 2), dtype=np.float32)  # [epoch, train/val]\n",
    "        self.epoch_mcc = self.epoch_mcc\n",
    "\n",
    "    def update(self, idx, train_loss, train_mcc, val_loss, val_mcc):\n",
    "        assert idx >= 0 and idx < self.total_epoch, 'total_epoch : {} , but update with the {} index'.format(\n",
    "            self.total_epoch, idx)\n",
    "        self.epoch_losses[idx, 0] = train_loss\n",
    "        self.epoch_losses[idx, 1] = val_loss\n",
    "        self.epoch_mcc[idx, 0] = train_mcc\n",
    "        self.epoch_mcc[idx, 1] = val_mcc\n",
    "        self.current_epoch = idx + 1\n",
    "\n",
    "    def max_mcc(self, istrain):\n",
    "        if self.current_epoch <= 0:\n",
    "            return 0\n",
    "        if istrain:\n",
    "            return self.epoch_mcc[:self.current_epoch, 0].max()\n",
    "        else:\n",
    "            return self.epoch_mcc[:self.current_epoch, 1].max()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d94f3b-6448-4cc4-8909-784cdfc88190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_string():\n",
    "    ISOTIMEFORMAT = '%Y-%m-%d %X'\n",
    "    string = '[{}]'.format(\n",
    "        time.strftime(ISOTIMEFORMAT, time.gmtime(time.time())))\n",
    "    return string\n",
    "\n",
    "\n",
    "def convert_secs2time(epoch_time):\n",
    "    need_hour = int(epoch_time / 3600)\n",
    "    need_mins = int((epoch_time - 3600 * need_hour) / 60)\n",
    "    need_secs = int(epoch_time - 3600 * need_hour - 60 * need_mins)\n",
    "    return need_hour, need_mins, need_secs\n",
    "\n",
    "\n",
    "def time_file_str():\n",
    "    ISOTIMEFORMAT = '%Y-%m-%d'\n",
    "    string = '{}'.format(time.strftime(ISOTIMEFORMAT,\n",
    "                                       time.gmtime(time.time())))\n",
    "    return string + '-{}'.format(random.randint(1, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebfc21f-f070-4c3a-9d14-0016ff758cdf",
   "metadata": {},
   "source": [
    "### Class quan_Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d955bd-6a8c-4182-8406-0edb3d399df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class quan_Linear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(quan_Linear, self).__init__(in_features, out_features, bias=bias)\n",
    "\n",
    "        self.N_bits = 8\n",
    "        self.full_lvls = 2**self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "        # Initialize the step size\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        self.__reset_stepsize__()\n",
    "        # flag to enable the inference with quantized weight or self.weight\n",
    "        self.inf_with_weight = False  # disabled by default\n",
    "\n",
    "        # create a vector to identify the weight to each bit\n",
    "        self.b_w = nn.Parameter(2**torch.arange(start=self.N_bits - 1,\n",
    "                                                end=-1,\n",
    "                                                step=-1).unsqueeze(-1).float(),\n",
    "                                requires_grad=False)\n",
    "\n",
    "        self.b_w[0] = -self.b_w[0]  #in-place reverse\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.inf_with_weight:\n",
    "            return F.linear(input, self.weight * self.step_size, self.bias)\n",
    "        else:\n",
    "            self.__reset_stepsize__()\n",
    "            weight_quan = quantize(self.weight, self.step_size,\n",
    "                                   self.half_lvls) * self.step_size\n",
    "            return F.linear(input, weight_quan, self.bias)\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        with torch.no_grad():\n",
    "            self.step_size.data = self.weight.abs().max() / self.half_lvls\n",
    "\n",
    "    def __reset_weight__(self):\n",
    "        '''\n",
    "        This function will reconstruct the weight stored in self.weight.\n",
    "        Replacing the orginal floating-point with the quantized fix-point\n",
    "        weight representation.\n",
    "        '''\n",
    "        # replace the weight with the quantized version\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = quantize(self.weight, self.step_size,\n",
    "                                        self.half_lvls)\n",
    "        # enable the flag, thus now computation does not invovle weight quantization\n",
    "        self.inf_with_weight = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511ef91d-ed9d-4cc0-8e3e-871496baa077",
   "metadata": {},
   "source": [
    "### Class quan_Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7af0b0-250e-40d1-a1e5-8c4dc2c0edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class quan_Conv1d(nn.Conv1d):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True):\n",
    "        super(quan_Conv1d, self).__init__(in_channels,\n",
    "                                          out_channels,\n",
    "                                          kernel_size,\n",
    "                                          stride=stride,\n",
    "                                          padding=padding,\n",
    "                                          dilation=dilation,\n",
    "                                          groups=groups,\n",
    "                                          bias=bias)\n",
    "\n",
    "        # Số lượng bit để lượng tử hóa trọng số\n",
    "        self.N_bits = 8\n",
    "        self.full_lvls = 2 ** self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "\n",
    "        # Bước lượng tử hóa (step size), là một tham số có thể học được\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "        self.__reset_stepsize__()\n",
    "\n",
    "        # Cờ để bật hoặc tắt sử dụng trọng số lượng tử hóa\n",
    "        self.inf_with_weight = False  # Tắt theo mặc định\n",
    "\n",
    "        # Tạo một vector để biểu diễn trọng số cho từng bit\n",
    "        self.b_w = nn.Parameter(2 ** torch.arange(start=self.N_bits - 1,\n",
    "                                                  end=-1,\n",
    "                                                  step=-1).unsqueeze(-1).float(),\n",
    "                                requires_grad=False)\n",
    "        self.b_w[0] = -self.b_w[0]  # Biến đổi MSB thành giá trị âm để hỗ trợ bù hai\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        \"\"\"Hàm này dùng để đặt lại giá trị `step_size`.\"\"\"\n",
    "        # Giá trị này có thể được tùy chỉnh tùy thuộc vào yêu cầu của mô hình\n",
    "        self.step_size.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Kiểm tra cờ `inf_with_weight` để quyết định sử dụng trọng số đã lượng tử hóa hay không\n",
    "        if self.inf_with_weight:\n",
    "            quantized_weight = self.quantize_weight(self.weight)\n",
    "            return nn.functional.conv1d(x, quantized_weight, self.bias, self.stride,\n",
    "                                        self.padding, self.dilation, self.groups)\n",
    "        else:\n",
    "            return nn.functional.conv1d(x, self.weight, self.bias, self.stride,\n",
    "                                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def quantize_weight(self, weight):\n",
    "        \"\"\"Lượng tử hóa trọng số theo số bit đã định.\"\"\"\n",
    "        # Tạo trọng số lượng tử hóa bằng cách sử dụng step_size\n",
    "        quantized_weight = torch.round(weight / self.step_size) * self.step_size\n",
    "        quantized_weight = torch.clamp(quantized_weight, -self.half_lvls * self.step_size,\n",
    "                                       (self.half_lvls - 1) * self.step_size)\n",
    "        return quantized_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fa88fb5-bb55-4533-a756-13cbd6a6c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_quan_bitwidth(model, n_bit):\n",
    "    '''This script change the quantization bit-width of entire model to n_bit'''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear):\n",
    "            m.N_bits = n_bit\n",
    "            # print(\"Change weight bit-width as {}.\".format(m.N_bits))\n",
    "            m.b_w.data = m.b_w.data[-m.N_bits:]\n",
    "            m.b_w[0] = -m.b_w[0]\n",
    "            print(m.b_w)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa75564-0034-4b5e-9d74-bdd47ab945f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _quantize_func(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, step_size, half_lvls):\n",
    "        # ctx is a context object that can be used to stash information\n",
    "        # for backward computation\n",
    "        ctx.step_size = step_size\n",
    "        ctx.half_lvls = half_lvls\n",
    "        output = F.hardtanh(input,\n",
    "                            min_val=-ctx.half_lvls * ctx.step_size.item(),\n",
    "                            max_val=ctx.half_lvls * ctx.step_size.item())\n",
    "\n",
    "        output = torch.round(output / ctx.step_size)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone() / ctx.step_size\n",
    "\n",
    "        return grad_input, None, None\n",
    "\n",
    "quantize = _quantize_func.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d00dfb4e-6a31-4c77-80fd-5f3c446e2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _bin_func(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, mu):\n",
    "        ctx.mu = mu\n",
    "        output = input.clone().zero_()\n",
    "        output[input.ge(0)] = 1\n",
    "        output[input.lt(0)] = -1\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone() / ctx.mu\n",
    "        return grad_input, None\n",
    "\n",
    "w_bin = _bin_func.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f06e03c-27bb-4119-a6b7-785167405267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(tensor, step_size, half_lvls):\n",
    "    \"\"\"Quantization function.\"\"\"\n",
    "    return torch.clamp(torch.round(tensor / step_size), min=-half_lvls, max=half_lvls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ffdeb-6fac-47a8-b893-220f06d0200f",
   "metadata": {},
   "source": [
    "### Class CustomBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a72a2a-9140-440b-9fec-b84050b902dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, apply_softmax=False):\n",
    "        super(CustomBlock, self).__init__()\n",
    "        self.N_bits = 16\n",
    "        self.full_lvls = 2 ** self.N_bits\n",
    "        self.half_lvls = (self.full_lvls - 2) / 2\n",
    "        self.apply_softmax = apply_softmax\n",
    "\n",
    "        # Initialize the step size\n",
    "        self.step_size = nn.Parameter(torch.Tensor([1]), requires_grad=True)\n",
    "\n",
    "        # Initialize weights and bias\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_features)) if bias else None\n",
    "\n",
    "        # Reset parameters\n",
    "        self.__reset_stepsize__()\n",
    "        self.reset_parameters()\n",
    "\n",
    "        # Flag for inference with quantized weights\n",
    "        self.inf_with_weight = False\n",
    "\n",
    "        self.b_w = nn.Parameter(2**torch.arange(start=self.N_bits - 1,\n",
    "                                             end=-1,\n",
    "                                             step=-1).unsqueeze(-1).float(),\n",
    "                           requires_grad=False)\n",
    "        self.b_w[0] = -self.b_w[0]  #in-place reverse\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.weight, a=5 ** 0.5)\n",
    "        if self.bias is not None:\n",
    "            nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.inf_with_weight:\n",
    "            weight_applied = self.weight * self.step_size\n",
    "        else:\n",
    "            self.__reset_stepsize__()\n",
    "            weight_quan = quantize(self.weight, self.step_size, self.half_lvls) * self.step_size\n",
    "            weight_applied = weight_quan\n",
    "\n",
    "        # Linear transformation\n",
    "        input = input.view(input.size(0), -1)  # Flatten input to 2D for matmul\n",
    "        output = input @ weight_applied.T\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "\n",
    "        if self.apply_softmax:\n",
    "            output = F.softmax(output, dim=-1)\n",
    "        return output\n",
    "\n",
    "    def __reset_stepsize__(self):\n",
    "        with torch.no_grad():\n",
    "            self.step_size.data = self.weight.abs().max() / self.half_lvls\n",
    "\n",
    "    def __reset_weight__(self):\n",
    "        with torch.no_grad():\n",
    "            self.weight.data = quantize(self.weight, self.step_size, self.half_lvls)\n",
    "        self.inf_with_weight = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37fcad76-3af7-4814-9f3f-115a0d6e6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleA(nn.Module):\n",
    "    def __init__(self, nIn, nOut, stride):\n",
    "        super(DownsampleA, self).__init__()\n",
    "        assert stride == 2\n",
    "        self.avg = nn.AvgPool1d(kernel_size=1, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        return torch.cat((x, x.mul(0)), 1)\n",
    "        \n",
    "class SEBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.conv_a = quan_Conv1d(inplanes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_a = nn.BatchNorm1d(planes)\n",
    "        self.dropout_a = nn.Dropout(p=0.3)  # Dropout sau BatchNorm\n",
    "\n",
    "        self.conv_b = quan_Conv1d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn_b = nn.BatchNorm1d(planes)\n",
    "        self.dropout_b = nn.Dropout(p=0.3)  # Dropout sau BatchNorm\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        basicblock = self.conv_a(x)\n",
    "        basicblock = self.bn_a(basicblock)\n",
    "        basicblock = F.relu(basicblock, inplace=True)\n",
    "        basicblock = self.dropout_a(basicblock)  # Áp dụng dropout\n",
    "\n",
    "        basicblock = self.conv_b(basicblock)\n",
    "        basicblock = self.bn_b(basicblock)\n",
    "        basicblock = self.dropout_b(basicblock)  # Áp dụng dropout\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        return F.relu(residual + basicblock, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b7bf3-7bc7-4e4f-b34c-7b60196f150d",
   "metadata": {},
   "source": [
    "### Class CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00cab76a-39cf-453d-b657-ca053aee8d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_size=69, hidden_sizes=[32, 64, 128, 256, 512], output_size=5):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = quan_Conv1d(input_size, hidden_sizes[0], kernel_size=3, stride=1, padding=1)\n",
    "        self.bn_1 = nn.BatchNorm1d(hidden_sizes[0])\n",
    "\n",
    "        self.inplanes = 32\n",
    "        self.stage_1 = self._make_layer(SEBlock, 32, 16, 1)\n",
    "        self.stage_2 = self._make_layer(SEBlock, 64, 16, 2)\n",
    "        self.stage_3 = self._make_layer(SEBlock, 128, 16, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.classifier = CustomBlock(128 * SEBlock.expansion, output_size)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                #m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal(m.weight)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        downsample = None\n",
    "        if stride == 2 or self.inplanes != planes * SEBlock.expansion:\n",
    "            downsample = DownsampleA(self.inplanes, planes * SEBlock.expansion, stride) if stride == 2 else None\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride=1, downsample=downsample))\n",
    "        self.inplanes = planes * SEBlock.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(self.bn_1(x), inplace=True)\n",
    "        \n",
    "        x = self.stage_1(x)\n",
    "        x = self.stage_2(x)\n",
    "        x = self.stage_3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4518cc2-57d4-474d-b206-68dfd5baa981",
   "metadata": {},
   "source": [
    "### Class CustomModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aa14999-e6e2-4a3b-8eb1-7032515747b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel2(nn.Module):\n",
    "    def __init__(self, input_size=69, hidden_sizes=[32, 64, 128, 100], output_size=5):\n",
    "        super(CustomModel2, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Conv1d(input_size, hidden_sizes[0], kernel_size=3, stride=2, padding=1)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        self.stage_1 = nn.Conv1d(hidden_sizes[0], hidden_sizes[1], kernel_size=3, stride=2, padding=1)\n",
    "        self.stage_2 = nn.Conv1d(hidden_sizes[1], hidden_sizes[2], kernel_size=3, stride=2, padding=1)\n",
    "        self.stage_3 = nn.Conv1d(hidden_sizes[2], hidden_sizes[3], kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Global Pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = CustomBlock(hidden_sizes[-1], output_size, apply_softmax=True)\n",
    "        nn.Dropout(0.15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_1(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_2(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        x = self.stage_3(x)\n",
    "        x = self.activation(self.pool(x))\n",
    "\n",
    "        # Global Pooling\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37be8524-9419-4c78-a136-c665a10da763",
   "metadata": {},
   "source": [
    "### Init dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c6d2715-cc0b-4a89-86b6-7b7859d97691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.arch = 'CustomModel'\n",
    "        self.data_path = '../../dataset/'\n",
    "        self.dataset = 'inid'\n",
    "        self.save_path = './save/attack_random'\n",
    "        self.epochs = 20\n",
    "        self.optimizer = 'SGD'\n",
    "        self.test_batch_size = 32\n",
    "        self.learning_rate = 0.001\n",
    "        self.momentum = 0.9\n",
    "        self.decay = 1e-4\n",
    "        self.schedule = [80, 120]\n",
    "        self.gammas = [0.1, 0.1]\n",
    "        self.print_freq = 100\n",
    "        self.resume = 'save\\model_best.pth.tar'\n",
    "        self.start_epoch = 0\n",
    "        self.enable_bfa = False\n",
    "        self.evaluate = False\n",
    "        self.ngpu = 1\n",
    "        self.gpu_id = 0\n",
    "        self.workers = 4\n",
    "        self.manualSeed = None\n",
    "        self.quan_bitwidth = 16\n",
    "        self.reset_weight = False\n",
    "        self.bfa = True\n",
    "        self.attack_sample_size = 128\n",
    "        self.n_iter = 20\n",
    "        self.k_top = None\n",
    "        self.random_bfa = True\n",
    "        self.progressive_bit_search= True\n",
    "        self.random_flip = True\n",
    "        self.clustering = False\n",
    "        self.lambda_coeff = 1e-3\n",
    "        self.use_cuda = True  \n",
    "\n",
    "args = Args()\n",
    "args.use_cuda = torch.cuda.is_available() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "896db0e2-2ae5-4eeb-a5be-9513eb168b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Save path: ./save/attack_random\n",
      "State: {'arch': 'CustomModel', 'attack_sample_size': 128, 'bfa': True, 'clustering': False, 'data_path': '../../dataset/', 'dataset': 'inid', 'decay': 0.0001, 'enable_bfa': False, 'epochs': 20, 'evaluate': False, 'gammas': [0.1, 0.1], 'gpu_id': 0, 'k_top': None, 'lambda_coeff': 0.001, 'learning_rate': 0.001, 'manualSeed': None, 'momentum': 0.9, 'n_iter': 20, 'ngpu': 1, 'optimizer': 'SGD', 'print_freq': 100, 'progressive_bit_search': True, 'quan_bitwidth': 16, 'random_bfa': True, 'random_flip': True, 'reset_weight': False, 'resume': 'save\\\\model_best.pth.tar', 'save_path': './save/attack_random', 'schedule': [80, 120], 'start_epoch': 0, 'test_batch_size': 32, 'use_cuda': True, 'workers': 4}\n",
      "Random Seed: None\n",
      "Python version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n",
      "Torch version: 2.2.2+cu118\n",
      "CUDNN version: 8907\n"
     ]
    }
   ],
   "source": [
    "# Thiết lập cấu hình logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Init logger\n",
    "if not os.path.isdir(args.save_path):\n",
    "    os.makedirs(args.save_path)\n",
    "\n",
    "# Tạo tệp log\n",
    "log_file_path = os.path.join(args.save_path, 'log_seed_{}.txt'.format(args.manualSeed))\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Định dạng cho tệp log\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Thêm file handler vào logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Ghi log vào console và tệp\n",
    "logger.info('Save path: {}'.format(args.save_path))\n",
    "state = {k: getattr(args, k) for k in dir(args) if not k.startswith('__')}\n",
    "logger.info('State: {}'.format(state))\n",
    "logger.info(\"Random Seed: {}\".format(args.manualSeed))\n",
    "logger.info(\"Python version: {}\".format(sys.version.replace('\\n', ' ')))\n",
    "logger.info(\"Torch version: {}\".format(torch.__version__))\n",
    "logger.info(\"CUDNN version: {}\".format(torch.backends.cudnn.version()))\n",
    "\n",
    "# Init the tensorboard path and writer\n",
    "tb_path = os.path.join(args.save_path, 'tb_log', 'run_' + str(args.manualSeed))\n",
    "writer = SummaryWriter(tb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcada582-5dd5-4a18-82bd-bedbe8d01b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inid dataset import sucsess!\n"
     ]
    }
   ],
   "source": [
    "# Init dataset\n",
    "if not os.path.isdir(args.data_path):\n",
    "    os.makedirs(args.data_path)\n",
    "\n",
    "if args.dataset == 'inid':\n",
    "    print(\"Inid dataset import sucsess!\")\n",
    "else:\n",
    "    assert False, \"Unknow dataset : {}\".format(args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1c44c7-8223-4bb5-92cf-416ec52171c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/tljh/user/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "=> creating model 'CustomModel'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194495    Mirai\n",
      "340351    Mirai\n",
      "196508    Mirai\n",
      "76905     Mirai\n",
      "39129     Mirai\n",
      "          ...  \n",
      "406041    Mirai\n",
      "97693       DoS\n",
      "511814    Mirai\n",
      "400759    Mirai\n",
      "81401     Mirai\n",
      "Name: Cat, Length: 234900, dtype: object\n",
      "Kiểu dữ liệu y_train: (234900,)\n",
      "Kiểu dữ liệu y_test: (58725,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Init_Bwd_Win_Byts</th>\n",
       "      <th>Fwd_Act_Data_Pkts</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>10101</td>\n",
       "      <td>17</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>982.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2179</td>\n",
       "      <td>554</td>\n",
       "      <td>6</td>\n",
       "      <td>5310</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>2261.327486</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>1056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52727</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1869</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52964</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1869</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36763</td>\n",
       "      <td>1900</td>\n",
       "      <td>17</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>886.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625772</th>\n",
       "      <td>5664</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625776</th>\n",
       "      <td>8739</td>\n",
       "      <td>19604</td>\n",
       "      <td>6</td>\n",
       "      <td>1092</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625778</th>\n",
       "      <td>56112</td>\n",
       "      <td>8043</td>\n",
       "      <td>17</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.0</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625779</th>\n",
       "      <td>4570</td>\n",
       "      <td>554</td>\n",
       "      <td>6</td>\n",
       "      <td>1658</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625781</th>\n",
       "      <td>9020</td>\n",
       "      <td>49784</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1869</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>125.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293625 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Src_Port  Dst_Port  Protocol  Flow_Duration  Tot_Fwd_Pkts  \\\n",
       "0          10000     10101        17             75             1   \n",
       "1           2179       554         6           5310             1   \n",
       "2          52727      9020         6            141             0   \n",
       "3          52964      9020         6            151             0   \n",
       "4          36763      1900        17            153             2   \n",
       "...          ...       ...       ...            ...           ...   \n",
       "625772      5664        23         6             28             1   \n",
       "625776      8739     19604         6           1092             0   \n",
       "625778     56112      8043        17            277             1   \n",
       "625779      4570       554         6           1658             0   \n",
       "625781      9020     49784         6            240             2   \n",
       "\n",
       "        Tot_Bwd_Pkts  TotLen_Fwd_Pkts  TotLen_Bwd_Pkts  Fwd_Pkt_Len_Max  \\\n",
       "0                  1            982.0           1430.0            982.0   \n",
       "1                  2              0.0              0.0              0.0   \n",
       "2                  3              0.0           2806.0              0.0   \n",
       "3                  2              0.0           2776.0              0.0   \n",
       "4                  1            886.0            420.0            452.0   \n",
       "...              ...              ...              ...              ...   \n",
       "625772             1              0.0             69.0              0.0   \n",
       "625776             2              0.0              0.0              0.0   \n",
       "625778             1             18.0             18.0             18.0   \n",
       "625779             2              0.0              0.0              0.0   \n",
       "625781             1           2776.0           1388.0           1388.0   \n",
       "\n",
       "        Fwd_Pkt_Len_Min  ...  Init_Bwd_Win_Byts  Fwd_Act_Data_Pkts  \\\n",
       "0                 982.0  ...                 -1                  1   \n",
       "1                   0.0  ...              14600                  0   \n",
       "2                   0.0  ...               1869                  0   \n",
       "3                   0.0  ...               1869                  0   \n",
       "4                 434.0  ...                 -1                  2   \n",
       "...                 ...  ...                ...                ...   \n",
       "625772              0.0  ...                256                  0   \n",
       "625776              0.0  ...                  0                  0   \n",
       "625778             18.0  ...                 -1                  1   \n",
       "625779              0.0  ...              14600                  0   \n",
       "625781           1388.0  ...               1869                  2   \n",
       "\n",
       "        Active_Mean  Active_Std  Active_Max  Active_Min  Idle_Mean  \\\n",
       "0               0.0         0.0         0.0         0.0       75.0   \n",
       "1               0.0         0.0         0.0         0.0     2655.0   \n",
       "2               0.0         0.0         0.0         0.0       70.5   \n",
       "3               0.0         0.0         0.0         0.0      151.0   \n",
       "4               0.0         0.0         0.0         0.0       76.5   \n",
       "...             ...         ...         ...         ...        ...   \n",
       "625772          0.0         0.0         0.0         0.0       28.0   \n",
       "625776          0.0         0.0         0.0         0.0     1092.0   \n",
       "625778          0.0         0.0         0.0         0.0      277.0   \n",
       "625779          0.0         0.0         0.0         0.0     1658.0   \n",
       "625781          0.0         0.0         0.0         0.0      120.0   \n",
       "\n",
       "           Idle_Std  Idle_Max  Idle_Min  \n",
       "0          0.000000      75.0      75.0  \n",
       "1       2261.327486    4254.0    1056.0  \n",
       "2          0.707107      71.0      70.0  \n",
       "3          0.000000     151.0     151.0  \n",
       "4          0.707107      77.0      76.0  \n",
       "...             ...       ...       ...  \n",
       "625772     0.000000      28.0      28.0  \n",
       "625776     0.000000    1092.0    1092.0  \n",
       "625778     0.000000     277.0     277.0  \n",
       "625779     0.000000    1658.0    1658.0  \n",
       "625781     7.071068     125.0     115.0  \n",
       "\n",
       "[293625 rows x 69 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init dataset\n",
    "if args.dataset == 'inid':\n",
    "    data = pd.read_csv(\"../../dataset/IoT_Network_Intrusion_Dataset.csv\",\n",
    "                               skipinitialspace=True)\n",
    "    data = data.drop_duplicates()\n",
    "    data = data.drop(columns=['Flow_ID', 'Src_IP', 'Dst_IP', 'Timestamp'])\n",
    "    data = data.drop(columns=['Fwd_PSH_Flags', 'Fwd_URG_Flags', 'Fwd_Byts/b_Avg', 'Fwd_Pkts/b_Avg',\n",
    "                                      'Fwd_Blk_Rate_Avg', 'Bwd_Byts/b_Avg', 'Bwd_Pkts/b_Avg', 'Bwd_Blk_Rate_Avg',\n",
    "                                      'Init_Fwd_Win_Byts', 'Fwd_Seg_Size_Min'])\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.fillna(0, inplace=True)\n",
    "    data = data.drop_duplicates()\n",
    "    datalabel = data[['Cat']]\n",
    "    data = data.drop(columns=['Label', 'Cat', 'Sub_Cat'])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    onc = LabelEncoder()\n",
    "    \n",
    "    # Tách dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, datalabel, test_size=0.2, random_state=100)\n",
    "    X_train= scaler.fit_transform(X_train)\n",
    "    X_test= scaler.transform(X_test)\n",
    "    print(y_train['Cat'])\n",
    "    # Chuyển đổi y_train và y_test thành mã số\n",
    "    y_train = onc.fit_transform(y_train['Cat'].to_numpy().reshape(-1,1))  # Chuyển đổi thành mã số\n",
    "    y_test= onc.transform(y_test['Cat'].to_numpy().reshape(-1,1))  # Chuyển đổi thành mã số\n",
    "    \n",
    "    # Kiểm tra kiểu dữ liệu của y_train và y_test\n",
    "    print(\"Kiểu dữ liệu y_train:\", y_train.shape)\n",
    "    print(\"Kiểu dữ liệu y_test:\", y_test.shape)\n",
    "    \n",
    "    # Tạo DataLoader cho tập huấn luyện\n",
    "    train_loader = DataLoader(\n",
    "        torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_train),\n",
    "            torch.LongTensor(y_train)  # y_train đã được chuyển đổi thành mã số\n",
    "        ),\n",
    "        batch_size=256,\n",
    "        num_workers=8,\n",
    "        shuffle=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Tạo DataLoader cho tập kiểm tra\n",
    "    test_loader = DataLoader(\n",
    "        torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_test),\n",
    "            torch.LongTensor(y_test)  # y_test đã được chuyển đổi thành mã số\n",
    "        ),\n",
    "        batch_size=256,\n",
    "        num_workers=8,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data,\n",
    "        batch_size=args.attack_sample_size,\n",
    "        shuffle=True,\n",
    "        num_workers=args.workers,\n",
    "        pin_memory=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=args.test_batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=args.workers,\n",
    "                                              pin_memory=True)\n",
    "\n",
    "logger.info(\"=> creating model '{}'\".format(args.arch))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba26c0f8-c31c-4391-b077-66165d0b8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc_score(preds, targets):\n",
    "    preds = preds.cpu().numpy()\n",
    "    targets = targets.cpu().numpy()\n",
    "    return matthews_corrcoef(targets, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99229d0e-0d79-4b51-beb2-c70f5f5c53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc2(outputs_label, outputs_cat, outputs_sub_cat, y_label_batch, y_cat_batch, y_sub_cat_batch):\n",
    "    \"\"\"Compute MCC for each output of the model (label, category, sub-category).\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Ensure target has at least one dimension\n",
    "        if y_label_batch.dim() == 0:\n",
    "            y_label_batch = y_label_batch.unsqueeze(0)\n",
    "        if y_cat_batch.dim() == 0:\n",
    "            y_cat_batch = y_cat_batch.unsqueeze(0)\n",
    "        if y_sub_cat_batch.dim() == 0:\n",
    "            y_sub_cat_batch = y_sub_cat_batch.unsqueeze(0)\n",
    "\n",
    "        # Get the predicted classes (top-1 prediction) for each output\n",
    "        _, pred_label = outputs_label.topk(1, 1, True, True)\n",
    "        _, pred_cat = outputs_cat.topk(1, 1, True, True)\n",
    "        _, pred_sub_cat = outputs_sub_cat.topk(1, 1, True, True)\n",
    "\n",
    "        # Compute MCC for each output type\n",
    "        mcc_label = mcc_score(pred_label.view(-1), y_label_batch)\n",
    "        mcc_cat = mcc_score(pred_cat.view(-1), y_cat_batch)\n",
    "        mcc_sub_cat = mcc_score(pred_sub_cat.view(-1), y_sub_cat_batch)\n",
    "\n",
    "        return mcc_label, mcc_cat, mcc_sub_cat\n",
    "\n",
    "\n",
    "def mcc(output, target):\n",
    "    \"\"\"Compute the Matthews Correlation Coefficient (MCC) for the given output and target.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Ensure target has at least one dimension\n",
    "        if target.dim() == 0:\n",
    "            target = target.unsqueeze(0)\n",
    "\n",
    "        # Get the predicted classes (top-1 prediction)\n",
    "        _, pred = output.topk(1, 1, True, True)\n",
    "        return mcc_score(pred.view(-1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41d98736-bb0a-4d10-9422-11caa334f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7f291e-ad43-4770-9e9a-0a0a07850136",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e39667a-f0ba-49cc-bc17-9fe62aaa29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()  # Track MCC instead of accuracy\n",
    "\n",
    "    # Switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # Measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.use_cuda:\n",
    "            input = input.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "            \n",
    "        input = input.view(input.size(0), 69, -1)  # Reshape input\n",
    "        \n",
    "        # Compute output and loss\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if args.clustering:\n",
    "            loss += clustering_loss(model, args.lambda_coeff)\n",
    "\n",
    "        # Compute MCC and record loss\n",
    "        mcc_value = mcc(output.data, target)  # MCC calculation instead of topk accuracy\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        mcc_meter.update(mcc_value, input.size(0))\n",
    "\n",
    "        # Compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "    return mcc_meter.avg, losses.avg\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion, summary_output=True):\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()  # Sử dụng MCC thay vì accuracy\n",
    "\n",
    "    # Chuyển model sang chế độ đánh giá\n",
    "    model.eval()\n",
    "    output_summary = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            if input.size(1) == 69 and input.dim() == 2:  # Kiểm tra nếu thiếu chiều thứ 3\n",
    "                input = input.unsqueeze(-1)\n",
    "\n",
    "            if torch.cuda.is_available() and args.use_cuda:\n",
    "                target = target.cuda(non_blocking=True)\n",
    "                input = input.cuda(non_blocking=True)\n",
    "\n",
    "            # Tính toán output và loss\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            losses.update(loss.item(), input.size(0))  # Cập nhật losses\n",
    "\n",
    "            if summary_output:\n",
    "                tmp_list = output.max(1, keepdim=True)[1].flatten().cpu().numpy() # get the index of the max log-probability\n",
    "                output_summary.append(tmp_list)\n",
    "                \n",
    "            # Tính MCC\n",
    "            mcc_value = mcc(output.data, target)\n",
    "            mcc_meter.update(mcc_value, input.size(0))\n",
    "\n",
    "    return mcc_meter.avg, losses.avg, output_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1687046-4b16-4dce-9495-484ece92b6b1",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8d35b5b-6c57-4d4e-8747-560eaa878af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, test_loader):\n",
    "    losses = AverageMeter()\n",
    "    mcc_meter = AverageMeter()  # Sử dụng MCC thay vì accuracy\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(test_loader):\n",
    "            if input.size(1) == 69 and input.dim() == 2:  # Kiểm tra nếu thiếu chiều thứ 3\n",
    "                input = input.unsqueeze(-1)\n",
    "\n",
    "            if torch.cuda.is_available() and args.use_cuda:\n",
    "                target = target.cuda(non_blocking=True)\n",
    "                input = input.cuda(non_blocking=True)\n",
    "\n",
    "            # Tính toán output và loss\n",
    "            output = model(input)\n",
    "\n",
    "                \n",
    "            # Tính MCC\n",
    "            mcc_value = mcc(output.data, target)\n",
    "            mcc_meter.update(mcc_value, input.size(0))\n",
    "\n",
    "    return mcc_meter.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db928785-c739-49a0-af06-9b3adb6fc504",
   "metadata": {},
   "source": [
    "### class BFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74582bcb-fbb1-4843-b49d-8b886e216d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BFA(object):\n",
    "    def __init__(self, criterion, model, k_top=10):\n",
    "        self.criterion = criterion\n",
    "        self.loss_dict = {}\n",
    "        self.bit_counter = 0\n",
    "        self.k_top = k_top\n",
    "        self.n_bits2flip = 0\n",
    "        self.loss = 0\n",
    "        self.num_bit_flipped = 0\n",
    "        \n",
    "        # Attributes for random attack\n",
    "        self.module_list = []\n",
    "\n",
    "        for name, m in model.named_modules():\n",
    "            if isinstance(m, (quan_Conv1d, quan_Linear, CustomBlock)):\n",
    "                self.module_list.append(name)\n",
    "\n",
    "    def flip_bit(self, m):\n",
    "        '''\n",
    "        the data type of input param is 32-bit floating, then return the data should\n",
    "        be in the same data_type.\n",
    "        '''\n",
    "        if self.k_top is None:\n",
    "            k_top = m.weight.detach().flatten().__len__()\n",
    "        else: \n",
    "            k_top = self.k_top\n",
    "        # 1. flatten the gradient tensor to perform topk\n",
    "        w_grad_topk, w_idx_topk = m.weight.grad.detach().abs().view(-1).topk(k_top)\n",
    "        # update the b_grad to its signed representation\n",
    "        w_grad_topk = m.weight.grad.detach().view(-1)[w_idx_topk]\n",
    "\n",
    "        # 2. create the b_grad matrix in shape of [N_bits, k_top]\n",
    "        b_grad_topk = w_grad_topk * m.b_w.data\n",
    "\n",
    "        # 3. generate the gradient mask to zero-out the bit-gradient\n",
    "        # which can not be flipped\n",
    "        b_grad_topk_sign = (b_grad_topk.sign() +\n",
    "                            1) * 0.5  # zero -> negative, one -> positive\n",
    "        # convert to twos complement into unsigned integer\n",
    "        w_bin = int2bin(m.weight.detach().view(-1), m.N_bits).short()\n",
    "        w_bin_topk = w_bin[w_idx_topk]  # get the weights whose grads are topk\n",
    "        \n",
    "        # generate two's complement bit-map\n",
    "        b_bin_topk = (w_bin_topk.repeat(m.N_bits, 1) & m.b_w.abs().repeat(1, k_top).short()) \\\n",
    "           // m.b_w.abs().repeat(1, k_top).short()\n",
    "\n",
    "        grad_mask = b_bin_topk ^ b_grad_topk_sign.short()\n",
    "\n",
    "        # 4. apply the gradient mask upon ```b_grad_topk``` and in-place update it\n",
    "        b_grad_topk *= grad_mask.float()\n",
    "\n",
    "        # 5. identify the several maximum of absolute bit gradient and return the index, the number of bits to flip is self.n_bits2flip\n",
    "\n",
    "        grad_max = b_grad_topk.abs().max()\n",
    "        num_elements = b_grad_topk.nelement()  # Get the total number of elements\n",
    "        k = min(self.n_bits2flip, num_elements)  # Clamp the value of k\n",
    "    \n",
    "        _, b_grad_max_idx = b_grad_topk.abs().view(-1).topk(k)  # Use clamped k\n",
    "        bit2flip = b_grad_topk.clone().view(-1).zero_()\n",
    "\n",
    "        if grad_max.item() != 0:  # ensure the max grad is not zero\n",
    "            bit2flip[b_grad_max_idx] = 1\n",
    "            bit2flip = bit2flip.view(b_grad_topk.size())\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # 6. Based on the identified bit indexed by ```bit2flip```, generate another\n",
    "        # mask, then perform the bitwise xor operation to realize the bit-flip.\n",
    "        bit2flip = bit2flip.reshape(m.b_w.abs().shape[0], -1)  # Định hình lại\n",
    "\n",
    "        w_bin_topk_flipped = (bit2flip.short() * m.b_w.abs().short()).sum(0, dtype=torch.int16) \\\n",
    "            ^ w_bin_topk\n",
    "\n",
    "        # 7. update the weight in the original weight tensor\n",
    "        w_bin[w_idx_topk] = w_bin_topk_flipped  # in-place change\n",
    "        param_flipped = bin2int(w_bin,\n",
    "                                m.N_bits).view(m.weight.data.size()).float()\n",
    "\n",
    "        return param_flipped\n",
    "\n",
    "    def progressive_bit_search(self, model, data, target, test_loader):\n",
    "        ''' \n",
    "        Given the model, based on the current data and target, go through\n",
    "        all the layers and identify the bits to be flipped. \n",
    "        '''\n",
    "        model.eval()\n",
    "        output = model(data)\n",
    "        self.loss = self.criterion(output, target)\n",
    "\n",
    "        # Zero out the grads first, then get the grads\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, (quan_Conv1d, quan_Linear, CustomBlock)):\n",
    "                if m.weight.grad is not None:\n",
    "                    m.weight.grad.data.zero_()\n",
    "\n",
    "        self.loss.backward()\n",
    "        self.loss_max = self.loss.item()\n",
    "\n",
    "        attack_log = []\n",
    "\n",
    "        # 3. Flip bits until no further loss degradation is observed\n",
    "        while self.loss_max <= self.loss.item():\n",
    "            self.n_bits2flip += 1\n",
    "            self.loss_dict = {}\n",
    "\n",
    "            for name, module in model.named_modules():\n",
    "                if isinstance(module, CustomBlock) or isinstance(module, quan_Conv1d):\n",
    "                    clean_weight = module.weight.data.detach()\n",
    "                    attack_weight = self.flip_bit(module)\n",
    "                    self.num_bit_flipped += 1\n",
    "\n",
    "                    module.weight.data = attack_weight\n",
    "                    output = model(data)\n",
    "\n",
    "                    self.loss_dict[name] = self.criterion(output, target).item()\n",
    "                    module.weight.data = clean_weight\n",
    "\n",
    "            max_loss_module = max(self.loss_dict.items(), key=lambda item: item[1])[0]\n",
    "            self.loss_max = self.loss_dict[max_loss_module]\n",
    "\n",
    "            if self.n_bits2flip == 100:\n",
    "                break;\n",
    "\n",
    "        weight_prior = None\n",
    "        weight_post = None\n",
    "                \n",
    "        # If loss_max does lead to degradation, change that layer's weight\n",
    "        for module_idx, (name, module) in enumerate(model.named_modules()):\n",
    "            if name == max_loss_module:\n",
    "                attack_weight = self.flip_bit(module)\n",
    "                self.num_bit_flipped += 1\n",
    "\n",
    "                ###########################################################\n",
    "                ## Attack profiling\n",
    "                ##########################################################\n",
    "                \n",
    "                weight_mismatch = attack_weight - module.weight.detach()\n",
    "                attack_weight_idx = torch.nonzero(weight_mismatch)\n",
    "                print('attacked module:', max_loss_module)\n",
    "                \n",
    "                attack_log = []\n",
    "                for i in range(attack_weight_idx.size(0)):\n",
    "                    weight_idx = attack_weight_idx[i, :].cpu().numpy()\n",
    "                    weight_prior = module.weight.detach()[tuple(weight_idx)].item()\n",
    "                    weight_post = attack_weight[tuple(weight_idx)].item()\n",
    "                \n",
    "                    tmp_list = [module_idx, self.bit_counter + (i + 1), max_loss_module,\n",
    "                                weight_idx, weight_prior, weight_post]\n",
    "                    attack_log.append(tmp_list)\n",
    "\n",
    "                module.weight.data = attack_weight\n",
    "\n",
    "        self.bit_counter += self.n_bits2flip\n",
    "        self.n_bits2flip = 0\n",
    "\n",
    "        if weight_prior is None or weight_post is None:\n",
    "            attack_last_status = [self.bit_counter, max_loss_module, \"No attack\", \"No attack\"]\n",
    "        else:\n",
    "            attack_last_status = [self.bit_counter, max_loss_module, weight_prior, weight_post]\n",
    "        \n",
    "        return attack_log, test(model, test_loader), self.bit_counter, attack_last_status\n",
    "\n",
    "    def random_flip_one_bit(self, model, test_loader):\n",
    "        \"\"\"\n",
    "        Randomly flip one bit in the weight of a chosen module.\n",
    "        \"\"\"\n",
    "        weight_prior = None\n",
    "        weight_post = None\n",
    "        \n",
    "        chosen_module = random.choice(self.module_list)\n",
    "        for name, m in model.named_modules():\n",
    "            if name == chosen_module:\n",
    "                flatten_weight = m.weight.detach().view(-1)\n",
    "                chosen_idx = random.choice(range(flatten_weight.numel()))\n",
    "                bin_w = int2bin(flatten_weight[chosen_idx], m.N_bits).short()\n",
    "                bit_idx = random.choice(range(m.N_bits))\n",
    "                mask = (bin_w.clone().zero_() + 1) * (2 ** bit_idx)\n",
    "                bin_w = bin_w ^ mask\n",
    "                int_w = bin2int(bin_w, m.N_bits).float()\n",
    "\n",
    "                ##############################################\n",
    "                ###   attack profiling\n",
    "                ###############################################\n",
    "                \n",
    "                weight_mismatch = flatten_weight[chosen_idx] - int_w\n",
    "                attack_weight_idx = chosen_idx\n",
    "\n",
    "                print('attacked module:', chosen_module)\n",
    "                \n",
    "                attack_log = []\n",
    "                weight_idx = chosen_idx\n",
    "                weight_prior = flatten_weight[chosen_idx]\n",
    "                weight_post = int_w\n",
    "\n",
    "                print('attacked weight index:', weight_idx)\n",
    "                print('weight before attack:', weight_prior)\n",
    "                print('weight after attack:', weight_post)\n",
    "\n",
    "                tmp_list = [\"module_idx\", self.bit_counter + 1, \"loss\",\n",
    "                            weight_idx, weight_prior, weight_post]\n",
    "                attack_log.append(tmp_list)                            \n",
    "\n",
    "                self.bit_counter += 1\n",
    "                flatten_weight[chosen_idx] = int_w\n",
    "                m.weight.data = flatten_weight.view(m.weight.data.size())\n",
    "                \n",
    "        if weight_prior is None or weight_post is None:\n",
    "            attack_last_status = [self.bit_counter, chosen_module, \"No attack\", \"No attack\"]\n",
    "        else:\n",
    "            attack_last_status = [self.bit_counter, chosen_module, weight_prior, weight_post]\n",
    "\n",
    "        return attack_log, test(model, test_loader), self.bit_counter, attack_last_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f84e2d5-5b3e-44c2-ad91-bb2db1f4123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using SGD as optimizer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = CustomModel().to(device)\n",
    "\n",
    "if args.use_cuda:\n",
    "    if args.ngpu > 1:\n",
    "        net = torch.nn.DataParallel(net, device_ids=list(range(args.ngpu)))\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.001, weight_decay=0.01)\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# separate the parameters thus param groups can be updated by different optimizer\n",
    "all_param = [\n",
    "    param for name, param in net.named_parameters()\n",
    "    if not 'step_size' in name\n",
    "]\n",
    "\n",
    "step_param = [\n",
    "    param for name, param in net.named_parameters() if 'step_size' in name \n",
    "]\n",
    "\n",
    "if args.optimizer == \"SGD\":\n",
    "    print(\"using SGD as optimizer\")\n",
    "    optimizer = torch.optim.SGD(all_param,\n",
    "                                lr=0.01,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=0.0001,\n",
    "                                nesterov=True)\n",
    "\n",
    "elif args.optimizer == \"Adam\":\n",
    "    print(\"using Adam as optimizer\")\n",
    "    optimizer = torch.optim.Adam(filter(lambda param: param.requires_grad,\n",
    "                                        all_param),\n",
    "                                 lr=0.001,\n",
    "                                 #momentum=0.9,\n",
    "                                 weight_decay=0.001)\n",
    "\n",
    "\n",
    "elif args.optimizer == \"RMSprop\":\n",
    "    print(\"using RMSprop as optimizer\")\n",
    "    optimizer = torch.optim.RMSprop(\n",
    "        filter(lambda param: param.requires_grad, net.parameters()),\n",
    "        lr=0.01,\n",
    "        alpha=0.99,\n",
    "        eps=1e-08,\n",
    "        momentum=0.9,\n",
    "        weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90b235-b1f9-4fca-8436-8b556b04e691",
   "metadata": {},
   "source": [
    "## BFA Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24700838-e7ee-4af6-8d1c-368edf0b351e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found at 'save\\model_best.pth.tar'\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[128.],\n",
      "        [ 64.],\n",
      "        [ 32.],\n",
      "        [ 16.],\n",
      "        [  8.],\n",
      "        [  4.],\n",
      "        [  2.],\n",
      "        [  1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if args.use_cuda:\n",
    "    net.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        if not args.fine_tune:\n",
    "            args.start_epoch = checkpoint['epoch']\n",
    "            recorder = checkpoint['recorder']\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        state_tmp = net.state_dict()\n",
    "        if 'state_dict' in checkpoint.keys():\n",
    "            state_tmp.update(checkpoint['state_dict'])\n",
    "        else:\n",
    "            state_tmp.update(checkpoint)\n",
    "\n",
    "        net.load_state_dict(state_tmp, strict=False)\n",
    "    else:\n",
    "        print(\"No checkpoint found at '{}'\".format(args.resume))\n",
    "else:\n",
    "    print(\"Do not use any checkpoint for {} model\".format(args.arch))\n",
    "\n",
    "\n",
    "# Configure the quantization bit-width\n",
    "if args.quan_bitwidth is not None:\n",
    "    change_quan_bitwidth(net, args.quan_bitwidth)\n",
    "\n",
    "# Update the step_size once the model is loaded. This is used for quantization.\n",
    "for m in net.modules():\n",
    "    if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear) or isinstance(m, CustomBlock) or m.__class__.__name__ == \"CustomBlock\" or m.__class__.__name__ == \"quan_Conv1d\":\n",
    "        m.__reset_stepsize__()\n",
    "\n",
    "# Block for weight reset\n",
    "if args.reset_weight:\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear) or isinstance(m, CustomBlock):\n",
    "            m.__reset_weight__()\n",
    "\n",
    "attacker = BFA(criterion, net, args.k_top)  # Khởi tạo đối tượng tấn công\n",
    "net_clean = copy.deepcopy(net)\n",
    "    # weight_conversion(net)\n",
    "\n",
    "if args.enable_bfa:\n",
    "    perform_attack(attacker, net, net_clean, train_loader, test_loader,\n",
    "                   args.n_iter, writer, csv_save_path=args.save_path,\n",
    "                   random_attack=args.random_bfa)\n",
    "\n",
    "if args.evaluate:\n",
    "    print(\"Evaluate mode\")\n",
    "    _, _, _, output_summary = validate(test_loader, net, criterion, summary_output=True)\n",
    "    pd.DataFrame(output_summary).to_csv(os.path.join(args.save_path, 'output_summary_{}.csv'.format(args.arch)),\n",
    "                                        header=['top-1 output'], index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bede100-21b0-4bf2-9614-b17a15142bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, gammas, schedule):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.learning_rate\n",
    "    mu = args.momentum\n",
    "\n",
    "    if args.optimizer != \"YF\":\n",
    "        assert len(gammas) == len(\n",
    "            schedule), \"length of gammas and schedule should be equal\"\n",
    "        for (gamma, step) in zip(gammas, schedule):\n",
    "            if (epoch >= step):\n",
    "                lr = lr * gamma\n",
    "            else:\n",
    "                break\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "    elif args.optimizer == \"YF\":\n",
    "        lr = optimizer._lr\n",
    "        mu = optimizer._mu\n",
    "\n",
    "    return lr, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbd7e109-0734-4e16-8a5b-e19358496855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 0 with seed: 4055\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "if args.ngpu == 1:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(\n",
    "        args.gpu_id)  # make only device #gpu_id visible, then\n",
    "\n",
    "args.use_cuda = args.ngpu > 0 and torch.cuda.is_available()  # check GPU\n",
    "\n",
    "# Give a random seed if no manual configuration\n",
    "if args.manualSeed is None:\n",
    "    args.manualSeed = random.randint(1, 10000)\n",
    "random.seed(args.manualSeed)\n",
    "torch.manual_seed(args.manualSeed)\n",
    "\n",
    "if args.use_cuda:\n",
    "    torch.cuda.manual_seed_all(args.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if args.use_cuda:\n",
    "    print(f\"Using GPU: {args.gpu_id} with seed: {args.manualSeed}\")\n",
    "else:\n",
    "    print(f\"Using CPU with seed: {args.manualSeed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48cb46-c3f3-4b1c-a3e0-63b33685a7b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train Loss: 0.7406, Train MCC: 0.5643\n",
      "Validation Loss: 0.4460, Validation MCC: 0.7018\n",
      "Epoch 2/50\n",
      "Train Loss: 0.4329, Train MCC: 0.7229\n",
      "Validation Loss: 0.4338, Validation MCC: 0.7138\n",
      "Epoch 3/50\n",
      "Train Loss: 0.3801, Train MCC: 0.7500\n",
      "Validation Loss: 0.3317, Validation MCC: 0.7802\n",
      "Epoch 4/50\n",
      "Train Loss: 0.3366, Train MCC: 0.7679\n",
      "Validation Loss: 0.3185, Validation MCC: 0.7755\n",
      "Epoch 5/50\n",
      "Train Loss: 0.3153, Train MCC: 0.7809\n",
      "Validation Loss: 0.2930, Validation MCC: 0.7961\n",
      "Epoch 6/50\n",
      "Train Loss: 0.3020, Train MCC: 0.7918\n",
      "Validation Loss: 0.2831, Validation MCC: 0.8030\n",
      "Epoch 7/50\n",
      "Train Loss: 0.2889, Train MCC: 0.8049\n",
      "Validation Loss: 0.2698, Validation MCC: 0.8283\n",
      "Epoch 8/50\n",
      "Train Loss: 0.2760, Train MCC: 0.8158\n",
      "Validation Loss: 0.2478, Validation MCC: 0.8370\n",
      "Epoch 9/50\n",
      "Train Loss: 0.2671, Train MCC: 0.8215\n",
      "Validation Loss: 0.2484, Validation MCC: 0.8349\n",
      "Epoch 10/50\n",
      "Train Loss: 0.2569, Train MCC: 0.8279\n",
      "Validation Loss: 0.2853, Validation MCC: 0.8056\n",
      "Epoch 11/50\n",
      "Train Loss: 0.2494, Train MCC: 0.8326\n",
      "Validation Loss: 0.2333, Validation MCC: 0.8444\n",
      "Epoch 12/50\n",
      "Train Loss: 0.2413, Train MCC: 0.8369\n",
      "Validation Loss: 0.2270, Validation MCC: 0.8453\n",
      "Epoch 13/50\n",
      "Train Loss: 0.2369, Train MCC: 0.8394\n",
      "Validation Loss: 0.2300, Validation MCC: 0.8384\n",
      "Epoch 14/50\n",
      "Train Loss: 0.2302, Train MCC: 0.8433\n",
      "Validation Loss: 0.2182, Validation MCC: 0.8485\n",
      "Epoch 15/50\n",
      "Train Loss: 0.2270, Train MCC: 0.8451\n",
      "Validation Loss: 0.2145, Validation MCC: 0.8484\n",
      "Epoch 16/50\n",
      "Train Loss: 0.2228, Train MCC: 0.8473\n",
      "Validation Loss: 0.2199, Validation MCC: 0.8475\n",
      "Epoch 17/50\n",
      "Train Loss: 0.2192, Train MCC: 0.8487\n",
      "Validation Loss: 0.2157, Validation MCC: 0.8514\n",
      "Epoch 18/50\n",
      "Train Loss: 0.2160, Train MCC: 0.8509\n",
      "Validation Loss: 0.2019, Validation MCC: 0.8565\n",
      "Epoch 19/50\n",
      "Train Loss: 0.2135, Train MCC: 0.8522\n",
      "Validation Loss: 0.2052, Validation MCC: 0.8547\n",
      "Epoch 20/50\n",
      "Train Loss: 0.2120, Train MCC: 0.8537\n",
      "Validation Loss: 0.2048, Validation MCC: 0.8540\n",
      "Epoch 21/50\n",
      "Train Loss: 0.2083, Train MCC: 0.8551\n",
      "Validation Loss: 0.2075, Validation MCC: 0.8519\n",
      "Epoch 22/50\n",
      "Train Loss: 0.2070, Train MCC: 0.8563\n",
      "Validation Loss: 0.2050, Validation MCC: 0.8551\n",
      "Epoch 23/50\n",
      "Train Loss: 0.2050, Train MCC: 0.8569\n",
      "Validation Loss: 0.1937, Validation MCC: 0.8594\n",
      "Epoch 24/50\n",
      "Train Loss: 0.2046, Train MCC: 0.8568\n",
      "Validation Loss: 0.1990, Validation MCC: 0.8557\n",
      "Epoch 25/50\n",
      "Train Loss: 0.2027, Train MCC: 0.8593\n",
      "Validation Loss: 0.1973, Validation MCC: 0.8584\n",
      "Epoch 26/50\n",
      "Train Loss: 0.2001, Train MCC: 0.8609\n",
      "Validation Loss: 0.1950, Validation MCC: 0.8604\n",
      "Epoch 27/50\n",
      "Train Loss: 0.1990, Train MCC: 0.8604\n",
      "Validation Loss: 0.2002, Validation MCC: 0.8649\n",
      "Epoch 28/50\n",
      "Train Loss: 0.1968, Train MCC: 0.8627\n",
      "Validation Loss: 0.1949, Validation MCC: 0.8615\n",
      "Epoch 29/50\n",
      "Train Loss: 0.1949, Train MCC: 0.8645\n",
      "Validation Loss: 0.1887, Validation MCC: 0.8746\n",
      "Epoch 30/50\n",
      "Train Loss: 0.1941, Train MCC: 0.8653\n",
      "Validation Loss: 0.1873, Validation MCC: 0.8680\n",
      "Epoch 31/50\n",
      "Train Loss: 0.1923, Train MCC: 0.8664\n",
      "Validation Loss: 0.1872, Validation MCC: 0.8722\n",
      "Epoch 32/50\n",
      "Train Loss: 0.1909, Train MCC: 0.8675\n",
      "Validation Loss: 0.1945, Validation MCC: 0.8610\n",
      "Epoch 33/50\n",
      "Train Loss: 0.1894, Train MCC: 0.8687\n",
      "Validation Loss: 0.1802, Validation MCC: 0.8757\n",
      "Epoch 34/50\n",
      "Train Loss: 0.1883, Train MCC: 0.8704\n",
      "Validation Loss: 0.1903, Validation MCC: 0.8683\n",
      "Epoch 35/50\n",
      "Train Loss: 0.1859, Train MCC: 0.8712\n",
      "Validation Loss: 0.1954, Validation MCC: 0.8687\n",
      "Epoch 36/50\n",
      "Train Loss: 0.1849, Train MCC: 0.8712\n",
      "Validation Loss: 0.1923, Validation MCC: 0.8669\n",
      "Epoch 37/50\n",
      "Train Loss: 0.1850, Train MCC: 0.8722\n",
      "Validation Loss: 0.1932, Validation MCC: 0.8647\n",
      "Epoch 38/50\n",
      "Train Loss: 0.1814, Train MCC: 0.8751\n",
      "Validation Loss: 0.1791, Validation MCC: 0.8718\n",
      "Epoch 39/50\n",
      "Train Loss: 0.1803, Train MCC: 0.8758\n",
      "Validation Loss: 0.1761, Validation MCC: 0.8764\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomModel().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Số epoch để chờ trước khi dừng\n",
    "counter = 0\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Vòng lặp huấn luyện\n",
    "best_val_loss = float('inf')\n",
    "best_mcc = -1  # Khởi tạo MCC tốt nhất\n",
    "\n",
    "# Vòng lặp huấn luyện\n",
    "for epoch in range(num_epochs):\n",
    "    train_mcc, train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    val_mcc, val_loss, output_summary = validate(test_loader, model, criterion, summary_output=True)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_mcc = val_mcc  # Lưu MCC tốt nhất\n",
    "        counter = 0\n",
    "\n",
    "        save_dir = \"CustomModel\"\n",
    "        save_path = os.path.join(save_dir, \"best_model.pth\")\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train MCC: {train_mcc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation MCC: {val_mcc:.4f}\")\n",
    "print(f\"Best MCC during training: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d48ac-3ec1-42da-a557-591fbb18f1e1",
   "metadata": {},
   "source": [
    "## Random Attack\n",
    "\n",
    "### import data_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca572d-36ef-4fd7-86cb-aa4958463a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2bin(input, num_bits):\n",
    "    '''\n",
    "    convert the signed integer value into unsigned integer (2's complement equivalently).\n",
    "    Note that, the conversion is different depends on number of bit used.\n",
    "    '''\n",
    "    output = input.clone()\n",
    "    if num_bits == 1: # when it is binary, the conversion is different\n",
    "        output = output/2 + .5\n",
    "    elif num_bits > 1:\n",
    "        output[input.lt(0)] = 2**num_bits + output[input.lt(0)]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def bin2int(input, num_bits):\n",
    "    '''\n",
    "    convert the unsigned integer (2's complement equivantly) back to the signed integer format\n",
    "    with the bitwise operations. Note that, in order to perform the bitwise operation, the input\n",
    "    tensor has to be in the integer format.\n",
    "    '''\n",
    "    if num_bits == 1:\n",
    "        output = input*2-1\n",
    "    elif num_bits > 1:\n",
    "        mask = 2**(num_bits - 1) - 1\n",
    "        output = -(input & ~mask) + (input & mask)\n",
    "    return output\n",
    "\n",
    "\n",
    "def weight_conversion(model):\n",
    "    '''\n",
    "    Perform the weight data type conversion between:\n",
    "        signed integer <==> two's complement (unsigned integer)\n",
    "    Such conversion is used as additional step to ensure the conversion correctness\n",
    "\n",
    "    Note that, the data type conversion chosen is depend on the bits:\n",
    "        N_bits <= 8   .char()   --> torch.CharTensor(), 8-bit signed integer\n",
    "        N_bits <= 16  .short()  --> torch.shortTensor(), 16 bit signed integer\n",
    "        N_bits <= 32  .int()    --> torch.IntTensor(), 32 bit signed integer\n",
    "    '''\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, quan_Conv1d) or isinstance(m, quan_Linear):\n",
    "            w_bin = int2bin(m.weight.data, m.N_bits).short()\n",
    "            m.weight.data = bin2int(w_bin, m.N_bits).float()\n",
    "    return\n",
    "\n",
    "def count_ones(t, n_bits):\n",
    "    counter = 0\n",
    "    for i in range(n_bits):\n",
    "        counter += ((t & 2**i) // 2**i).sum()\n",
    "    return counter.item()\n",
    "\n",
    "\n",
    "def hamming_distance(model1, model2):\n",
    "    '''\n",
    "    Given two model whose structure, name and so on are identical.\n",
    "    The only difference between the model1 and model2 are the weight.\n",
    "    The function compute the hamming distance bewtween the bianry weights\n",
    "    (two's complement) of model1 and model2.\n",
    "    '''\n",
    "    # TODO: add the function check model1 and model2 are same structure\n",
    "    # check the keys of state_dict match or not.\n",
    "\n",
    "    H_dist = 0  # hamming distance counter\n",
    "\n",
    "    for name, module in model1.named_modules():\n",
    "        if isinstance(module, quan_Conv1d) or isinstance(module, quan_Linear):\n",
    "            # remember to convert the tensor into integer for bitwise operations\n",
    "            binW_model1 = int2bin(model1.state_dict()[name + '.weight'],\n",
    "                                  module.N_bits).short()\n",
    "            binW_model2 = int2bin(model2.state_dict()[name + '.weight'],\n",
    "                                  module.N_bits).short()\n",
    "            H_dist += count_ones(binW_model1 ^ binW_model2, module.N_bits)\n",
    "\n",
    "    return H_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f209d-6392-4a4c-afce-986fa0128d9b",
   "metadata": {},
   "source": [
    "## Vẽ đồ thị MCC sau mỗi epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce8a7d-bea3-4e5b-a69e-dc8224dd1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mcc_vs_bit_flipped(image_filename, x_data, y_data):\n",
    "    \"\"\"\n",
    "    Plots a graph of MCC vs Bit Flipped and saves it as an image file.\n",
    "\n",
    "    Parameters:\n",
    "        image_filename (str): The name of the output image file (e.g., 'output.png').\n",
    "        x_data (list or array): Data for the x-axis (Bit Flipped).\n",
    "        y_data (list or array): Data for the y-axis (MCC).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if len(x_data) != len(y_data):\n",
    "        raise ValueError(\"x_data and y_data must have the same length.\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x_data, y_data, marker='o', linestyle='-', color='b', label='MCC')\n",
    "    plt.title('MCC after Epochs', fontsize=14)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('MCC', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot as an image file\n",
    "    plt.savefig(image_filename)\n",
    "    plt.close()\n",
    "    print(f\"Plot saved as {image_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7df3e7-c55b-4690-be7c-cfd6f344f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def perform_attack(attacker, model, model_clean, train_loader, test_loader,\n",
    "                   N_iter, writer, file, csv_file, csv_save_path=None, attack_type=1,):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    iter_time = AverageMeter()\n",
    "    attack_time = AverageMeter()\n",
    "\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "        if args.use_cuda:\n",
    "            target = target.cuda()\n",
    "            data = data.cuda()\n",
    "\n",
    "        data = data.unsqueeze(-1)  # Kích thước [512, 69, 1]\n",
    "        _, target = model(data).data.max(1)\n",
    "        break\n",
    "\n",
    "    val_acc_top1, val_loss, output_summary = validate(test_loader, model, attacker.criterion, summary_output=True)\n",
    "    print(f'**Test** MCC: {val_acc_top1:.3f}. Val_Loss: {val_loss:.3f}')\n",
    "\n",
    "    tmp_df = pd.DataFrame(output_summary)\n",
    "    tmp_df['BFA iteration'] = 0\n",
    "    tmp_df.to_csv(os.path.join(args.save_path, 'output_summary_{}_BFA_0.csv'.format(args.arch)), index=False)\n",
    "\n",
    "    writer.add_scalar('attack/val_top1_acc', val_acc_top1, 0)\n",
    "    writer.add_scalar('attack/val_loss', val_loss, 0)\n",
    "\n",
    "    print('Attack sample size is {}'.format(data.size()[0]))\n",
    "    end = time.time()\n",
    "    df = pd.DataFrame()\n",
    "    last_val_acc_top1 = val_acc_top1\n",
    "\n",
    "    MCC_data = [val_acc_top1]\n",
    "    Bit_flipped = [0]\n",
    "    all_attack_status = []\n",
    "\n",
    "    for i_iter in range(N_iter):\n",
    "        print('**********************************')        \n",
    "        if attack_type == 1:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            MCC_data.append(new_mcc)\n",
    "            Bit_flipped.append(bit_count)\n",
    "        elif attack_type == 2:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            MCC_data.append(new_mcc)\n",
    "            Bit_flipped.append(bit_count)\n",
    "        elif attack_type == 3:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            MCC_data.append(new_mcc)\n",
    "            Bit_flipped.append(bit_count)\n",
    "        elif attack_type == 4:\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.random_flip_one_bit(model, test_loader)\n",
    "            attack_log, new_mcc, bit_count, attack_last_status = attacker.progressive_bit_search(model, data, target, test_loader)\n",
    "            MCC_data.append(new_mcc)\n",
    "            Bit_flipped.append(bit_count)\n",
    "        \n",
    "        attack_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        h_dist = hamming_distance(model, model_clean)\n",
    "\n",
    "        if hasattr(attacker, \"loss_max\"):\n",
    "            losses.update(attacker.loss_max, data.size(0))\n",
    "\n",
    "        print('Iteration: [{:03d}/{:03d}]   Attack Time {attack_time.val:.3f} ({attack_time.avg:.3f})'.format(i_iter + 1, N_iter, attack_time=attack_time))\n",
    "\n",
    "        try:\n",
    "            print('Loss before attack: {:.4f}'.format(attacker.loss.item()))\n",
    "            print('Loss after attack: {:.4f}'.format(attacker.loss_max))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        print('Bit flips: {:.0f}'.format(attacker.bit_counter))\n",
    "        print('Hamming distance: {:.0f}'.format(h_dist))\n",
    "\n",
    "        writer.add_scalar('attack/bit_flip', attacker.bit_counter, i_iter + 1)\n",
    "        writer.add_scalar('attack/h_dist', h_dist, i_iter + 1)\n",
    "        writer.add_scalar('attack/sample_loss', losses.avg, i_iter + 1)\n",
    "\n",
    "        val_acc_top1, val_loss, output_summary = validate(test_loader, model, attacker.criterion, summary_output=True)\n",
    "        print(f'**Test** MCC: {val_acc_top1:.3f}. Val_Loss: {val_loss:.3f}')\n",
    "        tmp_df = pd.DataFrame(output_summary)\n",
    "        tmp_df['BFA iteration'] = i_iter + 1\n",
    "        tmp_df.to_csv(os.path.join(args.save_path, 'output_summary_{}_BFA_{}.csv'.format(args.arch, i_iter + 1)), index=False)\n",
    "\n",
    "        acc_drop = last_val_acc_top1 - val_acc_top1\n",
    "        last_val_acc_top1 = val_acc_top1\n",
    "\n",
    "        attack_last_status.append(val_acc_top1)\n",
    "        attack_last_status.append(acc_drop)\n",
    "\n",
    "        for entry in attack_log:\n",
    "            entry.append(val_acc_top1)\n",
    "            entry.append(acc_drop)\n",
    "            \n",
    "        df = pd.concat([df, pd.DataFrame(attack_log)], ignore_index=True)\n",
    "\n",
    "        writer.add_scalar('attack/val_top1_acc', val_acc_top1, i_iter + 1)\n",
    "        writer.add_scalar('attack/val_loss', val_loss, i_iter + 1)\n",
    "\n",
    "        iter_time.update(time.time() - end)\n",
    "        print('Iteration Time {iter_time.val:.3f} ({iter_time.avg:.3f})'.format(iter_time=iter_time))\n",
    "        end = time.time()\n",
    "\n",
    "        all_attack_status.append(attack_last_status)\n",
    "\n",
    "    column_list = ['module idx', 'bit-flip idx', 'module name', 'weight idx', 'weight before attack', 'weight after attack', 'validation mcc', 'mcc drop']\n",
    "    df.columns = column_list\n",
    "    df['trial seed'] = args.manualSeed\n",
    "\n",
    "    if csv_save_path is not None:\n",
    "        csv_file_name = 'attack_profile_{}.csv'.format(args.manualSeed)\n",
    "        df.to_csv(os.path.join(csv_save_path, csv_file_name), index=None)\n",
    "\n",
    "    # Vẽ đồ thị\n",
    "    plot_mcc_vs_bit_flipped(file, Bit_flipped, MCC_data)\n",
    "    \n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Ghi tiêu đề (nếu cần)\n",
    "        writer.writerow([\"Bit Counter\", \"Module\", \"Weight Before Attack\", \"Weight After Attack\", \"Validation\", \"MCC Drop\"])\n",
    "        \n",
    "        # Ghi dữ liệu\n",
    "        writer.writerows(all_attack_status)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f57a1b3-406b-4238-a9d7-40de139a9083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC before attack: 0.8908100339695398\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "# Kiểm tra xem tệp có tồn tại không\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "best_mcc = test(trained_model, test_loader)\n",
    "print(f\"MCC before attack: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d8058e6-93dd-406f-af0e-141023047ec5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.887. Val_Loss: 0.160\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: fc1\n",
      "Iteration: [001/020]   Attack Time 4.550 (4.550)\n",
      "Loss before attack: 0.0837\n",
      "Loss after attack: 7.4060\n",
      "Bit flips: 1\n",
      "Hamming distance: 1\n",
      "**Test** MCC: 0.385. Val_Loss: 10.673\n",
      "Iteration Time 3.491 (3.491)\n",
      "**********************************\n",
      "attacked module: stage_2.7.conv_a\n",
      "Iteration: [002/020]   Attack Time 4.979 (4.765)\n",
      "Loss before attack: 7.4060\n",
      "Loss after attack: 886.4497\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: -0.154. Val_Loss: 855.743\n",
      "Iteration Time 3.502 (3.497)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_a\n",
      "Iteration: [003/020]   Attack Time 4.240 (4.590)\n",
      "Loss before attack: 886.4497\n",
      "Loss after attack: 24708.7852\n",
      "Bit flips: 3\n",
      "Hamming distance: 3\n",
      "**Test** MCC: -0.149. Val_Loss: 23836.795\n",
      "Iteration Time 3.443 (3.479)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_b\n",
      "Iteration: [004/020]   Attack Time 4.532 (4.575)\n",
      "Loss before attack: 24708.7852\n",
      "Loss after attack: 2771054.2500\n",
      "Bit flips: 4\n",
      "Hamming distance: 4\n",
      "**Test** MCC: -0.171. Val_Loss: 2673626.502\n",
      "Iteration Time 3.603 (3.510)\n",
      "**********************************\n",
      "attacked module: stage_3.0.conv_a\n",
      "Iteration: [005/020]   Attack Time 5.763 (4.813)\n",
      "Loss before attack: 2771054.2500\n",
      "Loss after attack: 70556552.0000\n",
      "Bit flips: 5\n",
      "Hamming distance: 5\n",
      "**Test** MCC: 0.077. Val_Loss: 77624785.264\n",
      "Iteration Time 3.497 (3.507)\n",
      "**********************************\n",
      "attacked module: stage_2.7.conv_b\n",
      "Iteration: [006/020]   Attack Time 5.006 (4.845)\n",
      "Loss before attack: 70556552.0000\n",
      "Loss after attack: 14962988032.0000\n",
      "Bit flips: 6\n",
      "Hamming distance: 6\n",
      "**Test** MCC: 0.076. Val_Loss: 16481804427.672\n",
      "Iteration Time 3.453 (3.498)\n",
      "**********************************\n",
      "attacked module: stage_3.3.conv_b\n",
      "Iteration: [007/020]   Attack Time 7.901 (5.281)\n",
      "Loss before attack: 14962988032.0000\n",
      "Loss after attack: 670069620736.0000\n",
      "Bit flips: 7\n",
      "Hamming distance: 7\n",
      "**Test** MCC: -0.104. Val_Loss: 631336021203.635\n",
      "Iteration Time 3.457 (3.492)\n",
      "**********************************\n",
      "attacked module: stage_3.3.conv_a\n",
      "Iteration: [008/020]   Attack Time 7.812 (5.598)\n",
      "Loss before attack: 670069620736.0000\n",
      "Loss after attack: 33198515945472.0000\n",
      "Bit flips: 8\n",
      "Hamming distance: 8\n",
      "**Test** MCC: -0.102. Val_Loss: 31278675038823.113\n",
      "Iteration Time 3.502 (3.494)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_a\n",
      "Iteration: [009/020]   Attack Time 4.147 (5.437)\n",
      "Loss before attack: 33198515945472.0000\n",
      "Loss after attack: 460800699400192.0000\n",
      "Bit flips: 9\n",
      "Hamming distance: 9\n",
      "**Test** MCC: -0.103. Val_Loss: 434164468703825.812\n",
      "Iteration Time 3.436 (3.487)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_b\n",
      "Iteration: [010/020]   Attack Time 4.268 (5.320)\n",
      "Loss before attack: 460800699400192.0000\n",
      "Loss after attack: 50842426985676800.0000\n",
      "Bit flips: 10\n",
      "Hamming distance: 10\n",
      "**Test** MCC: -0.103. Val_Loss: 47902012923096376.000\n",
      "Iteration Time 3.516 (3.490)\n",
      "**********************************\n",
      "attacked module: stage_3.2.conv_b\n",
      "Iteration: [011/020]   Attack Time 7.952 (5.559)\n",
      "Loss before attack: 50842426985676800.0000\n",
      "Loss after attack: 686547292450193408.0000\n",
      "Bit flips: 11\n",
      "Hamming distance: 11\n",
      "**Test** MCC: -0.111. Val_Loss: 646875644056000384.000\n",
      "Iteration Time 3.510 (3.492)\n",
      "**********************************\n",
      "attacked module: stage_3.2.conv_a\n",
      "Iteration: [012/020]   Attack Time 8.238 (5.782)\n",
      "Loss before attack: 686547292450193408.0000\n",
      "Loss after attack: 45238433956564566016.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 12\n",
      "**Test** MCC: -0.006. Val_Loss: 42624757368370708480.000\n",
      "Iteration Time 3.659 (3.506)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_b\n",
      "Iteration: [013/020]   Attack Time 7.765 (5.935)\n",
      "Loss before attack: 45238433956564566016.0000\n",
      "Loss after attack: 1389115320339083034624.0000\n",
      "Bit flips: 13\n",
      "Hamming distance: 13\n",
      "**Test** MCC: -0.091. Val_Loss: 1308747406604271353856.000\n",
      "Iteration Time 3.541 (3.509)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_a\n",
      "Iteration: [014/020]   Attack Time 7.895 (6.075)\n",
      "Loss before attack: 1389115320339083034624.0000\n",
      "Loss after attack: 71997997904058942226432.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 14\n",
      "**Test** MCC: -0.101. Val_Loss: 67836805233907909787648.000\n",
      "Iteration Time 3.620 (3.517)\n",
      "**********************************\n",
      "attacked module: stage_3.0.conv_b\n",
      "Iteration: [015/020]   Attack Time 8.069 (6.208)\n",
      "Loss before attack: 71997997904058942226432.0000\n",
      "Loss after attack: 15985988766529358670069760.0000\n",
      "Bit flips: 15\n",
      "Hamming distance: 15\n",
      "**Test** MCC: -0.101. Val_Loss: 15061280392249355593056256.000\n",
      "Iteration Time 3.484 (3.514)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [016/020]   Attack Time 4.163 (6.080)\n",
      "Loss before attack: 15985988766529358670069760.0000\n",
      "Loss after attack: 213567031939419744157827072.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 15\n",
      "**Test** MCC: -0.103. Val_Loss: 200121884560339772830121984.000\n",
      "Iteration Time 3.451 (3.510)\n",
      "**********************************\n",
      "attacked module: stage_3.13.conv_a\n",
      "Iteration: [017/020]   Attack Time 7.876 (6.186)\n",
      "Loss before attack: 213567031939419744157827072.0000\n",
      "Loss after attack: 2839314583684029162855596032.0000\n",
      "Bit flips: 17\n",
      "Hamming distance: 16\n",
      "**Test** MCC: -0.102. Val_Loss: 2672990198045220272548610048.000\n",
      "Iteration Time 3.591 (3.515)\n",
      "**********************************\n",
      "attacked module: stage_1.10.conv_b\n",
      "Iteration: [018/020]   Attack Time 4.326 (6.082)\n",
      "Loss before attack: 2839314583684029162855596032.0000\n",
      "Loss after attack: 31626951568812181626216775680.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 17\n",
      "**Test** MCC: -0.091. Val_Loss: 29772958319126501198691041280.000\n",
      "Iteration Time 3.536 (3.516)\n",
      "**********************************\n",
      "attacked module: stage_1.10.conv_a\n",
      "Iteration: [019/020]   Attack Time 4.372 (5.992)\n",
      "Loss before attack: 31626951568812181626216775680.0000\n",
      "Loss after attack: 3744474547632654073023103500288.0000\n",
      "Bit flips: 19\n",
      "Hamming distance: 18\n",
      "**Test** MCC: -0.104. Val_Loss: 3525472036713935368870229442560.000\n",
      "Iteration Time 3.619 (3.522)\n",
      "**********************************\n",
      "attacked module: stage_1.2.conv_b\n",
      "Iteration: [020/020]   Attack Time 5.290 (5.957)\n",
      "Loss before attack: 3744474547632654073023103500288.0000\n",
      "Loss after attack: 31879071631782867679708184576000.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 19\n",
      "**Test** MCC: -0.102. Val_Loss: 30010431831637358711013686378496.000\n",
      "Iteration Time 3.857 (3.538)\n",
      "Plot saved as CustomModel/PBS_attack/PBS_attack.png\n",
      "\n",
      "MCC after 100 times PBS attack: -0.10189083745635426\n"
     ]
    }
   ],
   "source": [
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_path = os.path.join(attack_dir, \"PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_path,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 1,                  # Chế độ tấn công PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "best_mcc = test(trained_model, test_loader)\n",
    "print(f\"\\nMCC after 100 times PBS attack: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31bd74aa-83fe-4388-9e48-e018219c5c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.901. Val_Loss: 0.148\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_a\n",
      "attacked weight index: 2114\n",
      "weight before attack: tensor(-0.1289, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [001/020]   Attack Time 2.971 (2.971)\n",
      "Bit flips: 1\n",
      "Hamming distance: 1\n",
      "**Test** MCC: 0.901. Val_Loss: 0.148\n",
      "Iteration Time 3.585 (3.585)\n",
      "**********************************\n",
      "attacked module: stage_2.3.conv_b\n",
      "attacked weight index: 10576\n",
      "weight before attack: tensor(-0.0852, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [002/020]   Attack Time 3.001 (2.986)\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.901. Val_Loss: 0.148\n",
      "Iteration Time 3.489 (3.537)\n",
      "**********************************\n",
      "attacked module: stage_3.11.conv_b\n",
      "attacked weight index: 35382\n",
      "weight before attack: tensor(-0.0057, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [003/020]   Attack Time 2.959 (2.977)\n",
      "Bit flips: 3\n",
      "Hamming distance: 3\n",
      "**Test** MCC: 0.901. Val_Loss: 0.148\n",
      "Iteration Time 3.579 (3.551)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 307\n",
      "weight before attack: tensor(0.0367, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [004/020]   Attack Time 2.993 (2.981)\n",
      "Bit flips: 4\n",
      "Hamming distance: 3\n",
      "**Test** MCC: 0.392. Val_Loss: 22.496\n",
      "Iteration Time 3.460 (3.528)\n",
      "**********************************\n",
      "attacked module: stage_3.12.conv_b\n",
      "attacked weight index: 22200\n",
      "weight before attack: tensor(-0.1360, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [005/020]   Attack Time 2.970 (2.979)\n",
      "Bit flips: 5\n",
      "Hamming distance: 4\n",
      "**Test** MCC: 0.392. Val_Loss: 22.496\n",
      "Iteration Time 3.602 (3.543)\n",
      "**********************************\n",
      "attacked module: stage_1.6.conv_b\n",
      "attacked weight index: 302\n",
      "weight before attack: tensor(0.0088, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [006/020]   Attack Time 2.872 (2.961)\n",
      "Bit flips: 6\n",
      "Hamming distance: 5\n",
      "**Test** MCC: 0.392. Val_Loss: 22.496\n",
      "Iteration Time 3.560 (3.546)\n",
      "**********************************\n",
      "attacked module: stage_1.4.conv_b\n",
      "attacked weight index: 147\n",
      "weight before attack: tensor(0.0539, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [007/020]   Attack Time 2.985 (2.964)\n",
      "Bit flips: 7\n",
      "Hamming distance: 6\n",
      "**Test** MCC: 0.392. Val_Loss: 22.496\n",
      "Iteration Time 3.537 (3.545)\n",
      "**********************************\n",
      "attacked module: stage_2.3.conv_b\n",
      "attacked weight index: 2190\n",
      "weight before attack: tensor(0.0228, device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "Iteration: [008/020]   Attack Time 3.023 (2.972)\n",
      "Bit flips: 8\n",
      "Hamming distance: 7\n",
      "**Test** MCC: 0.392. Val_Loss: 22.496\n",
      "Iteration Time 3.524 (3.542)\n",
      "**********************************\n",
      "attacked module: stage_3.14.conv_a\n",
      "attacked weight index: 28957\n",
      "weight before attack: tensor(-0.0166, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [009/020]   Attack Time 3.012 (2.976)\n",
      "Bit flips: 9\n",
      "Hamming distance: 8\n",
      "**Test** MCC: 0.372. Val_Loss: 22.785\n",
      "Iteration Time 3.599 (3.548)\n",
      "**********************************\n",
      "attacked module: stage_2.11.conv_a\n",
      "attacked weight index: 285\n",
      "weight before attack: tensor(-0.0641, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "Iteration: [010/020]   Attack Time 2.996 (2.978)\n",
      "Bit flips: 10\n",
      "Hamming distance: 9\n",
      "**Test** MCC: 0.372. Val_Loss: 22.785\n",
      "Iteration Time 3.526 (3.546)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_a\n",
      "attacked weight index: 407\n",
      "weight before attack: tensor(0.0330, device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "Iteration: [011/020]   Attack Time 2.980 (2.978)\n",
      "Bit flips: 11\n",
      "Hamming distance: 10\n",
      "**Test** MCC: 0.372. Val_Loss: 22.785\n",
      "Iteration Time 3.489 (3.541)\n",
      "**********************************\n",
      "attacked module: stage_3.0.conv_a\n",
      "attacked weight index: 282\n",
      "weight before attack: tensor(0.0052, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [012/020]   Attack Time 2.970 (2.978)\n",
      "Bit flips: 12\n",
      "Hamming distance: 11\n",
      "**Test** MCC: 0.372. Val_Loss: 22.785\n",
      "Iteration Time 3.619 (3.547)\n",
      "**********************************\n",
      "attacked module: stage_2.6.conv_b\n",
      "attacked weight index: 4251\n",
      "weight before attack: tensor(0.0115, device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "Iteration: [013/020]   Attack Time 3.040 (2.983)\n",
      "Bit flips: 13\n",
      "Hamming distance: 12\n",
      "**Test** MCC: 0.372. Val_Loss: 22.785\n",
      "Iteration Time 3.590 (3.551)\n",
      "**********************************\n",
      "attacked module: stage_3.2.conv_b\n",
      "attacked weight index: 25278\n",
      "weight before attack: tensor(-0.0696, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [014/020]   Attack Time 2.985 (2.983)\n",
      "Bit flips: 14\n",
      "Hamming distance: 13\n",
      "**Test** MCC: 0.372. Val_Loss: 22.785\n",
      "Iteration Time 3.521 (3.549)\n",
      "**********************************\n",
      "attacked module: stage_1.5.conv_b\n",
      "attacked weight index: 2262\n",
      "weight before attack: tensor(0.0611, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "Iteration: [015/020]   Attack Time 2.938 (2.980)\n",
      "Bit flips: 15\n",
      "Hamming distance: 14\n",
      "**Test** MCC: 0.372. Val_Loss: 22.785\n",
      "Iteration Time 3.509 (3.546)\n",
      "**********************************\n",
      "attacked module: stage_3.0.conv_a\n",
      "attacked weight index: 21124\n",
      "weight before attack: tensor(0.2809, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [016/020]   Attack Time 3.018 (2.982)\n",
      "Bit flips: 16\n",
      "Hamming distance: 15\n",
      "**Test** MCC: 0.374. Val_Loss: 22.194\n",
      "Iteration Time 3.504 (3.543)\n",
      "**********************************\n",
      "attacked module: stage_3.14.conv_a\n",
      "attacked weight index: 19504\n",
      "weight before attack: tensor(-0.0192, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [017/020]   Attack Time 3.048 (2.986)\n",
      "Bit flips: 17\n",
      "Hamming distance: 16\n",
      "**Test** MCC: 0.374. Val_Loss: 22.198\n",
      "Iteration Time 3.544 (3.543)\n",
      "**********************************\n",
      "attacked module: stage_2.8.conv_a\n",
      "attacked weight index: 4727\n",
      "weight before attack: tensor(0.0560, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "Iteration: [018/020]   Attack Time 2.960 (2.985)\n",
      "Bit flips: 18\n",
      "Hamming distance: 17\n",
      "**Test** MCC: 0.374. Val_Loss: 22.198\n",
      "Iteration Time 3.494 (3.541)\n",
      "**********************************\n",
      "attacked module: stage_2.3.conv_a\n",
      "attacked weight index: 4573\n",
      "weight before attack: tensor(0.1932, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [019/020]   Attack Time 3.007 (2.986)\n",
      "Bit flips: 19\n",
      "Hamming distance: 18\n",
      "**Test** MCC: 0.374. Val_Loss: 22.198\n",
      "Iteration Time 3.487 (3.538)\n",
      "**********************************\n",
      "attacked module: stage_1.13.conv_a\n",
      "attacked weight index: 1820\n",
      "weight before attack: tensor(-0.0539, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [020/020]   Attack Time 2.982 (2.986)\n",
      "Bit flips: 20\n",
      "Hamming distance: 19\n",
      "**Test** MCC: 0.374. Val_Loss: 22.198\n",
      "Iteration Time 3.531 (3.537)\n",
      "Plot saved as CustomModel/RandomFlip_attack/RandomFlip_attack.png\n",
      "\n",
      "MCC after 100 times random attack: 0.3737262318896209\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_path = os.path.join(attack_dir, \"RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_path,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 2,                  # Chế độ tấn công random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "\n",
    "best_mcc = test(trained_model ,test_loader)\n",
    "print(f\"\\nMCC after 100 times random attack: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0b8375d-ecc2-40d2-b41a-97f243b4c903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.901. Val_Loss: 0.148\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: fc1\n",
      "attacked module: stage_2.1.conv_a\n",
      "attacked weight index: 10109\n",
      "weight before attack: tensor(-0.0404, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [001/020]   Attack Time 7.502 (7.502)\n",
      "Loss before attack: 0.0902\n",
      "Loss after attack: 8.4606\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.029. Val_Loss: 9.544\n",
      "Iteration Time 3.490 (3.490)\n",
      "**********************************\n",
      "attacked module: stage_2.7.conv_a\n",
      "attacked module: stage_1.7.conv_a\n",
      "attacked weight index: 1441\n",
      "weight before attack: tensor(0.0160, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [002/020]   Attack Time 8.271 (7.887)\n",
      "Loss before attack: 8.4606\n",
      "Loss after attack: 468.9542\n",
      "Bit flips: 4\n",
      "Hamming distance: 4\n",
      "**Test** MCC: 0.003. Val_Loss: 464.584\n",
      "Iteration Time 3.342 (3.416)\n",
      "**********************************\n",
      "attacked module: stage_3.0.conv_a\n",
      "attacked module: stage_3.3.conv_a\n",
      "attacked weight index: 19080\n",
      "weight before attack: tensor(0.0208, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [003/020]   Attack Time 8.845 (8.206)\n",
      "Loss before attack: 490.8237\n",
      "Loss after attack: 14158.9395\n",
      "Bit flips: 6\n",
      "Hamming distance: 6\n",
      "**Test** MCC: -0.043. Val_Loss: 14459.600\n",
      "Iteration Time 3.414 (3.415)\n",
      "**********************************\n",
      "attacked module: stage_2.7.conv_b\n",
      "attacked module: stage_3.10.conv_a\n",
      "attacked weight index: 24686\n",
      "weight before attack: tensor(0.0500, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "Iteration: [004/020]   Attack Time 8.035 (8.163)\n",
      "Loss before attack: 14158.9395\n",
      "Loss after attack: 3014658.0000\n",
      "Bit flips: 8\n",
      "Hamming distance: 8\n",
      "**Test** MCC: -0.044. Val_Loss: 3080105.296\n",
      "Iteration Time 3.564 (3.452)\n",
      "**********************************\n",
      "attacked module: stage_3.3.conv_b\n",
      "attacked module: stage_2.7.conv_b\n",
      "attacked weight index: 7925\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [005/020]   Attack Time 11.146 (8.760)\n",
      "Loss before attack: 3014658.0000\n",
      "Loss after attack: 86073712.0000\n",
      "Bit flips: 10\n",
      "Hamming distance: 10\n",
      "**Test** MCC: -0.004. Val_Loss: 79970781.320\n",
      "Iteration Time 3.527 (3.467)\n",
      "**********************************\n",
      "attacked module: stage_3.3.conv_a\n",
      "attacked module: stage_1.10.conv_b\n",
      "attacked weight index: 216\n",
      "weight before attack: tensor(-0.0562, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [006/020]   Attack Time 11.112 (9.152)\n",
      "Loss before attack: 86073712.0000\n",
      "Loss after attack: 4096183808.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 12\n",
      "**Test** MCC: -0.011. Val_Loss: 3805948263.699\n",
      "Iteration Time 3.441 (3.463)\n",
      "**********************************\n",
      "attacked module: stage_1.0.conv_a\n",
      "attacked module: stage_3.6.conv_a\n",
      "attacked weight index: 1911\n",
      "weight before attack: tensor(0.1669, device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "Iteration: [007/020]   Attack Time 7.289 (8.886)\n",
      "Loss before attack: 4096183808.0000\n",
      "Loss after attack: 106477215744.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 14\n",
      "**Test** MCC: -0.007. Val_Loss: 99547338325.730\n",
      "Iteration Time 3.519 (3.471)\n",
      "**********************************\n",
      "attacked module: stage_1.0.conv_b\n",
      "attacked module: stage_2.10.conv_b\n",
      "attacked weight index: 2347\n",
      "weight before attack: tensor(-0.0416, device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "Iteration: [008/020]   Attack Time 8.602 (8.850)\n",
      "Loss before attack: 106477215744.0000\n",
      "Loss after attack: 6725035884544.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 16\n",
      "**Test** MCC: -0.007. Val_Loss: 6288155237302.014\n",
      "Iteration Time 3.657 (3.494)\n",
      "**********************************\n",
      "attacked module: stage_3.2.conv_b\n",
      "attacked module: stage_3.13.conv_a\n",
      "attacked weight index: 33510\n",
      "weight before attack: tensor(0.0386, device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "Iteration: [009/020]   Attack Time 11.077 (9.098)\n",
      "Loss before attack: 6725035884544.0000\n",
      "Loss after attack: 91510225764352.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 18\n",
      "**Test** MCC: -0.007. Val_Loss: 85565116157368.547\n",
      "Iteration Time 3.458 (3.490)\n",
      "**********************************\n",
      "attacked module: stage_3.2.conv_a\n",
      "attacked module: stage_1.14.conv_b\n",
      "attacked weight index: 883\n",
      "weight before attack: tensor(0.0952, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "Iteration: [010/020]   Attack Time 11.002 (9.288)\n",
      "Loss before attack: 91510225764352.0000\n",
      "Loss after attack: 5638630097813504.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 20\n",
      "**Test** MCC: 0.002. Val_Loss: 5274314754900942.000\n",
      "Iteration Time 3.475 (3.489)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_b\n",
      "attacked module: stage_1.11.conv_a\n",
      "attacked weight index: 2500\n",
      "weight before attack: tensor(-0.0539, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [011/020]   Attack Time 10.858 (9.431)\n",
      "Loss before attack: 5641111515168768.0000\n",
      "Loss after attack: 178826082969976832.0000\n",
      "Bit flips: 22\n",
      "Hamming distance: 22\n",
      "**Test** MCC: 0.017. Val_Loss: 167206178878145152.000\n",
      "Iteration Time 3.640 (3.502)\n",
      "**********************************\n",
      "attacked module: stage_3.1.conv_a\n",
      "attacked module: stage_2.9.conv_a\n",
      "attacked weight index: 501\n",
      "weight before attack: tensor(-0.0460, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [012/020]   Attack Time 10.869 (9.551)\n",
      "Loss before attack: 178826082969976832.0000\n",
      "Loss after attack: 9396719940578312192.0000\n",
      "Bit flips: 24\n",
      "Hamming distance: 24\n",
      "**Test** MCC: 0.005. Val_Loss: 8785573442715247616.000\n",
      "Iteration Time 3.586 (3.509)\n",
      "**********************************\n",
      "attacked module: stage_3.0.conv_b\n",
      "attacked module: stage_3.10.conv_a\n",
      "attacked weight index: 40620\n",
      "weight before attack: tensor(-0.0243, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [013/020]   Attack Time 10.860 (9.651)\n",
      "Loss before attack: 9396719940578312192.0000\n",
      "Loss after attack: 2086323911839285510144.0000\n",
      "Bit flips: 26\n",
      "Hamming distance: 26\n",
      "**Test** MCC: 0.005. Val_Loss: 1950747705614273085440.000\n",
      "Iteration Time 3.522 (3.510)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: stage_2.4.conv_b\n",
      "attacked weight index: 7410\n",
      "weight before attack: tensor(-0.0194, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "Iteration: [014/020]   Attack Time 7.104 (9.469)\n",
      "Loss before attack: 2086323911839285510144.0000\n",
      "Loss after attack: 27755231891721816113152.0000\n",
      "Bit flips: 28\n",
      "Hamming distance: 27\n",
      "**Test** MCC: 0.008. Val_Loss: 25877929059886963884032.000\n",
      "Iteration Time 3.522 (3.511)\n",
      "**********************************\n",
      "attacked module: stage_1.7.conv_b\n",
      "attacked module: stage_2.14.conv_a\n",
      "attacked weight index: 8295\n",
      "weight before attack: tensor(0.0691, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [015/020]   Attack Time 7.331 (9.327)\n",
      "Loss before attack: 27755231891721816113152.0000\n",
      "Loss after attack: 327970607637990247235584.0000\n",
      "Bit flips: 30\n",
      "Hamming distance: 29\n",
      "**Test** MCC: -0.000. Val_Loss: 305783409710536360722432.000\n",
      "Iteration Time 3.540 (3.513)\n",
      "**********************************\n",
      "attacked module: stage_1.7.conv_a\n",
      "attacked module: stage_3.9.conv_b\n",
      "attacked weight index: 36253\n",
      "weight before attack: tensor(-0.0983, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "Iteration: [016/020]   Attack Time 7.314 (9.201)\n",
      "Loss before attack: 327970607637990247235584.0000\n",
      "Loss after attack: 29192576627513779420135424.0000\n",
      "Bit flips: 32\n",
      "Hamming distance: 31\n",
      "**Test** MCC: 0.009. Val_Loss: 27216780165762721588969472.000\n",
      "Iteration Time 3.550 (3.516)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_a\n",
      "attacked module: stage_2.14.conv_b\n",
      "attacked weight index: 11819\n",
      "weight before attack: tensor(0.0066, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "Iteration: [017/020]   Attack Time 7.196 (9.083)\n",
      "Loss before attack: 29192576627513779420135424.0000\n",
      "Loss after attack: 510664241458529605752193024.0000\n",
      "Bit flips: 34\n",
      "Hamming distance: 33\n",
      "**Test** MCC: 0.009. Val_Loss: 476098237062299322899496960.000\n",
      "Iteration Time 3.555 (3.518)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_b\n",
      "attacked module: stage_2.4.conv_b\n",
      "attacked weight index: 3482\n",
      "weight before attack: tensor(-0.0118, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [018/020]   Attack Time 7.330 (8.986)\n",
      "Loss before attack: 510664241458529605752193024.0000\n",
      "Loss after attack: 58988874236788228829457940480.0000\n",
      "Bit flips: 36\n",
      "Hamming distance: 35\n",
      "**Test** MCC: 0.010. Val_Loss: 55001121762373702793962717184.000\n",
      "Iteration Time 3.467 (3.515)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_a\n",
      "attacked module: stage_2.1.conv_a\n",
      "attacked weight index: 10804\n",
      "weight before attack: tensor(0.0344, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [019/020]   Attack Time 7.256 (8.895)\n",
      "Loss before attack: 58988874236788228829457940480.0000\n",
      "Loss after attack: 789366451644370149509282398208.0000\n",
      "Bit flips: 38\n",
      "Hamming distance: 37\n",
      "**Test** MCC: 0.012. Val_Loss: 772388530643418561296264593408.000\n",
      "Iteration Time 3.566 (3.518)\n",
      "**********************************\n",
      "attacked module: stage_1.3.conv_b\n",
      "attacked module: stage_1.1.conv_b\n",
      "attacked weight index: 1671\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [020/020]   Attack Time 7.194 (8.810)\n",
      "Loss before attack: 828407275389413806334273388544.0000\n",
      "Loss after attack: 94040705040113884521749228290048.0000\n",
      "Bit flips: 40\n",
      "Hamming distance: 39\n",
      "**Test** MCC: 0.012. Val_Loss: 87672615132981471327848058847232.000\n",
      "Iteration Time 3.516 (3.518)\n",
      "Plot saved as CustomModel/PBS_to_RandomFlip_attack/PBS_to_RandomFlip_attack.png\n",
      "\n",
      "MCC after 100 times PBS to Random: 0.011699364357906241\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"PBS_to_RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_path,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,\n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 3,                  # Chế độ tấn công PBS -> random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "best_mcc = test( trained_model,test_loader)\n",
    "print(f\"\\nMCC after 100 times PBS to Random: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "799e64b0-3b50-4bfa-9193-95cda8da9a48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.901. Val_Loss: 0.148\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: stage_3.15.conv_b\n",
      "attacked weight index: 21661\n",
      "weight before attack: tensor(0.0212, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "attacked module: fc1\n",
      "Iteration: [001/020]   Attack Time 7.654 (7.654)\n",
      "Loss before attack: 0.0829\n",
      "Loss after attack: 10.0068\n",
      "Bit flips: 2\n",
      "Hamming distance: 2\n",
      "**Test** MCC: 0.143. Val_Loss: 14.278\n",
      "Iteration Time 3.594 (3.594)\n",
      "**********************************\n",
      "attacked module: stage_2.6.conv_a\n",
      "attacked weight index: 8954\n",
      "weight before attack: tensor(0.0990, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "attacked module: stage_1.5.conv_a\n",
      "Iteration: [002/020]   Attack Time 7.195 (7.425)\n",
      "Loss before attack: 10.0068\n",
      "Loss after attack: 785.9612\n",
      "Bit flips: 4\n",
      "Hamming distance: 4\n",
      "**Test** MCC: 0.138. Val_Loss: 1128.641\n",
      "Iteration Time 3.449 (3.522)\n",
      "**********************************\n",
      "attacked module: stage_3.15.conv_b\n",
      "attacked weight index: 36422\n",
      "weight before attack: tensor(0.1353, device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "attacked module: stage_1.3.conv_a\n",
      "Iteration: [003/020]   Attack Time 7.376 (7.408)\n",
      "Loss before attack: 785.9612\n",
      "Loss after attack: 113592.7578\n",
      "Bit flips: 6\n",
      "Hamming distance: 6\n",
      "**Test** MCC: 0.139. Val_Loss: 163116.143\n",
      "Iteration Time 3.505 (3.516)\n",
      "**********************************\n",
      "attacked module: stage_3.2.conv_b\n",
      "attacked weight index: 29204\n",
      "weight before attack: tensor(-0.0105, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: stage_1.2.conv_b\n",
      "Iteration: [004/020]   Attack Time 7.359 (7.396)\n",
      "Loss before attack: 113592.7578\n",
      "Loss after attack: 14073571.0000\n",
      "Bit flips: 8\n",
      "Hamming distance: 8\n",
      "**Test** MCC: 0.073. Val_Loss: 20211516.854\n",
      "Iteration Time 3.459 (3.502)\n",
      "**********************************\n",
      "attacked module: stage_1.0.conv_a\n",
      "attacked weight index: 1816\n",
      "weight before attack: tensor(-0.4759, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "attacked module: stage_1.2.conv_a\n",
      "Iteration: [005/020]   Attack Time 7.296 (7.376)\n",
      "Loss before attack: 14072826.0000\n",
      "Loss after attack: 1614089728.0000\n",
      "Bit flips: 10\n",
      "Hamming distance: 10\n",
      "**Test** MCC: 0.158. Val_Loss: 2324171025.836\n",
      "Iteration Time 3.575 (3.516)\n",
      "**********************************\n",
      "attacked module: stage_1.1.conv_b\n",
      "attacked weight index: 1493\n",
      "weight before attack: tensor(0.0883, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "attacked module: stage_1.1.conv_b\n",
      "Iteration: [006/020]   Attack Time 7.339 (7.370)\n",
      "Loss before attack: 1614089728.0000\n",
      "Loss after attack: 186664108032.0000\n",
      "Bit flips: 12\n",
      "Hamming distance: 12\n",
      "**Test** MCC: 0.188. Val_Loss: 268031945684.634\n",
      "Iteration Time 3.466 (3.508)\n",
      "**********************************\n",
      "attacked module: stage_2.1.conv_a\n",
      "attacked weight index: 495\n",
      "weight before attack: tensor(-0.1085, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "attacked module: stage_1.5.conv_b\n",
      "Iteration: [007/020]   Attack Time 7.577 (7.400)\n",
      "Loss before attack: 186664108032.0000\n",
      "Loss after attack: 19263347752960.0000\n",
      "Bit flips: 14\n",
      "Hamming distance: 14\n",
      "**Test** MCC: 0.160. Val_Loss: 27607196416488.137\n",
      "Iteration Time 3.502 (3.507)\n",
      "**********************************\n",
      "attacked module: stage_3.11.conv_a\n",
      "attacked weight index: 13519\n",
      "weight before attack: tensor(-0.1919, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "attacked module: stage_1.1.conv_a\n",
      "Iteration: [008/020]   Attack Time 7.336 (7.392)\n",
      "Loss before attack: 19263347752960.0000\n",
      "Loss after attack: 1963799976345600.0000\n",
      "Bit flips: 16\n",
      "Hamming distance: 16\n",
      "**Test** MCC: 0.110. Val_Loss: 2821858711788638.500\n",
      "Iteration Time 3.542 (3.511)\n",
      "**********************************\n",
      "attacked module: stage_1.14.conv_a\n",
      "attacked weight index: 843\n",
      "weight before attack: tensor(-0.0983, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "attacked module: stage_1.0.conv_b\n",
      "Iteration: [009/020]   Attack Time 7.352 (7.387)\n",
      "Loss before attack: 1963799976345600.0000\n",
      "Loss after attack: 336988081846484992.0000\n",
      "Bit flips: 18\n",
      "Hamming distance: 18\n",
      "**Test** MCC: 0.059. Val_Loss: 483911790846663168.000\n",
      "Iteration Time 3.535 (3.514)\n",
      "**********************************\n",
      "attacked module: stage_2.12.conv_b\n",
      "attacked weight index: 6469\n",
      "weight before attack: tensor(0.0382, device='cuda:0')\n",
      "weight after attack: tensor(4., device='cuda:0')\n",
      "attacked module: stage_1.0.conv_a\n",
      "Iteration: [010/020]   Attack Time 8.227 (7.471)\n",
      "Loss before attack: 339014928453074944.0000\n",
      "Loss after attack: 39801142249026224128.0000\n",
      "Bit flips: 20\n",
      "Hamming distance: 20\n",
      "**Test** MCC: 0.182. Val_Loss: 56733789342074683392.000\n",
      "Iteration Time 3.521 (3.515)\n",
      "**********************************\n",
      "attacked module: stage_3.14.conv_b\n",
      "attacked weight index: 32911\n",
      "weight before attack: tensor(-0.0198, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: stage_1.3.conv_b\n",
      "Iteration: [011/020]   Attack Time 7.264 (7.452)\n",
      "Loss before attack: 39801142249026224128.0000\n",
      "Loss after attack: 3442749995020588154880.0000\n",
      "Bit flips: 22\n",
      "Hamming distance: 22\n",
      "**Test** MCC: 0.177. Val_Loss: 4906761126547143262208.000\n",
      "Iteration Time 3.650 (3.527)\n",
      "**********************************\n",
      "attacked module: stage_3.2.conv_a\n",
      "attacked weight index: 46492\n",
      "weight before attack: tensor(0.1668, device='cuda:0')\n",
      "weight after attack: tensor(-128., device='cuda:0')\n",
      "attacked module: stage_2.12.conv_b\n",
      "Iteration: [012/020]   Attack Time 7.990 (7.497)\n",
      "Loss before attack: 3442749995020588154880.0000\n",
      "Loss after attack: 151116015682204798550016.0000\n",
      "Bit flips: 24\n",
      "Hamming distance: 24\n",
      "**Test** MCC: 0.021. Val_Loss: 170276691493775782969344.000\n",
      "Iteration Time 3.603 (3.533)\n",
      "**********************************\n",
      "attacked module: stage_3.7.conv_b\n",
      "attacked weight index: 19740\n",
      "weight before attack: tensor(-0.0341, device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "attacked module: stage_2.12.conv_a\n",
      "Iteration: [013/020]   Attack Time 8.026 (7.538)\n",
      "Loss before attack: 151116015682204798550016.0000\n",
      "Loss after attack: 16604179512692026984366080.0000\n",
      "Bit flips: 26\n",
      "Hamming distance: 26\n",
      "**Test** MCC: 0.074. Val_Loss: 18641377754603146224599040.000\n",
      "Iteration Time 3.642 (3.542)\n",
      "**********************************\n",
      "attacked module: stage_1.13.conv_a\n",
      "attacked weight index: 931\n",
      "weight before attack: tensor(0.1402, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "attacked module: stage_2.15.conv_b\n",
      "Iteration: [014/020]   Attack Time 8.031 (7.573)\n",
      "Loss before attack: 16540727324764484554194944.0000\n",
      "Loss after attack: 390918456682641063686438912.0000\n",
      "Bit flips: 28\n",
      "Hamming distance: 28\n",
      "**Test** MCC: -0.011. Val_Loss: 330346935104767477418033152.000\n",
      "Iteration Time 3.682 (3.552)\n",
      "**********************************\n",
      "attacked module: stage_1.9.conv_b\n",
      "attacked weight index: 2296\n",
      "weight before attack: tensor(-0.1253, device='cuda:0')\n",
      "weight after attack: tensor(-33., device='cuda:0')\n",
      "attacked module: stage_2.15.conv_a\n",
      "Iteration: [015/020]   Attack Time 8.192 (7.614)\n",
      "Loss before attack: 390918456682641063686438912.0000\n",
      "Loss after attack: 67702599038078746786705440768.0000\n",
      "Bit flips: 30\n",
      "Hamming distance: 30\n",
      "**Test** MCC: -0.012. Val_Loss: 57173249275087254391743315968.000\n",
      "Iteration Time 3.833 (3.571)\n",
      "**********************************\n",
      "attacked module: stage_1.8.conv_b\n",
      "attacked weight index: 2333\n",
      "weight before attack: tensor(0.0875, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [016/020]   Attack Time 7.828 (7.628)\n",
      "Loss before attack: 67702599038078746786705440768.0000\n",
      "Loss after attack: 1157071968896808692830091345920.0000\n",
      "Bit flips: 32\n",
      "Hamming distance: 31\n",
      "**Test** MCC: -0.011. Val_Loss: 986911726701064100101071306752.000\n",
      "Iteration Time 3.718 (3.580)\n",
      "**********************************\n",
      "attacked module: stage_2.2.conv_b\n",
      "attacked weight index: 235\n",
      "weight before attack: tensor(-0.1076, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: stage_1.7.conv_b\n",
      "Iteration: [017/020]   Attack Time 7.471 (7.618)\n",
      "Loss before attack: 1157071968896808692830091345920.0000\n",
      "Loss after attack: 19334527136266428126935379869696.0000\n",
      "Bit flips: 34\n",
      "Hamming distance: 33\n",
      "**Test** MCC: -0.019. Val_Loss: 16488874445138866797989731500032.000\n",
      "Iteration Time 3.642 (3.583)\n",
      "**********************************\n",
      "attacked module: stage_2.13.conv_a\n",
      "attacked weight index: 6421\n",
      "weight before attack: tensor(0.1573, device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "attacked module: stage_1.7.conv_a\n",
      "Iteration: [018/020]   Attack Time 7.480 (7.611)\n",
      "Loss before attack: 19334527136266428126935379869696.0000\n",
      "Loss after attack: 4483060584017585060266252225740800.0000\n",
      "Bit flips: 36\n",
      "Hamming distance: 35\n",
      "**Test** MCC: -0.015. Val_Loss: 3823430550951417148972035806855168.000\n",
      "Iteration Time 3.591 (3.584)\n",
      "**********************************\n",
      "attacked module: stage_2.4.conv_b\n",
      "attacked weight index: 4637\n",
      "weight before attack: tensor(-0.0384, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "attacked module: stage_3.1.conv_a\n",
      "Iteration: [019/020]   Attack Time 10.984 (7.788)\n",
      "Loss before attack: 4483060584017585060266252225740800.0000\n",
      "Loss after attack: 58734491015268381313403514106413056.0000\n",
      "Bit flips: 38\n",
      "Hamming distance: 37\n",
      "**Test** MCC: 0.073. Val_Loss: 53439607208440506378809852796338176.000\n",
      "Iteration Time 3.638 (3.587)\n",
      "**********************************\n",
      "attacked module: stage_2.13.conv_b\n",
      "attacked weight index: 8015\n",
      "weight before attack: tensor(-0.0262, device='cuda:0')\n",
      "weight after attack: tensor(127., device='cuda:0')\n",
      "attacked module: stage_3.3.conv_b\n",
      "Iteration: [020/020]   Attack Time 11.174 (7.958)\n",
      "Loss before attack: 58734491015268381313403514106413056.0000\n",
      "Loss after attack: inf\n",
      "Bit flips: 40\n",
      "Hamming distance: 39\n",
      "**Test** MCC: 0.046. Val_Loss: inf\n",
      "Iteration Time 3.739 (3.594)\n",
      "Plot saved as CustomModel/RandomFlip_to_PBS_attack/RandomFlip_to_PBS_attack.png\n",
      "\n",
      "MCC after 100 times random to PBS: 0.04613136180861582\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel\", \"best_model.pth\")\n",
    "trained_model = CustomModel()\n",
    "\n",
    "# Tải trọng số từ file best_model.pth\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel\", \"RandomFlip_to_PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_path,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 4,                  # Chế độ tấn công Random -> PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "best_mcc = test( trained_model,test_loader)\n",
    "print(f\"\\nMCC after 100 times random to PBS: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7697a5c3-03a5-41bf-ab93-fb316b41e52f",
   "metadata": {},
   "source": [
    "## Train second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fb16fd3-7699-4cb4-8d3a-6e981aeffaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train Loss: 1.0852, Train MCC: 0.6870\n",
      "Validation Loss: 1.0362, Validation MCC: 0.7759\n",
      "Epoch 2/50\n",
      "Train Loss: 1.0343, Train MCC: 0.7781\n",
      "Validation Loss: 1.0322, Validation MCC: 0.7831\n",
      "Epoch 3/50\n",
      "Train Loss: 1.0327, Train MCC: 0.7805\n",
      "Validation Loss: 1.0318, Validation MCC: 0.7836\n",
      "Epoch 4/50\n",
      "Train Loss: 1.0314, Train MCC: 0.7833\n",
      "Validation Loss: 1.0330, Validation MCC: 0.7820\n",
      "Epoch 5/50\n",
      "Train Loss: 1.0316, Train MCC: 0.7828\n",
      "Validation Loss: 1.0320, Validation MCC: 0.7827\n",
      "Epoch 6/50\n",
      "Train Loss: 1.0309, Train MCC: 0.7842\n",
      "Validation Loss: 1.0312, Validation MCC: 0.7845\n",
      "Epoch 7/50\n",
      "Train Loss: 1.0305, Train MCC: 0.7849\n",
      "Validation Loss: 1.0306, Validation MCC: 0.7857\n",
      "Epoch 8/50\n",
      "Train Loss: 1.0262, Train MCC: 0.7917\n",
      "Validation Loss: 1.0237, Validation MCC: 0.7969\n",
      "Epoch 9/50\n",
      "Train Loss: 1.0221, Train MCC: 0.7987\n",
      "Validation Loss: 1.0218, Validation MCC: 0.8018\n",
      "Epoch 10/50\n",
      "Train Loss: 1.0215, Train MCC: 0.8004\n",
      "Validation Loss: 1.0198, Validation MCC: 0.8050\n",
      "Epoch 11/50\n",
      "Train Loss: 1.0189, Train MCC: 0.8051\n",
      "Validation Loss: 1.0196, Validation MCC: 0.8058\n",
      "Epoch 12/50\n",
      "Train Loss: 1.0184, Train MCC: 0.8056\n",
      "Validation Loss: 1.0180, Validation MCC: 0.8078\n",
      "Epoch 13/50\n",
      "Train Loss: 1.0178, Train MCC: 0.8069\n",
      "Validation Loss: 1.0198, Validation MCC: 0.8033\n",
      "Epoch 14/50\n",
      "Train Loss: 1.0175, Train MCC: 0.8069\n",
      "Validation Loss: 1.0187, Validation MCC: 0.8071\n",
      "Epoch 15/50\n",
      "Train Loss: 1.0173, Train MCC: 0.8070\n",
      "Validation Loss: 1.0274, Validation MCC: 0.7880\n",
      "Epoch 16/50\n",
      "Train Loss: 1.0174, Train MCC: 0.8073\n",
      "Validation Loss: 1.0184, Validation MCC: 0.8074\n",
      "Epoch 17/50\n",
      "Train Loss: 1.0200, Train MCC: 0.8020\n",
      "Validation Loss: 1.0186, Validation MCC: 0.8069\n",
      "Epoch 18/50\n",
      "Train Loss: 1.0148, Train MCC: 0.8111\n",
      "Validation Loss: 1.0120, Validation MCC: 0.8158\n",
      "Epoch 19/50\n",
      "Train Loss: 1.0133, Train MCC: 0.8138\n",
      "Validation Loss: 1.0127, Validation MCC: 0.8147\n",
      "Epoch 20/50\n",
      "Train Loss: 1.0126, Train MCC: 0.8145\n",
      "Validation Loss: 1.0122, Validation MCC: 0.8156\n",
      "Epoch 21/50\n",
      "Train Loss: 1.0091, Train MCC: 0.8201\n",
      "Validation Loss: 1.0167, Validation MCC: 0.8068\n",
      "Epoch 22/50\n",
      "Train Loss: 1.0079, Train MCC: 0.8224\n",
      "Validation Loss: 1.0088, Validation MCC: 0.8211\n",
      "Epoch 23/50\n",
      "Train Loss: 1.0079, Train MCC: 0.8227\n",
      "Validation Loss: 1.0076, Validation MCC: 0.8239\n",
      "Epoch 24/50\n",
      "Train Loss: 1.0080, Train MCC: 0.8226\n",
      "Validation Loss: 1.0079, Validation MCC: 0.8234\n",
      "Epoch 25/50\n",
      "Train Loss: 1.0051, Train MCC: 0.8273\n",
      "Validation Loss: 1.0037, Validation MCC: 0.8315\n",
      "Epoch 26/50\n",
      "Train Loss: 1.0066, Train MCC: 0.8258\n",
      "Validation Loss: 1.0112, Validation MCC: 0.8201\n",
      "Epoch 27/50\n",
      "Train Loss: 1.0076, Train MCC: 0.8234\n",
      "Validation Loss: 1.0067, Validation MCC: 0.8243\n",
      "Epoch 28/50\n",
      "Train Loss: 1.0042, Train MCC: 0.8295\n",
      "Validation Loss: 1.0099, Validation MCC: 0.8199\n",
      "Epoch 29/50\n",
      "Train Loss: 1.0036, Train MCC: 0.8304\n",
      "Validation Loss: 1.0079, Validation MCC: 0.8241\n",
      "Epoch 30/50\n",
      "Train Loss: 0.9994, Train MCC: 0.8373\n",
      "Validation Loss: 0.9983, Validation MCC: 0.8404\n",
      "Epoch 31/50\n",
      "Train Loss: 0.9969, Train MCC: 0.8416\n",
      "Validation Loss: 0.9970, Validation MCC: 0.8418\n",
      "Epoch 32/50\n",
      "Train Loss: 0.9955, Train MCC: 0.8447\n",
      "Validation Loss: 0.9964, Validation MCC: 0.8433\n",
      "Epoch 33/50\n",
      "Train Loss: 0.9983, Train MCC: 0.8392\n",
      "Validation Loss: 1.0038, Validation MCC: 0.8304\n",
      "Epoch 34/50\n",
      "Train Loss: 0.9988, Train MCC: 0.8385\n",
      "Validation Loss: 1.0106, Validation MCC: 0.8188\n",
      "Epoch 35/50\n",
      "Train Loss: 1.0019, Train MCC: 0.8330\n",
      "Validation Loss: 1.0064, Validation MCC: 0.8258\n",
      "Epoch 36/50\n",
      "Train Loss: 0.9959, Train MCC: 0.8437\n",
      "Validation Loss: 0.9960, Validation MCC: 0.8448\n",
      "Epoch 37/50\n",
      "Train Loss: 0.9950, Train MCC: 0.8455\n",
      "Validation Loss: 0.9954, Validation MCC: 0.8465\n",
      "Epoch 38/50\n",
      "Train Loss: 0.9962, Train MCC: 0.8433\n",
      "Validation Loss: 0.9966, Validation MCC: 0.8430\n",
      "Epoch 39/50\n",
      "Train Loss: 0.9979, Train MCC: 0.8403\n",
      "Validation Loss: 1.0082, Validation MCC: 0.8234\n",
      "Epoch 40/50\n",
      "Train Loss: 1.0000, Train MCC: 0.8365\n",
      "Validation Loss: 1.0069, Validation MCC: 0.8262\n",
      "Epoch 41/50\n",
      "Train Loss: 0.9955, Train MCC: 0.8444\n",
      "Validation Loss: 0.9961, Validation MCC: 0.8446\n",
      "Epoch 42/50\n",
      "Train Loss: 0.9945, Train MCC: 0.8461\n",
      "Validation Loss: 1.0028, Validation MCC: 0.8335\n",
      "Epoch 43/50\n",
      "Train Loss: 0.9959, Train MCC: 0.8438\n",
      "Validation Loss: 0.9983, Validation MCC: 0.8396\n",
      "Epoch 44/50\n",
      "Train Loss: 0.9928, Train MCC: 0.8491\n",
      "Validation Loss: 0.9953, Validation MCC: 0.8456\n",
      "Epoch 45/50\n",
      "Train Loss: 0.9927, Train MCC: 0.8492\n",
      "Validation Loss: 0.9951, Validation MCC: 0.8456\n",
      "Epoch 46/50\n",
      "Train Loss: 0.9923, Train MCC: 0.8497\n",
      "Validation Loss: 0.9955, Validation MCC: 0.8454\n",
      "Epoch 47/50\n",
      "Train Loss: 0.9927, Train MCC: 0.8494\n",
      "Validation Loss: 0.9956, Validation MCC: 0.8453\n",
      "Epoch 48/50\n",
      "Train Loss: 0.9925, Train MCC: 0.8495\n",
      "Validation Loss: 0.9952, Validation MCC: 0.8467\n",
      "Epoch 49/50\n",
      "Train Loss: 0.9923, Train MCC: 0.8501\n",
      "Validation Loss: 0.9952, Validation MCC: 0.8457\n",
      "Epoch 50/50\n",
      "Train Loss: 0.9924, Train MCC: 0.8498\n",
      "Validation Loss: 0.9940, Validation MCC: 0.8459\n",
      "Best MCC during training: 0.8458845896321342\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CustomModel2().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Số epoch để chờ trước khi dừng\n",
    "counter = 0\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Vòng lặp huấn luyện\n",
    "best_val_loss = float('inf')\n",
    "best_mcc = -1  # Khởi tạo MCC tốt nhất\n",
    "\n",
    "# Vòng lặp huấn luyện\n",
    "for epoch in range(num_epochs):\n",
    "    train_mcc, train_loss = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    val_mcc, val_loss, output_summary = validate(test_loader, model, criterion, summary_output=True)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_mcc = val_mcc  # Lưu MCC tốt nhất\n",
    "        counter = 0\n",
    "\n",
    "        save_dir = \"CustomModel2\"\n",
    "        save_path = os.path.join(save_dir, \"model.pth\")\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train MCC: {train_mcc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation MCC: {val_mcc:.4f}\")\n",
    "print(f\"Best MCC during training: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1da615-4cac-4211-aa06-e9fa9f329505",
   "metadata": {},
   "source": [
    "## Attack second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dcfa057-0619-4fa5-aed2-8b01848a50f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC before attack: 0.8458845896321342\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "best_mcc = test(trained_model, test_loader)\n",
    "print(f\"MCC before attack: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35349df9-2ad5-4463-ab65-d64b1f095f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.846. Val_Loss: 0.994\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [001/020]   Attack Time 1.101 (1.101)\n",
      "Loss before attack: 0.9096\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.227 (1.227)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [002/020]   Attack Time 1.174 (1.137)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 101\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.133 (1.180)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [003/020]   Attack Time 1.165 (1.147)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 201\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.180 (1.180)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [004/020]   Attack Time 1.162 (1.150)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 301\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.154 (1.174)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [005/020]   Attack Time 1.190 (1.158)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 401\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.146 (1.168)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [006/020]   Attack Time 1.215 (1.168)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 501\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.183 (1.171)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [007/020]   Attack Time 1.189 (1.171)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 601\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.165 (1.170)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [008/020]   Attack Time 1.121 (1.165)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 701\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.142 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [009/020]   Attack Time 1.138 (1.162)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 801\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.171 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [010/020]   Attack Time 1.153 (1.161)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 901\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.169 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [011/020]   Attack Time 1.179 (1.162)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1001\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.216 (1.172)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [012/020]   Attack Time 1.221 (1.167)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1101\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.117 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [013/020]   Attack Time 1.181 (1.168)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1201\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.166 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [014/020]   Attack Time 1.159 (1.168)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1301\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.142 (1.165)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [015/020]   Attack Time 1.160 (1.167)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1401\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.174 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [016/020]   Attack Time 1.145 (1.166)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1501\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.170 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [017/020]   Attack Time 1.145 (1.165)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1601\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.206 (1.168)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [018/020]   Attack Time 1.184 (1.166)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1701\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.145 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [019/020]   Attack Time 1.184 (1.167)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1801\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.164 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "Iteration: [020/020]   Attack Time 1.162 (1.166)\n",
      "Loss before attack: 1.0759\n",
      "Loss after attack: 1.0759\n",
      "Bit flips: 1901\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.196 (1.168)\n",
      "Plot saved as CustomModel2/PBS_attack/PBS_attack.png\n",
      "\n",
      "MCC after 100 times PBS: 0.6417351393140422\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_path = os.path.join(attack_dir, \"PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_attack.csv\")\n",
    "\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_path,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 1,                  # Chế độ tấn công PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "best_mcc = test(trained_model, test_loader)\n",
    "print(f\"\\nMCC after 100 times PBS: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a700d594-b183-473f-9a0f-03aec9ccfdb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.846. Val_Loss: 0.994\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 357\n",
      "weight before attack: tensor(0.0480, device='cuda:0')\n",
      "weight after attack: tensor(8192., device='cuda:0')\n",
      "Iteration: [001/020]   Attack Time 1.005 (1.005)\n",
      "Bit flips: 1\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.773\n",
      "Iteration Time 1.179 (1.179)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 153\n",
      "weight before attack: tensor(0.0277, device='cuda:0')\n",
      "weight after attack: tensor(128., device='cuda:0')\n",
      "Iteration: [002/020]   Attack Time 1.015 (1.010)\n",
      "Bit flips: 2\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.774\n",
      "Iteration Time 1.127 (1.153)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 418\n",
      "weight before attack: tensor(0.0358, device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "Iteration: [003/020]   Attack Time 1.011 (1.010)\n",
      "Bit flips: 3\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.774\n",
      "Iteration Time 1.175 (1.160)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 206\n",
      "weight before attack: tensor(-0.0204, device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "Iteration: [004/020]   Attack Time 1.047 (1.019)\n",
      "Bit flips: 4\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.774\n",
      "Iteration Time 1.178 (1.165)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 498\n",
      "weight before attack: tensor(-0.0047, device='cuda:0')\n",
      "weight after attack: tensor(-3., device='cuda:0')\n",
      "Iteration: [005/020]   Attack Time 1.020 (1.020)\n",
      "Bit flips: 5\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.774\n",
      "Iteration Time 1.170 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 58\n",
      "weight before attack: tensor(0.0513, device='cuda:0')\n",
      "weight after attack: tensor(-32768., device='cuda:0')\n",
      "Iteration: [006/020]   Attack Time 1.010 (1.018)\n",
      "Bit flips: 6\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.794\n",
      "Iteration Time 1.244 (1.179)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 330\n",
      "weight before attack: tensor(0.0293, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [007/020]   Attack Time 1.028 (1.019)\n",
      "Bit flips: 7\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.794\n",
      "Iteration Time 1.152 (1.175)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 169\n",
      "weight before attack: tensor(-0.0059, device='cuda:0')\n",
      "weight after attack: tensor(-257., device='cuda:0')\n",
      "Iteration: [008/020]   Attack Time 0.994 (1.016)\n",
      "Bit flips: 8\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.794\n",
      "Iteration Time 1.123 (1.168)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 492\n",
      "weight before attack: tensor(0.0102, device='cuda:0')\n",
      "weight after attack: tensor(16384., device='cuda:0')\n",
      "Iteration: [009/020]   Attack Time 1.027 (1.017)\n",
      "Bit flips: 9\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.794\n",
      "Iteration Time 1.167 (1.168)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 257\n",
      "weight before attack: tensor(0.0419, device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [010/020]   Attack Time 1.034 (1.019)\n",
      "Bit flips: 10\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.016. Val_Loss: 1.794\n",
      "Iteration Time 1.184 (1.170)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 452\n",
      "weight before attack: tensor(-0.0178, device='cuda:0')\n",
      "weight after attack: tensor(-257., device='cuda:0')\n",
      "Iteration: [011/020]   Attack Time 1.019 (1.019)\n",
      "Bit flips: 11\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.001. Val_Loss: 1.797\n",
      "Iteration Time 1.180 (1.171)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 121\n",
      "weight before attack: tensor(-0.0414, device='cuda:0')\n",
      "weight after attack: tensor(-17., device='cuda:0')\n",
      "Iteration: [012/020]   Attack Time 1.025 (1.020)\n",
      "Bit flips: 12\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.000. Val_Loss: 1.797\n",
      "Iteration Time 1.121 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 226\n",
      "weight before attack: tensor(-0.0099, device='cuda:0')\n",
      "weight after attack: tensor(-2049., device='cuda:0')\n",
      "Iteration: [013/020]   Attack Time 1.011 (1.019)\n",
      "Bit flips: 13\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.000. Val_Loss: 1.810\n",
      "Iteration Time 1.158 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 464\n",
      "weight before attack: tensor(0.0025, device='cuda:0')\n",
      "weight after attack: tensor(2048., device='cuda:0')\n",
      "Iteration: [014/020]   Attack Time 1.017 (1.019)\n",
      "Bit flips: 14\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.000. Val_Loss: 1.810\n",
      "Iteration Time 1.160 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 360\n",
      "weight before attack: tensor(-0.0328, device='cuda:0')\n",
      "weight after attack: tensor(-16385., device='cuda:0')\n",
      "Iteration: [015/020]   Attack Time 1.074 (1.022)\n",
      "Bit flips: 15\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.149. Val_Loss: 1.880\n",
      "Iteration Time 1.165 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 387\n",
      "weight before attack: tensor(0.0485, device='cuda:0')\n",
      "weight after attack: tensor(512., device='cuda:0')\n",
      "Iteration: [016/020]   Attack Time 1.004 (1.021)\n",
      "Bit flips: 16\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.142. Val_Loss: 1.877\n",
      "Iteration Time 1.161 (1.165)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 84\n",
      "weight before attack: tensor(0.0339, device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [017/020]   Attack Time 0.995 (1.020)\n",
      "Bit flips: 17\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.142. Val_Loss: 1.877\n",
      "Iteration Time 1.191 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 176\n",
      "weight before attack: tensor(0.0385, device='cuda:0')\n",
      "weight after attack: tensor(2048., device='cuda:0')\n",
      "Iteration: [018/020]   Attack Time 1.022 (1.020)\n",
      "Bit flips: 18\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.142. Val_Loss: 1.877\n",
      "Iteration Time 1.139 (1.165)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 200\n",
      "weight before attack: tensor(0.0372, device='cuda:0')\n",
      "weight after attack: tensor(512., device='cuda:0')\n",
      "Iteration: [019/020]   Attack Time 1.030 (1.020)\n",
      "Bit flips: 19\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.154. Val_Loss: 1.880\n",
      "Iteration Time 1.161 (1.165)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 153\n",
      "weight before attack: tensor(128., device='cuda:0')\n",
      "weight after attack: tensor(0., device='cuda:0')\n",
      "Iteration: [020/020]   Attack Time 1.010 (1.020)\n",
      "Bit flips: 20\n",
      "Hamming distance: 0\n",
      "**Test** MCC: -0.154. Val_Loss: 1.880\n",
      "Iteration Time 1.156 (1.165)\n",
      "Plot saved as CustomModel2/RandomFlip_attack/RandomFlip_attack.png\n",
      "\n",
      "MCC after 100 times Random attack: -0.15418494486301548\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_path = os.path.join(attack_dir, \"RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_path,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 2,                  # Chế độ tấn công random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "\n",
    "best_mcc = test(trained_model ,test_loader)\n",
    "print(f\"\\nMCC after 100 times Random attack: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59c7df1b-f79c-407c-a2a7-0b26256de0e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.846. Val_Loss: 0.994\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 23\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-8193., device='cuda:0')\n",
      "Iteration: [001/020]   Attack Time 2.027 (2.027)\n",
      "Loss before attack: 0.9097\n",
      "Loss after attack: 1.0624\n",
      "Bit flips: 2\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.200 (1.200)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 261\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8192., device='cuda:0')\n",
      "Iteration: [002/020]   Attack Time 2.197 (2.112)\n",
      "Loss before attack: 1.0624\n",
      "Loss after attack: 1.0624\n",
      "Bit flips: 103\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.570. Val_Loss: 1.156\n",
      "Iteration Time 1.139 (1.169)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 88\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8192., device='cuda:0')\n",
      "Iteration: [003/020]   Attack Time 2.206 (2.143)\n",
      "Loss before attack: 1.1158\n",
      "Loss after attack: 1.1158\n",
      "Bit flips: 204\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.570. Val_Loss: 1.156\n",
      "Iteration Time 1.209 (1.183)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 127\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(1024., device='cuda:0')\n",
      "Iteration: [004/020]   Attack Time 2.259 (2.172)\n",
      "Loss before attack: 1.1158\n",
      "Loss after attack: 1.1158\n",
      "Bit flips: 305\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.564. Val_Loss: 1.159\n",
      "Iteration Time 1.120 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 370\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(1., device='cuda:0')\n",
      "Iteration: [005/020]   Attack Time 2.211 (2.180)\n",
      "Loss before attack: 1.1158\n",
      "Loss after attack: 1.1158\n",
      "Bit flips: 406\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.564. Val_Loss: 1.159\n",
      "Iteration Time 1.179 (1.169)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 60\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-129., device='cuda:0')\n",
      "Iteration: [006/020]   Attack Time 2.156 (2.176)\n",
      "Loss before attack: 1.1158\n",
      "Loss after attack: 1.1158\n",
      "Bit flips: 507\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.447. Val_Loss: 1.236\n",
      "Iteration Time 1.172 (1.170)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 471\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(64., device='cuda:0')\n",
      "Iteration: [007/020]   Attack Time 2.171 (2.175)\n",
      "Loss before attack: 1.1744\n",
      "Loss after attack: 1.1744\n",
      "Bit flips: 608\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.447. Val_Loss: 1.236\n",
      "Iteration Time 1.204 (1.175)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 43\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(512., device='cuda:0')\n",
      "Iteration: [008/020]   Attack Time 2.144 (2.171)\n",
      "Loss before attack: 1.1744\n",
      "Loss after attack: 1.1744\n",
      "Bit flips: 709\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.636. Val_Loss: 1.112\n",
      "Iteration Time 1.201 (1.178)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 316\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [009/020]   Attack Time 2.222 (2.177)\n",
      "Loss before attack: 1.0650\n",
      "Loss after attack: 1.0650\n",
      "Bit flips: 810\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.636. Val_Loss: 1.112\n",
      "Iteration Time 1.188 (1.179)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 421\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-257., device='cuda:0')\n",
      "Iteration: [010/020]   Attack Time 2.184 (2.178)\n",
      "Loss before attack: 1.0650\n",
      "Loss after attack: 1.0650\n",
      "Bit flips: 911\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.636. Val_Loss: 1.112\n",
      "Iteration Time 1.198 (1.181)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 218\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "Iteration: [011/020]   Attack Time 2.222 (2.182)\n",
      "Loss before attack: 1.0650\n",
      "Loss after attack: 1.0650\n",
      "Bit flips: 1012\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.636. Val_Loss: 1.112\n",
      "Iteration Time 1.189 (1.182)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 197\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-129., device='cuda:0')\n",
      "Iteration: [012/020]   Attack Time 2.204 (2.184)\n",
      "Loss before attack: 1.0650\n",
      "Loss after attack: 1.0650\n",
      "Bit flips: 1113\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.636. Val_Loss: 1.112\n",
      "Iteration Time 1.096 (1.175)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 212\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(16384., device='cuda:0')\n",
      "Iteration: [013/020]   Attack Time 2.255 (2.189)\n",
      "Loss before attack: 1.0650\n",
      "Loss after attack: 1.0650\n",
      "Bit flips: 1214\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.635. Val_Loss: 1.113\n",
      "Iteration Time 1.211 (1.177)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 161\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-513., device='cuda:0')\n",
      "Iteration: [014/020]   Attack Time 2.204 (2.190)\n",
      "Loss before attack: 1.0650\n",
      "Loss after attack: 1.0650\n",
      "Bit flips: 1315\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.635. Val_Loss: 1.113\n",
      "Iteration Time 1.139 (1.175)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 34\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-513., device='cuda:0')\n",
      "Iteration: [015/020]   Attack Time 2.263 (2.195)\n",
      "Loss before attack: 1.0650\n",
      "Loss after attack: 1.0650\n",
      "Bit flips: 1416\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.677. Val_Loss: 1.089\n",
      "Iteration Time 1.176 (1.175)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 135\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "Iteration: [016/020]   Attack Time 2.121 (2.190)\n",
      "Loss before attack: 1.0533\n",
      "Loss after attack: 1.0533\n",
      "Bit flips: 1517\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.677. Val_Loss: 1.089\n",
      "Iteration Time 1.155 (1.173)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 84\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(4096., device='cuda:0')\n",
      "Iteration: [017/020]   Attack Time 2.231 (2.193)\n",
      "Loss before attack: 1.0533\n",
      "Loss after attack: 1.0533\n",
      "Bit flips: 1618\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.677. Val_Loss: 1.089\n",
      "Iteration Time 1.121 (1.170)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 101\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(512., device='cuda:0')\n",
      "Iteration: [018/020]   Attack Time 2.103 (2.188)\n",
      "Loss before attack: 1.0533\n",
      "Loss after attack: 1.0533\n",
      "Bit flips: 1719\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.677. Val_Loss: 1.089\n",
      "Iteration Time 1.158 (1.170)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 126\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "Iteration: [019/020]   Attack Time 2.180 (2.187)\n",
      "Loss before attack: 1.0533\n",
      "Loss after attack: 1.0533\n",
      "Bit flips: 1820\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.677. Val_Loss: 1.089\n",
      "Iteration Time 1.135 (1.168)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked module: classifier\n",
      "attacked weight index: 134\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "Iteration: [020/020]   Attack Time 2.166 (2.186)\n",
      "Loss before attack: 1.0533\n",
      "Loss after attack: 1.0533\n",
      "Bit flips: 1921\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.632. Val_Loss: 1.113\n",
      "Iteration Time 1.165 (1.168)\n",
      "Plot saved as CustomModel2/PBS_to_RandomFlip_attack/PBS_to_RandomFlip_attack.png\n",
      "\n",
      "MCC after 100 times PBS to Random: 0.6316712316557384\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"PBS_to_RandomFlip_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"PBS_to_RandomFlip_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_path,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path, \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 3,                  # Chế độ tấn công PBS -> random\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "best_mcc = test( trained_model,test_loader)\n",
    "print(f\"\\nMCC after 100 times PBS to Random: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d875038-92fb-44a5-80f3-36ddbb14431b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Test** MCC: 0.846. Val_Loss: 0.994\n",
      "Attack sample size is 256\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 144\n",
      "weight before attack: tensor(-0.0402, device='cuda:0')\n",
      "weight after attack: tensor(-9., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [001/020]   Attack Time 2.073 (2.073)\n",
      "Loss before attack: 0.9083\n",
      "Loss after attack: 1.0644\n",
      "Bit flips: 2\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.642. Val_Loss: 1.123\n",
      "Iteration Time 1.192 (1.192)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 281\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(2., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [002/020]   Attack Time 2.260 (2.167)\n",
      "Loss before attack: 1.0644\n",
      "Loss after attack: 1.0644\n",
      "Bit flips: 103\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.641. Val_Loss: 1.123\n",
      "Iteration Time 1.151 (1.172)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 379\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [003/020]   Attack Time 2.275 (2.203)\n",
      "Loss before attack: 1.0644\n",
      "Loss after attack: 1.0644\n",
      "Bit flips: 204\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.641. Val_Loss: 1.123\n",
      "Iteration Time 1.150 (1.164)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 179\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(2048., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [004/020]   Attack Time 2.212 (2.205)\n",
      "Loss before attack: 1.0644\n",
      "Loss after attack: 1.0644\n",
      "Bit flips: 305\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.641. Val_Loss: 1.123\n",
      "Iteration Time 1.206 (1.175)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 339\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [005/020]   Attack Time 2.156 (2.195)\n",
      "Loss before attack: 1.1383\n",
      "Loss after attack: 1.1383\n",
      "Bit flips: 406\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.535. Val_Loss: 1.200\n",
      "Iteration Time 1.117 (1.163)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 296\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-513., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [006/020]   Attack Time 2.190 (2.195)\n",
      "Loss before attack: 1.5680\n",
      "Loss after attack: 1.5680\n",
      "Bit flips: 507\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.139. Val_Loss: 1.599\n",
      "Iteration Time 1.137 (1.159)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 344\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-4097., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [007/020]   Attack Time 2.171 (2.191)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 608\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.181 (1.162)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 269\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [008/020]   Attack Time 2.117 (2.182)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 709\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.192 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 348\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(8., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [009/020]   Attack Time 2.202 (2.184)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 810\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.186 (1.168)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 254\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-65., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [010/020]   Attack Time 2.237 (2.189)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 911\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.198 (1.171)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 395\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-2., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [011/020]   Attack Time 2.133 (2.184)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 1012\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.183 (1.172)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 480\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [012/020]   Attack Time 2.216 (2.187)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 1113\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.147 (1.170)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 302\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [013/020]   Attack Time 2.224 (2.190)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 1214\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.100 (1.165)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 166\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-16385., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [014/020]   Attack Time 2.180 (2.189)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 1315\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.193 (1.167)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 269\n",
      "weight before attack: tensor(32., device='cuda:0')\n",
      "weight after attack: tensor(8224., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [015/020]   Attack Time 2.148 (2.186)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 1416\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.117. Val_Loss: 1.608\n",
      "Iteration Time 1.154 (1.166)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 334\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(16., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [016/020]   Attack Time 2.224 (2.189)\n",
      "Loss before attack: 1.5721\n",
      "Loss after attack: 1.5721\n",
      "Bit flips: 1517\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.118. Val_Loss: 1.608\n",
      "Iteration Time 1.199 (1.168)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 53\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-16385., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [017/020]   Attack Time 2.244 (2.192)\n",
      "Loss before attack: 1.5682\n",
      "Loss after attack: 1.5682\n",
      "Bit flips: 1618\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.148. Val_Loss: 1.604\n",
      "Iteration Time 1.210 (1.170)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 39\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-2049., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [018/020]   Attack Time 2.186 (2.192)\n",
      "Loss before attack: 1.5682\n",
      "Loss after attack: 1.5682\n",
      "Bit flips: 1719\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.148. Val_Loss: 1.604\n",
      "Iteration Time 1.164 (1.170)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 465\n",
      "weight before attack: tensor(-1., device='cuda:0')\n",
      "weight after attack: tensor(-5., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [019/020]   Attack Time 2.182 (2.191)\n",
      "Loss before attack: 1.5924\n",
      "Loss after attack: 1.5924\n",
      "Bit flips: 1820\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.075. Val_Loss: 1.626\n",
      "Iteration Time 1.187 (1.171)\n",
      "**********************************\n",
      "attacked module: classifier\n",
      "attacked weight index: 22\n",
      "weight before attack: tensor(0., device='cuda:0')\n",
      "weight after attack: tensor(32., device='cuda:0')\n",
      "attacked module: classifier\n",
      "Iteration: [020/020]   Attack Time 2.231 (2.193)\n",
      "Loss before attack: 1.5924\n",
      "Loss after attack: 1.5924\n",
      "Bit flips: 1921\n",
      "Hamming distance: 0\n",
      "**Test** MCC: 0.075. Val_Loss: 1.626\n",
      "Iteration Time 1.166 (1.171)\n",
      "Plot saved as CustomModel2/RandomFlip_to_PBS_attack/RandomFlip_to_PBS_attack.png\n",
      "\n",
      "MCC after 100 times Random to PBS: 0.0752135152168701\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Tải mô hình đã huấn luyện\n",
    "model_path = os.path.join(\"CustomModel2\", \"model.pth\")\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Không tìm thấy mô hình tại: {model_path}\")\n",
    "\n",
    "trained_model = CustomModel2()\n",
    "\n",
    "trained_model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda' if torch.cuda.is_available() else 'cpu')))\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "# Bước 2: Tạo bản sao của mô hình để làm tham chiếu\n",
    "model_clean = copy.deepcopy(trained_model)\n",
    "\n",
    "# Bước 3: Khởi tạo đối tượng tấn công BFA\n",
    "attacker = BFA(criterion=criterion, model=trained_model, k_top=10)\n",
    "\n",
    "# Định nghĩa đường dẫn để lưu kết quả tấn công\n",
    "attack_dir = os.path.join(\"CustomModel2\", \"RandomFlip_to_PBS_attack\")\n",
    "\n",
    "os.makedirs(attack_dir, exist_ok=True)\n",
    "attack_image_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.png\")\n",
    "attack_csv_path = os.path.join(attack_dir, \"RandomFlip_to_PBS_attack.csv\")\n",
    "\n",
    "# Bước 4: Thực hiện tấn công\n",
    "perform_attack(\n",
    "    attacker=attacker,               # Đối tượng tấn công\n",
    "    model=trained_model,             # Mô hình bị tấn công\n",
    "    model_clean=model_clean,         # Mô hình gốc làm tham chiếu\n",
    "    train_loader=train_loader,       # Bộ dữ liệu huấn luyện\n",
    "    test_loader=test_loader,         # Bộ dữ liệu kiểm tra\n",
    "    N_iter=args.n_iter,              # Số vòng lặp tấn công\n",
    "    writer=writer,                   # TensorBoard writer để ghi log\n",
    "    file=attack_image_path,          # Lưu ảnh vào thư mục tấn công\n",
    "    csv_file=attack_csv_path,  \n",
    "    csv_save_path=args.save_path,    # Đường dẫn lưu file CSV\n",
    "    attack_type= 4,                  # Chế độ tấn công Random -> PBS\n",
    ")\n",
    "\n",
    "writer.close()  # Đóng TensorBoard writer\n",
    "best_mcc = test( trained_model,test_loader)\n",
    "print(f\"\\nMCC after 100 times Random to PBS: {best_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "199afe5b-0442-41e8-8bd7-f0e17a00340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đồ thị đã được lưu tại CustomModel/Aggregate_Results/CustomModel_comparison_plot.png\n",
      "Đồ thị đã được lưu tại CustomModel2/Aggregate_Results/CustomModel2_comparison_plot.png\n"
     ]
    }
   ],
   "source": [
    "model_names = [\"CustomModel\", \"CustomModel2\"]\n",
    "attack_types = [\"PBS\", \"RandomFlip\", \"PBS_to_RandomFlip\", \"RandomFlip_to_PBS\"]\n",
    "\n",
    "def aggregate_results(model_name, attack_types):\n",
    "    \n",
    "    aggregate_dir = os.path.join(model_name, \"Aggregate_Results\")\n",
    "    os.makedirs(aggregate_dir, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Đọc kết quả từ từng kịch bản tấn công\n",
    "    for attack_type in attack_types:\n",
    "        csv_file_path = os.path.join(model_name, f\"{attack_type}_attack\", f\"{attack_type}_attack.csv\")\n",
    "        if os.path.exists(csv_file_path):\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "            \n",
    "            mcc_values = df['MCC Drop'].tolist()\n",
    "            results.append(mcc_values)\n",
    "        else:\n",
    "            print(f\"File {csv_file_path} không tồn tại.\")\n",
    "\n",
    "    # Ghi kết quả tổng hợp vào file CSV\n",
    "    aggregate_df = pd.DataFrame(results, index=attack_types).T\n",
    "    aggregate_csv_path = os.path.join(aggregate_dir, \"aggregated_results.csv\")\n",
    "    aggregate_df.to_csv(aggregate_csv_path)\n",
    "\n",
    "    # Vẽ đồ thị so sánh\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, attack_type in enumerate(attack_types):\n",
    "        plt.plot(aggregate_df.index, aggregate_df[attack_type], marker='o', label=attack_type)\n",
    "\n",
    "    plt.title(f'So sánh MCC giữa các kịch bản tấn công cho {model_name}', fontsize=14)\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('MCC', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    epochs = aggregate_df.index.astype(int).tolist()\n",
    "    plt.xticks(epochs, epochs)\n",
    "    \n",
    "    plot_path = os.path.join(aggregate_dir, f\"{model_name}_comparison_plot.png\")\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Đồ thị đã được lưu tại {plot_path}\")\n",
    "\n",
    "for model_name in model_names:\n",
    "    aggregate_results(model_name, attack_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5cf81-88d2-4ebc-9de0-2e3076c58fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
